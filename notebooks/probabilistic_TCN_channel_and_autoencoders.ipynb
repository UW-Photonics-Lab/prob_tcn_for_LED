{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58dbdd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "import torch\n",
    "import h5py\n",
    "import torchaudio\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.special import beta\n",
    "from torch.special import psi\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Subset\n",
    "import copy\n",
    "import math\n",
    "import wandb\n",
    "import yaml\n",
    "import time\n",
    "import gc\n",
    "import datetime\n",
    "import optuna\n",
    "import zarr\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "if wandb.run is not None:\n",
    "    wandb.run.tags = list(wandb.run.tags) + [\"junk\"]\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78649825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maild\\AppData\\Local\\Temp\\ipykernel_7740\\703347769.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(cache_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from cache!\n",
      "Train Size 6202\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Import and cache dataset for fast loading in future\n",
    "'''\n",
    "\n",
    "# file_path = \"C:/Users/maild/mldrivenpeled/data/channel_measurements/zarr_files/channel_3e5-15MHz_3.5V_scale2.zarr\"\n",
    "file_path = \"C:/Users/maild/mldrivenpeled/data/channel_measurements/zarr_files/channel_3e5-15MHz_2.8V_scale2_v2.zarr\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\") # for M chip Macs\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Device\", device)\n",
    "\n",
    "cache_path = file_path.replace(\".zarr\", \"_cached.pt\").replace(\".h5\", \"_cached.pt\")\n",
    "if os.path.exists(cache_path):\n",
    "    data = torch.load(cache_path, map_location=device)\n",
    "    sent_frames_time = data[\"sent_frames_time\"].to(device)\n",
    "    received_frames_time = data[\"received_frames_time\"].to(device)\n",
    "    FREQUENCIES = data[\"frequencies\"].to(device)\n",
    "    NUM_POINTS_SYMBOL = data[\"NUM_POINTS_SYMBOL\"]\n",
    "    CP_LENGTH = data[\"CP_LENGTH\"]\n",
    "    delta_f = FREQUENCIES[1] - FREQUENCIES[0]\n",
    "    KS = (FREQUENCIES / delta_f).to(torch.int)\n",
    "    K_MIN = int(KS[0].item())\n",
    "    K_MAX = int(KS[-1].item())\n",
    "    NUM_ZEROS = K_MIN - 1\n",
    "    CP_RATIO = 0.25 # Known from experiment\n",
    "    NUM_POINTS_FRAME = NUM_POINTS_SYMBOL - CP_LENGTH\n",
    "    NUM_POS_FREQS_LOW_BAND = K_MAX + 1\n",
    "    UPSAMPLING_ZEROS = (NUM_POINTS_FRAME  - 2 * NUM_POS_FREQS_LOW_BAND) // 2\n",
    "    print(\"Loaded from cache!\")\n",
    "\n",
    "else:\n",
    "    print(\"No cache found — loading original dataset...\")\n",
    "\n",
    "\n",
    "        # Open the Zarr root\n",
    "    root = zarr.open(file_path, mode=\"r\")\n",
    "\n",
    "    # Load metadata (attributes live under .attrs)\n",
    "    sent, received, received_time = [], [], []\n",
    "    # Loop through frames\n",
    "    num_skipped = 0\n",
    "    for frame_key in root.group_keys():\n",
    "        try:\n",
    "            frame = root[frame_key]\n",
    "            if FREQUENCIES is None:\n",
    "                FREQUENCIES = torch.tensor(frame[\"freqs\"][:], dtype=torch.int).real\n",
    "                NUM_POINTS_SYMBOL = int(frame.attrs[\"num_points_symbol\"])\n",
    "                CP_LENGTH = int(frame.attrs[\"cp_length\"])\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            sent.append(torch.tensor(frame[\"sent\"][:], dtype=torch.complex64))\n",
    "            received.append(torch.tensor(frame[\"received\"][:], dtype=torch.complex64))\n",
    "            if \"received_time\" in frame:\n",
    "                received_time.append(torch.tensor(frame[\"received_time\"][:], dtype=torch.float32))\n",
    "        except:\n",
    "            num_skipped += 1\n",
    "            pass # skip corrupted frames\n",
    "    print(f\"Skipped {num_skipped} corrupted frames\")\n",
    "\n",
    "\n",
    "    sent_frames = torch.stack(sent).squeeze(1)\n",
    "    received_frames = torch.stack(received).squeeze(1)\n",
    "\n",
    "    # Establish globals\n",
    "    delta_f = FREQUENCIES[1] - FREQUENCIES[0]\n",
    "    KS = (FREQUENCIES / delta_f).to(torch.int)\n",
    "    K_MIN = int(KS[0].item())\n",
    "    K_MAX = int(KS[-1].item())\n",
    "    NUM_ZEROS = K_MIN - 1\n",
    "    CP_RATIO = 0.25\n",
    "    NUM_POINTS_FRAME = NUM_POINTS_SYMBOL - CP_LENGTH\n",
    "    NUM_POS_FREQS_LOW_BAND = K_MAX + 1\n",
    "    UPSAMPLING_ZEROS = (NUM_POINTS_FRAME  - 2 * NUM_POS_FREQS_LOW_BAND) // 2\n",
    "\n",
    "\n",
    "    def symbols_to_time(X, num_padding_zeros: int, num_leading_zeros=0):\n",
    "        'Convert OFDM symbols to real valued signal'\n",
    "        # Make hermetian symmetric\n",
    "        Nt, Nf = X.shape\n",
    "        padding_zeros = torch.zeros(Nt, num_padding_zeros, device=device)\n",
    "        leading_zeros = torch.zeros(Nt, num_leading_zeros, device=device)\n",
    "        X = torch.cat([leading_zeros, X.to(device), padding_zeros], dim=-1)\n",
    "        DC_Nyquist = torch.zeros((X.shape[0], 1), device=X.device)\n",
    "        X_hermitian = torch.flip(X, dims=[1]).conj()\n",
    "        X_full = torch.hstack([DC_Nyquist, X, DC_Nyquist, X_hermitian])\n",
    "\n",
    "        # Convert to time domain\n",
    "        x_time = torch.fft.ifft(X_full, dim=-1, norm=\"ortho\").real\n",
    "        return x_time.to(device)\n",
    "\n",
    "\n",
    "\n",
    "    sent_frames_time = symbols_to_time(sent_frames, UPSAMPLING_ZEROS, NUM_ZEROS)\n",
    "    # Add cyclic prefix\n",
    "    sent_frames_time = torch.hstack((sent_frames_time[:, -CP_LENGTH:], sent_frames_time))\n",
    "\n",
    "    # Handle received time symbols; perform some cleaning if necessary\n",
    "    N_shortest = min(t.size(-1) for t in received_time)\n",
    "    N_longest = max(t.size(-1) for t in received_time)\n",
    "    good_indices = [i for i, x in enumerate(received_time) if x.size(-1) == N_shortest]\n",
    "    received_frames_time = torch.stack([t for t in received_time if t.size(-1) == N_shortest], dim=0).real\n",
    "    sent_frames = sent_frames[good_indices]\n",
    "    received_frames_time = received_frames_time.squeeze(1)\n",
    "\n",
    "\n",
    "\n",
    "    DELAY_TIME = 0 # If for some reason there is a global delay with measure data adjust here\n",
    "    if DELAY_TIME > 0:\n",
    "        sent_frames_time = sent_frames_time[:, :-DELAY_TIME]\n",
    "    received_frames_time = received_frames_time[:, DELAY_TIME:]\n",
    "    received_frames_time = received_frames_time - received_frames_time.mean(dim=1, keepdim=True) # Always zero mean\n",
    "    sent_frames_time = sent_frames_time.to(device)\n",
    "    received_frames_time = received_frames_time.to(device)\n",
    "\n",
    "\n",
    "    # Create a cache path\n",
    "    cache_path = file_path.replace(\".zarr\", \"_cached.pt\").replace(\".h5\", \"_cached.pt\")\n",
    "\n",
    "    torch.save({\n",
    "        \"sent_frames_time\": sent_frames_time.cpu(),\n",
    "        \"received_frames_time\": received_frames_time.cpu(),\n",
    "        \"frequencies\": FREQUENCIES.cpu(),\n",
    "        \"NUM_POINTS_SYMBOL\": NUM_POINTS_SYMBOL,\n",
    "        \"CP_LENGTH\": CP_LENGTH\n",
    "    }, cache_path)\n",
    "\n",
    "\n",
    "class ChannelData(Dataset):\n",
    "    def __init__(self,\n",
    "                sent_frames,\n",
    "                received_frames,\n",
    "                frequencies,\n",
    "                transform=None,\n",
    "                target_transform=None):\n",
    "\n",
    "        self.sent_frames = sent_frames\n",
    "        self.received_frames = received_frames\n",
    "        assert len(sent_frames) == len(received_frames)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sent_frames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sent_frames[idx], self.received_frames[idx]\n",
    "\n",
    "\n",
    "dataset = ChannelData(sent_frames_time, received_frames_time, FREQUENCIES)\n",
    "\n",
    "# Split sizes\n",
    "train_size = int(0.9 * len(dataset))\n",
    "\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size  # ensures total = 100%\n",
    "\n",
    "# Perform split\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset,\n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator()\n",
    ")\n",
    "print(\"Train Size\", train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7642d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation=dilation,\n",
    "            padding=0\n",
    "        )\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        self.relu = nn.ReLU()\n",
    "        self.resample = None\n",
    "        if in_channels != out_channels:\n",
    "            self.resample = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.pad(x, (self.padding, 0))\n",
    "        out = self.conv(out)\n",
    "        out = self.relu(out)\n",
    "        if self.resample:\n",
    "            x = self.resample(x)\n",
    "        return out + x # residual connection\n",
    "\n",
    "\n",
    "def sample_student_t_mps(mean, std, nu):\n",
    "    '''\n",
    "    Wilson-Hilferty Approximation for chi^2 converted to scaled and shifted student t\n",
    "    '''\n",
    "    z = torch.randn_like(mean)\n",
    "    z_chi = torch.randn_like(mean)\n",
    "    chi2_approx = nu * (1 - 2/(9*nu) + z_chi * torch.sqrt(2/(9*nu))).pow(3)\n",
    "    scale = torch.sqrt(nu / (chi2_approx + 1e-6))\n",
    "    return mean + std * z * scale\n",
    "\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, nlayers=3, dilation_base=2, num_taps=10, hidden_channels=32):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "        for i in range(nlayers):\n",
    "            dilation = dilation_base ** i\n",
    "            layers.append(\n",
    "                TCNBlock(in_channels, hidden_channels, num_taps, dilation)\n",
    "            )\n",
    "            in_channels = hidden_channels\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.readout = nn.Conv1d(hidden_channels, 1, kernel_size=1)\n",
    "\n",
    "        # Calculate the total receptive field for the whole TCN stack\n",
    "        self.receptive_field = 1\n",
    "        for i in range(nlayers):\n",
    "            dilation = dilation_base ** i\n",
    "            self.receptive_field += (num_taps - 1) * dilation\n",
    "\n",
    "    def forward(self, xin):\n",
    "        x = xin.unsqueeze(1)    # [B,1,T]\n",
    "        out = self.tcn(x)     # [B,H,T]\n",
    "        out = self.readout(out).squeeze(1)\n",
    "        out = out - out.mean(dim=1, keepdim=True)  # [B,T]\n",
    "        return out\n",
    "    \n",
    "\n",
    "class TCN_channel(nn.Module):\n",
    "    def __init__(self, nlayers=3, dilation_base=2, num_taps=10,\n",
    "                 hidden_channels=32, learn_noise=False, gaussian=True):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "        for i in range(nlayers):\n",
    "            dilation = dilation_base ** i\n",
    "            layers.append(\n",
    "                TCNBlock(in_channels, hidden_channels, num_taps, dilation)\n",
    "            )\n",
    "            in_channels = hidden_channels\n",
    "        self.learn_noise = learn_noise\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        if gaussian:\n",
    "            self.readout = nn.Conv1d(hidden_channels, 2, kernel_size=1) # 2 channels mean | std\n",
    "        else:\n",
    "            self.readout = nn.Conv1d(hidden_channels, 3, kernel_size=1) # 3 channels mean | std | nu\n",
    "        self.num_taps = num_taps\n",
    "        self.gaussian = gaussian\n",
    "\n",
    "        self.ar_tap = nn.Parameter(torch.tensor(0.0))\n",
    "        self.input_tap = nn.Parameter(torch.tensor(0.0))\n",
    "        self.cross_tap = nn.Parameter(torch.tensor(0.0))\n",
    "        self.cross_tap_2 = nn.Parameter(torch.tensor(0.0))\n",
    "        self.cross_tap_3 = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "        if not gaussian:\n",
    "            with torch.no_grad():\n",
    "                # Initialize nu bias towards Gaussian for stability\n",
    "                self.readout.bias[2].fill_(48)\n",
    "\n",
    "    def forward(self, xin):\n",
    "        x = xin.unsqueeze(1)    # [B,1,T]\n",
    "        out = self.tcn(x)     # [B,H,T]\n",
    "        out = self.readout(out) # [B, 3, T] mean | std | nu\n",
    "        mean_out = out[:, 0, :]\n",
    "        log_std_out = out[:, 1, :]\n",
    "        std_out = torch.exp(log_std_out)\n",
    "        if not self.gaussian:\n",
    "            log_nu_out = out[:, 2, :]\n",
    "            nu_out = torch.nn.functional.softplus(log_nu_out)\n",
    "            nu_out = torch.clamp(nu_out, 2, 50) # nu between 2 and 50\n",
    "        mean_out = mean_out - mean_out.mean(dim=1, keepdim=True)  # [B ,T]\n",
    "\n",
    "        # # Produce noisy output\n",
    "        if self.gaussian:\n",
    "            z = torch.randn_like(mean_out)\n",
    "            noisy_out = mean_out + std_out * z\n",
    "            nu_out = torch.zeros_like(mean_out)\n",
    "        else:\n",
    "            noisy_out = sample_student_t_mps(mean_out, std_out, nu_out)\n",
    "            \n",
    "        if self.learn_noise:\n",
    "            return noisy_out, mean_out, std_out, nu_out\n",
    "        else:\n",
    "            return mean_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5195d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, loop):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    batch_count = 0\n",
    "    thetas = []\n",
    "    for batch in loop:\n",
    "        x, y = batch[0], batch[1]\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        noisy_y_pred, y_pred, y_pred_std, y_pred_nu = model(x)\n",
    "\n",
    "        # calculate residual\n",
    "        r = y - y_pred\n",
    "\n",
    "        if model.learn_noise:\n",
    "            if model.gaussian:\n",
    "                loss = loss_fn(r, y_pred_std)\n",
    "            else:\n",
    "                loss = loss_fn(r, y_pred_std, y_pred_nu)\n",
    "        else:\n",
    "            loss = loss_fn(y, y_pred)\n",
    "\n",
    "        mse_loss = F.mse_loss(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        wandb.log({\"nnl_train_loss\": loss.item()})\n",
    "        wandb.log({\"mse_train_loss\": mse_loss.item()})\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        wandb.log({\"learning_rate\": lr})\n",
    "        batch_count += 1\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    loop.close()\n",
    "\n",
    "\n",
    "def val(model, loss_fn, val_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    batch_count = 0\n",
    "    y_preds = []\n",
    "    std_preds = []\n",
    "    nu_preds = []\n",
    "    true_ys = []\n",
    "    noisy_ys = []\n",
    "    val_mse_loss = 0\n",
    "    nrmse_pct_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            noisy_y, mean_y, std_y, nu_y = model(x)\n",
    "            y_preds.append(mean_y)\n",
    "            std_preds.append(std_y)\n",
    "            nu_preds.append(nu_y)\n",
    "            true_ys.append(y)\n",
    "            noisy_ys.append(noisy_y)\n",
    "            if model.learn_noise:\n",
    "                if model.gaussian:\n",
    "                    loss = loss_fn(y - mean_y, std_y) # Use mean for validation\n",
    "                else:\n",
    "                    loss = loss_fn(y - mean_y, std_y, nu_y) # Use mean for validation\n",
    "            else:\n",
    "                loss = loss_fn(y, mean_y)\n",
    "            r = y - mean_y\n",
    "            mse_loss = F.mse_loss(y, mean_y)\n",
    "            nrmse_pct_loss += (torch.sqrt(torch.mean(r ** 2) / torch.mean(y ** 2)) * 100).item()\n",
    "            val_mse_loss += mse_loss.item()\n",
    "            val_loss += loss.item()\n",
    "            batch_count += 1\n",
    "    avg_val_loss = (val_loss / batch_count)\n",
    "    avg_val_mse_loss = (val_mse_loss / batch_count)\n",
    "    avg_nrmse_pct_loss = (nrmse_pct_loss / batch_count)\n",
    "\n",
    "    y_preds = torch.vstack(y_preds)\n",
    "    std_preds = torch.vstack(std_preds)\n",
    "    nu_preds = torch.vstack(nu_preds)\n",
    "    true_ys = torch.vstack(true_ys)\n",
    "    noisy_ys = torch.vstack(noisy_ys)\n",
    "\n",
    "\n",
    "    noise_pred = noisy_ys - y_preds\n",
    "    noise_power_pred_k = torch.fft.fft(noise_pred[:, CP_LENGTH:], norm='ortho', dim=-1).abs().square().mean(dim=0)\n",
    "    signal_power_model = torch.fft.fft(y_preds[:, CP_LENGTH:], norm='ortho', dim=-1).abs().square().mean(dim=0)\n",
    "    snr_k_model = (signal_power_model / (noise_power_pred_k + 1e-8))\n",
    "    sample_rate = delta_f * NUM_POINTS_FRAME\n",
    "    snr_mag_model = 10 * torch.log10(torch.abs(snr_k_model) + 1e-8)\n",
    "    freqs = torch.fft.fftfreq(len(snr_mag_model), d=1/sample_rate)\n",
    "    half = len(freqs)//2\n",
    "    freqs = freqs[:half]\n",
    "    snr_mag_model = snr_mag_model[:half]\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.plot(freqs, snr_mag_model.cpu(), lw=1.5, color=\"orange\")\n",
    "    ax.set_title(\"SNR vs Frequency (Model)\", fontsize=11)\n",
    "    ax.set_xlabel(\"Frequency\", fontsize=9)\n",
    "    ax.set_ylabel(\"SNR Magnitude (dB)\", fontsize=9)\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    # # ---- Log to WandB ----\n",
    "    wandb.log({\"SNR_Frequency\": wandb.Image(fig)})\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "    # Log both scalar and histogram\n",
    "    wandb.log({\n",
    "        'val_nll_loss': avg_val_loss,\n",
    "        \"avg_val_mse_loss\": avg_val_mse_loss,\n",
    "        \"avg_nrmse_pct_loss\": avg_nrmse_pct_loss\n",
    "    })\n",
    "\n",
    "    # print(f\"Average Val Loss: {avg_val_loss:.2e}\")\n",
    "\n",
    "    # visualize_std(model, x[:, :200])\n",
    "    return avg_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d961ced8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\maild\\mldrivenpeled\\notebooks\\wandb\\run-20251204_170629-tx4ofcbb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/tx4ofcbb' target=\"_blank\">sleek-violet-7785</a></strong> to <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/tx4ofcbb' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/tx4ofcbb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run info:\n",
      "  Name: sleek-violet-7785\n",
      "  ID: tx4ofcbb\n",
      "  URL: https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/tx4ofcbb\n",
      "Chosen hyperparameters for this session:\n",
      "{'CP_ratio': 0.25, 'batch_size': 16, 'num_taps': 10, 'epochs': 10, 'gain': 20, 'lr': 0.001, 'nlayers': 2, 'hidden_channels': 8, 'dilation_base': 2, 'num_points_symbol': 4000, 'learn_noise': True, 'num_symbols_per_frame': 1, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'gaussian': False, 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'wd_channel': '1e-3', 'wd_noise': '1e-3', 'wd_joint': '1e-4', 'training_schedule': [{'epochs': 10, 'mode': 'channel_only'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [channel_only]: 100%|██████████| 388/388 [00:04<00:00, 96.19it/s, loss=-3.4]  \n",
      "Epoch 2 [channel_only]: 100%|██████████| 388/388 [00:03<00:00, 112.05it/s, loss=-3.46]\n",
      "Epoch 3 [channel_only]: 100%|██████████| 388/388 [00:03<00:00, 117.46it/s, loss=-3.49]\n",
      "Epoch 4 [channel_only]: 100%|██████████| 388/388 [00:03<00:00, 110.58it/s, loss=-3.5] \n",
      "Epoch 5 [channel_only]: 100%|██████████| 388/388 [00:03<00:00, 101.75it/s, loss=-3.51]\n",
      "Epoch 6 [channel_only]: 100%|██████████| 388/388 [00:03<00:00, 105.42it/s, loss=-3.5] \n",
      "Epoch 7 [channel_only]: 100%|██████████| 388/388 [00:03<00:00, 108.88it/s, loss=-3.53]\n",
      "Epoch 8 [channel_only]: 100%|██████████| 388/388 [00:03<00:00, 106.67it/s, loss=-3.52]\n",
      "Epoch 9 [channel_only]: 100%|██████████| 388/388 [00:03<00:00, 106.33it/s, loss=-3.52]\n",
      "Epoch 10 [channel_only]: 100%|██████████| 388/388 [00:03<00:00, 107.21it/s, loss=-3.51]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_nrmse_pct_loss</td><td>█▄▃▃▁▁▁▂▂▁</td></tr><tr><td>avg_val_mse_loss</td><td>█▄▃▃▁▁▁▂▂▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mse_train_loss</td><td>▄▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>nnl_train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_nll_loss</td><td>█▅▄▄▃▃▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_nrmse_pct_loss</td><td>12.1868</td></tr><tr><td>avg_val_mse_loss</td><td>5e-05</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>mse_train_loss</td><td>5e-05</td></tr><tr><td>nnl_train_loss</td><td>-3.50941</td></tr><tr><td>val_nll_loss</td><td>-3.51894</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sleek-violet-7785</strong> at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/tx4ofcbb' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/tx4ofcbb</a><br> View project at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a><br>Synced 5 W&B file(s), 10 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251204_170629-tx4ofcbb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def students_t_loss(difference, y_pred_std, y_pred_nu):\n",
    "    # nu = y_pred_nu.clamp_min(2.0)\n",
    "    nu = y_pred_nu\n",
    "    z_resid = (difference) / (y_pred_std)\n",
    "    term1 = -1 * torch.lgamma((nu + 1) / 2) + 0.5 * torch.log(torch.pi * nu) + torch.lgamma(nu / 2) + torch.log(y_pred_std + 1e-8)\n",
    "    term2 = ((nu + 1) / 2) * torch.log(1 + (1 / nu) * torch.square(z_resid) + 1e-8)\n",
    "    loss = torch.mean(term1 + term2)\n",
    "    if torch.isnan(loss):\n",
    "        raise ValueError(\"NaN in loss\")\n",
    "    return loss\n",
    "\n",
    "def gaussian_nll(difference, y_pred_std):\n",
    "    term1 = 0.5 * torch.log(2 * torch.pi * (y_pred_std ** 2))\n",
    "    term2 = 0.5 * torch.square((difference) / y_pred_std)\n",
    "    loss = torch.mean(term1 + term2)\n",
    "    if torch.isnan(loss):\n",
    "        raise ValueError(\"NaN in loss\")\n",
    "    return loss\n",
    "\n",
    "noise_model = None\n",
    "\n",
    "def make_optimizer(mode):\n",
    "    if mode == \"channel_only\":\n",
    "        return optim.AdamW(\n",
    "            list(channel_model.parameters()),\n",
    "            lr=float(config.lr_channel),\n",
    "            weight_decay=float(config.wd_channel)\n",
    "        )\n",
    "\n",
    "    elif mode == \"noise_only\":\n",
    "        return optim.AdamW(\n",
    "            list(noise_model.parameters()),\n",
    "            lr=float(config.lr_noise),\n",
    "            weight_decay=float(config.wd_noise)\n",
    "        )\n",
    "\n",
    "    elif mode == \"joint\":\n",
    "        return optim.AdamW(\n",
    "            list(channel_model.parameters()) +\n",
    "            list(noise_model.parameters()),\n",
    "            lr=float(config.lr_joint),\n",
    "            weight_decay=float(config.wd_joint)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unknown mode\")\n",
    "\n",
    "\n",
    "script_dir = os.getcwd()\n",
    "config_path = os.path.join(script_dir, \"..\", \"offline_time_channel_config.yml\")\n",
    "with open(config_path, \"r\") as f:\n",
    "    hyperparams = yaml.safe_load(f)\n",
    "\n",
    "# Start Weights and Biases session\n",
    "wandb.init(project=\"mldrivenpeled\",\n",
    "           config=hyperparams, tags=['channel_model'])\n",
    "config = wandb.config\n",
    "\n",
    "schedule = config.training_schedule\n",
    "\n",
    "\n",
    "RECEPTIVE_FIELD = (1 + (config.num_taps - 1) * (config.dilation_base**config.nlayers - 1) // (config.dilation_base - 1))\n",
    "\n",
    "\n",
    "print(f\"WandB run info:\")\n",
    "print(f\"  Name: {wandb.run.name}\")\n",
    "print(f\"  ID: {wandb.run.id}\")\n",
    "print(f\"  URL: {wandb.run.url}\")\n",
    "print(\"Chosen hyperparameters for this session:\")\n",
    "print(config)\n",
    "\n",
    "\n",
    "# Create dataloader\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=config.batch_size, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset)\n",
    "val_loader = DataLoader(val_dataset, shuffle=True, batch_size=config.batch_size, drop_last=False)\n",
    "\n",
    "\n",
    "channel_model = TCN_channel(\n",
    "    nlayers=config.nlayers,\n",
    "    dilation_base=config.dilation_base,\n",
    "    num_taps=config.num_taps,\n",
    "    hidden_channels=config.hidden_channels,\n",
    "    learn_noise=config.learn_noise,\n",
    "    gaussian=config.gaussian\n",
    ").to(device)\n",
    "\n",
    "initial_model_state = copy.deepcopy(channel_model.state_dict())\n",
    "\n",
    "if channel_model.gaussian:\n",
    "    loss_fn = gaussian_nll\n",
    "else:\n",
    "    loss_fn = students_t_loss\n",
    "\n",
    "# loss_fn = F.mse_loss\n",
    "\n",
    "num_epochs = config.epochs\n",
    "\n",
    "epoch_counter = 0\n",
    "for phase in schedule:\n",
    "    mode = phase[\"mode\"]\n",
    "    num_batches = None # if None, all batches run\n",
    "    if \"batches\" in phase:\n",
    "        num_batches = phase[\"batches\"]\n",
    "    num_phase_epochs = phase[\"epochs\"]\n",
    "\n",
    "\n",
    "    optimizer = make_optimizer(mode)\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1, min_lr=1e-6)\n",
    "\n",
    "    for local_epoch in range(num_phase_epochs):\n",
    "        epoch_counter += 1\n",
    "\n",
    "        loop = tqdm(train_loader, desc=f'Epoch {epoch_counter} [{mode}]')\n",
    "        train(channel_model,\n",
    "              optimizer,\n",
    "              loss_fn,\n",
    "              loop)\n",
    "\n",
    "        avg_val_loss = val(channel_model,\n",
    "                           loss_fn,\n",
    "                           val_loader)\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Trainable parameters: {count_parameters(channel_model):,}\")\n",
    "# Freeze model\n",
    "for param in channel_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Save model\n",
    "torch.save({\n",
    "    \"channel_model\": channel_model.state_dict(),\n",
    "}, \"channel_model_final.pth\")\n",
    "\n",
    "artifact = wandb.Artifact(\"channel_model\", type=\"model\")\n",
    "artifact.add_file(\"channel_model_final.pth\")\n",
    "wandb.log_artifact(artifact)\n",
    "print(\"Finished!\")\n",
    "run_name = wandb.run.name\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc6339c",
   "metadata": {},
   "source": [
    "### Memory Polynomial for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "931dde24",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Rename for convenience'''\n",
    "X = sent_frames_time.cpu().numpy()\n",
    "Y = received_frames_time.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d5d6036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE  % 13.434357\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def create_regressors(X, memory_linear, memory_nonlinear, nonlinearity_order):\n",
    "    B, T = X.shape\n",
    "    # pad data with longest memory\n",
    "    max_taps = max(memory_linear, memory_nonlinear) # memory here is strictly in the past (current time step not considered)\n",
    "    # Each example and target will get a matrix and column vector. All will be stacked\n",
    "    # to form a A with shape [NxT, memory_linear + memory_nonlinearxnonlinear_order] regressor matrix\n",
    "\n",
    "    batched_regressor_cols = []\n",
    "    num_regressors = memory_linear + (memory_nonlinear * (nonlinearity_order - 1)) + 2\n",
    "    regressor_length = T * B\n",
    "\n",
    "\n",
    "    for i in range(memory_linear + 1):\n",
    "        X_shifted = np.roll(X, i, axis=1)\n",
    "        X_shifted[:, :i] = 0.0\n",
    "        batched_regressor_cols.append(X_shifted)\n",
    "\n",
    "    for k in range(2, nonlinearity_order + 1):\n",
    "        for j in range(memory_nonlinear + 1):\n",
    "            X_shifted = np.roll(X, j, axis=1)\n",
    "            X_shifted[:, :j] = 0.0\n",
    "            batched_regressor_cols.append(np.power(X_shifted, k))\n",
    "\n",
    "    stack = np.array(batched_regressor_cols) # [features, B, T]\n",
    "    stack = stack.transpose(1, 2, 0) # [B, T, freatures]\n",
    "    A = stack.reshape(regressor_length, num_regressors)\n",
    "    return A\n",
    "\n",
    "def memory_polynomial(X, Y, memory_linear, memory_nonlinear, nonlinearity_order):\n",
    "    A = create_regressors(X, memory_linear, memory_nonlinear, nonlinearity_order)\n",
    "    Y_flat = Y.flatten()\n",
    "\n",
    "    weights, residuals, rank, s = np.linalg.lstsq(A, Y_flat, rcond=None)\n",
    "    # print(\"Solved Weights:\", weights)\n",
    "    y_pred = A @ weights\n",
    "    # Reshape back to (B, T) for analysis\n",
    "    B, T = X.shape\n",
    "    y_pred = y_pred.reshape(B, T)\n",
    "    residuals = Y - y_pred\n",
    "    return weights, y_pred, residuals\n",
    "\n",
    "    \n",
    "\n",
    "weights, y_pred, residuals = memory_polynomial(X, Y, memory_linear=10, memory_nonlinear=10, nonlinearity_order=2)\n",
    "\n",
    "\n",
    "# Calculate NRMSE\n",
    "signal_power = np.mean(np.square(Y))\n",
    "error_power = np.mean(np.square(residuals))\n",
    "\n",
    "nrmse_pct = np.sqrt(error_power / signal_power) * 100\n",
    "print(\"NRMSE  %\", nrmse_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a073e000",
   "metadata": {},
   "outputs": [],
   "source": [
    "class memory_polynomial_channel(nn.Module):\n",
    "    def __init__(self, weights):\n",
    "        super().__init__()\n",
    "        self.weights = torch.tensor(weights, device=device)\n",
    "\n",
    "        def _create_regressors(x):\n",
    "                B, T = X.shape\n",
    "        # pad data with longest memory\n",
    "        max_taps = max(memory_linear, memory_nonlinear) # memory here is strictly in the past (current time step not considered)\n",
    "        # Each example and target will get a matrix and column vector. All will be stacked\n",
    "        # to form a A with shape [NxT, memory_linear + memory_nonlinearxnonlinear_order] regressor matrix\n",
    "\n",
    "        batched_regressor_cols = []\n",
    "        num_regressors = memory_linear + (memory_nonlinear * (nonlinearity_order - 1)) + 2\n",
    "        regressor_length = T * B\n",
    "\n",
    "\n",
    "        for i in range(memory_linear + 1):\n",
    "            X_shifted = np.roll(X, i, axis=1)\n",
    "            X_shifted[:, :i] = 0.0\n",
    "            batched_regressor_cols.append(X_shifted)\n",
    "\n",
    "        for k in range(2, nonlinearity_order + 1):\n",
    "            for j in range(memory_nonlinear + 1):\n",
    "                X_shifted = np.roll(X, j, axis=1)\n",
    "                X_shifted[:, :j] = 0.0\n",
    "                batched_regressor_cols.append(np.power(X_shifted, k))\n",
    "\n",
    "        stack = np.array(batched_regressor_cols) # [features, B, T]\n",
    "        stack = stack.transpose(1, 2, 0) # [B, T, freatures]\n",
    "        A = stack.reshape(regressor_length, num_regressors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldrivenpeled",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
