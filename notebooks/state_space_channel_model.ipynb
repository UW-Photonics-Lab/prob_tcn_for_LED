{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54ebde2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mse_train_loss</td><td>█▇▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/mse_y</td><td>▁</td></tr><tr><td>val/snr_y_over_eps</td><td>▁</td></tr><tr><td>val/std_max</td><td>▁</td></tr><tr><td>val/std_mean</td><td>▁</td></tr><tr><td>val/std_min</td><td>▁</td></tr><tr><td>val/std_std</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>-1.48562</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>mse_train_loss</td><td>0.00064</td></tr><tr><td>val/mse_y</td><td>0.00196</td></tr><tr><td>val/snr_y_over_eps</td><td>4.17929</td></tr><tr><td>val/std_max</td><td>0.35603</td></tr><tr><td>val/std_mean</td><td>0.24794</td></tr><tr><td>val/std_min</td><td>0.22112</td></tr><tr><td>val/std_std</td><td>0.01522</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trim-sun-7387</strong> at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/2t3zo4cn' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/2t3zo4cn</a><br> View project at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a><br>Synced 5 W&B file(s), 49 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251126_211233-2t3zo4cn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import h5py\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.special import beta\n",
    "from torch.special import psi\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Subset\n",
    "import wandb\n",
    "import itertools\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import gc\n",
    "import datetime\n",
    "import optuna\n",
    "import zarr\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "if wandb.run is not None:\n",
    "    wandb.run.tags = list(wandb.run.tags) + [\"junk\"]\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be64339b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "3000\n",
      "Loaded from cache!\n",
      "Train Size 1801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maild\\AppData\\Local\\Temp\\ipykernel_29788\\2011889474.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(cache_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/wideband_twocarrier_3.1V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/wideband_single_carrier_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/wideband_2.83V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/time_channel_2.83V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_channel_2.83V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_channel_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/normalized_channel_2.83V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/single_X_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_wide_channel_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_wide_channel_3.5V_scale2.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_wide_channel_test_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_wide_channel_3.13V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_25MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_15MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_15MHz_3.5V_scale4.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_7.5MHz_3.5V_scale8.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_4MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_3e5-4MHz_3.5V_scale4.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/channel_3e5-4MHz_3.5V_scale2.zarr\"\n",
    "file_path = \"C:/Users/maild/mldrivenpeled/data/channel_measurements/zarr_files/test/channel_3e5-15MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/channel_3e5-15MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/channel_3e5-30MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_7.5MHz_3.5V_scale4.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_1e4-15MHz_3.5V_scale4.zarr\"\n",
    "\n",
    "# Set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\") # for M chip Macs\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "WIDE_BAND = False\n",
    "TIME_MODEL = True\n",
    "\n",
    "cache_path = file_path.replace(\".zarr\", \"_cached.pt\").replace(\".h5\", \"_cached.pt\")\n",
    "\n",
    "if os.path.exists(cache_path):\n",
    "    data = torch.load(cache_path, map_location=device)\n",
    "    sent_frames_time = data[\"sent_frames_time\"].to(device)\n",
    "    received_frames_time = data[\"received_frames_time\"].to(device)\n",
    "    FREQUENCIES = data[\"frequencies\"].to(device)\n",
    "    NUM_POINTS_SYMBOL = data[\"NUM_POINTS_SYMBOL\"]\n",
    "    CP_LENGTH = data[\"CP_LENGTH\"]\n",
    "    delta_f = FREQUENCIES[1] - FREQUENCIES[0]\n",
    "    KS = (FREQUENCIES / delta_f).to(torch.int)\n",
    "    K_MIN = int(KS[0].item())\n",
    "    K_MAX = int(KS[-1].item())\n",
    "    NUM_ZEROS = K_MIN - 1\n",
    "    CP_RATIO = 0.25\n",
    "    NUM_POINTS_FRAME = NUM_POINTS_SYMBOL - CP_LENGTH\n",
    "    NUM_POS_FREQS_LOW_BAND = K_MAX + 1\n",
    "    print(NUM_POINTS_FRAME  - 2 * NUM_POS_FREQS_LOW_BAND)\n",
    "    UPSAMPLING_ZEROS = (NUM_POINTS_FRAME  - 2 * NUM_POS_FREQS_LOW_BAND) // 2\n",
    "\n",
    "    print(\"Loaded from cache!\")\n",
    "else:\n",
    "    print(\"No cache found — loading original dataset...\")\n",
    "\n",
    "    H5 = False\n",
    "    FREQUENCIES = None\n",
    "    if H5:\n",
    "        # Extract all frame data\n",
    "        DTYPE = torch.complex64\n",
    "        sent = []\n",
    "        received = []\n",
    "        received_time = []\n",
    "        FREQUENCIES = None\n",
    "        with h5py.File(file_path, \"r\") as f:\n",
    "            # Get frequency\n",
    "            first_frame = list(f.keys())[-1]\n",
    "            FREQUENCIES = torch.tensor(f[first_frame]['freqs'][:], dtype=DTYPE).to(device).real\n",
    "            NUM_POINTS_SYMBOL = int(f[first_frame]['num_points_symbol'][()])\n",
    "            CP_LENGTH = int(f[first_frame]['cp_length'][()])\n",
    "            for frame in f:\n",
    "                group = f[frame]\n",
    "                sent.append(torch.tensor(group['sent'][:], dtype=DTYPE))\n",
    "                received.append(torch.tensor(group['received'][:], dtype=DTYPE))\n",
    "                received_time.append(torch.tensor(group['received_time'][:], dtype=DTYPE))\n",
    "    else:\n",
    "        # Open the Zarr root\n",
    "        root = zarr.open(file_path, mode=\"r\")\n",
    "\n",
    "        # Get first frame\n",
    "\n",
    "        # Load metadata (attributes live under .attrs)\n",
    "        sent, received, received_time = [], [], []\n",
    "\n",
    "        # Loop through frames\n",
    "        num_skipped = 0\n",
    "        for frame_key in root.group_keys():\n",
    "            try:\n",
    "                frame = root[frame_key]\n",
    "                if FREQUENCIES is None:\n",
    "                    FREQUENCIES = torch.tensor(frame[\"freqs\"][:], dtype=torch.int).real\n",
    "                    NUM_POINTS_SYMBOL = int(frame.attrs[\"num_points_symbol\"])\n",
    "                    CP_LENGTH = int(frame.attrs[\"cp_length\"])\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                sent.append(torch.tensor(frame[\"sent\"][:], dtype=torch.complex64))\n",
    "                received.append(torch.tensor(frame[\"received\"][:], dtype=torch.complex64))\n",
    "                if \"received_time\" in frame:\n",
    "                    received_time.append(torch.tensor(frame[\"received_time\"][:], dtype=torch.float32))\n",
    "            except:\n",
    "                num_skipped += 1\n",
    "                pass # skip corrupted frames\n",
    "    print(f\"Skipped {num_skipped} corrupted frames\")\n",
    "\n",
    "    sent_frames = torch.stack(sent).squeeze(1)\n",
    "    sent_frames_active = sent_frames\n",
    "    received_frames = torch.stack(received).squeeze(1)\n",
    "\n",
    "\n",
    "    delta_f = FREQUENCIES[1] - FREQUENCIES[0]\n",
    "    KS = (FREQUENCIES / delta_f).to(torch.int)\n",
    "    K_MIN = int(KS[0].item())\n",
    "    K_MAX = int(KS[-1].item())\n",
    "    NUM_ZEROS = K_MIN - 1\n",
    "    CP_RATIO = 0.25\n",
    "    NUM_POINTS_FRAME = NUM_POINTS_SYMBOL - CP_LENGTH\n",
    "    NUM_POS_FREQS_LOW_BAND = K_MAX + 1\n",
    "    UPSAMPLING_ZEROS = (NUM_POINTS_FRAME  - 2 * NUM_POS_FREQS_LOW_BAND) // 2\n",
    "\n",
    "\n",
    "    def symbols_to_time(X, num_padding_zeros: int, num_leading_zeros=0):\n",
    "        # Make hermetian symmetric\n",
    "        Nt, Nf = X.shape\n",
    "        padding_zeros = torch.zeros(Nt, num_padding_zeros, device=device)\n",
    "        leading_zeros = torch.zeros(Nt, num_leading_zeros, device=device)\n",
    "        X = torch.cat([leading_zeros, X.to(device), padding_zeros], dim=-1)\n",
    "        DC_Nyquist = torch.zeros((X.shape[0], 1), device=X.device)\n",
    "        X_hermitian = torch.flip(X, dims=[1]).conj()\n",
    "        X_full = torch.hstack([DC_Nyquist, X, DC_Nyquist, X_hermitian])\n",
    "\n",
    "        # Convert to time domain\n",
    "        x_time = torch.fft.ifft(X_full, dim=-1, norm=\"ortho\").real\n",
    "        return x_time.to(device)\n",
    "\n",
    "    if len(received_time) > 0:\n",
    "        N_shortest = min(t.size(-1) for t in received_time)\n",
    "        N_longest = max(t.size(-1) for t in received_time)\n",
    "        good_indices = [i for i, x in enumerate(received_time) if x.size(-1) == N_shortest]\n",
    "        received_frames_time = torch.stack([t for t in received_time if t.size(-1) == N_shortest], dim=0).real.squeeze(1)\n",
    "        sent_frames = sent_frames[good_indices]\n",
    "\n",
    "\n",
    "    sent_frames_time = symbols_to_time(sent_frames, UPSAMPLING_ZEROS, NUM_ZEROS)\n",
    "    # Add cyclic prefix\n",
    "    sent_frames_time = torch.hstack((sent_frames_time[:, -CP_LENGTH:], sent_frames_time))\n",
    "    received_frames_time = received_frames_time - received_frames_time.mean(dim=1, keepdim=True)\n",
    "\n",
    "\n",
    "\n",
    "    # enforce OSA causality\n",
    "    # sent_frames_time = sent_frames_time[:, :-1]\n",
    "    # received_frames_time_resampled = received_frames_time_resampled[:,  1:]\n",
    "    sent_frames_time = sent_frames_time.to(device)\n",
    "    received_frames_time = received_frames_time.to(device)\n",
    "\n",
    "    TRUNCATE_SIZE = slice(CP_LENGTH, CP_LENGTH + 100)\n",
    "    sent_frames_time = sent_frames_time[:, TRUNCATE_SIZE]\n",
    "    received_frames_time = received_frames_time[:, TRUNCATE_SIZE]\n",
    "\n",
    "    # Create a cache path\n",
    "    cache_path = file_path.replace(\".zarr\", \"_cached.pt\").replace(\".h5\", \"_cached.pt\")\n",
    "\n",
    "    torch.save({\n",
    "        \"sent_frames_time\": sent_frames_time.cpu(),\n",
    "        \"received_frames_time\": received_frames_time.cpu(),\n",
    "        \"frequencies\": FREQUENCIES.cpu(),\n",
    "        \"NUM_POINTS_SYMBOL\": NUM_POINTS_SYMBOL,\n",
    "        \"CP_LENGTH\": CP_LENGTH\n",
    "    }, cache_path)\n",
    "\n",
    "class ChannelData(Dataset):\n",
    "        def __init__(self,\n",
    "                    sent_frames,\n",
    "                    received_frames,\n",
    "                    frequencies,\n",
    "                    transform=None,\n",
    "                    target_transform=None):\n",
    "\n",
    "            self.sent_frames = sent_frames\n",
    "            self.received_frames = received_frames\n",
    "            assert len(sent_frames) == len(received_frames)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.sent_frames)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.sent_frames[idx], self.received_frames[idx]\n",
    "\n",
    "if TIME_MODEL:\n",
    "    dataset = ChannelData(sent_frames_time, received_frames_time, FREQUENCIES)\n",
    "else:\n",
    "    dataset = ChannelData(sent_frames, received_frames, FREQUENCIES)\n",
    "\n",
    "# Split sizes\n",
    "train_size = int(0.9 * len(dataset))\n",
    "\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size  # ensures total = 100%\n",
    "\n",
    "# Perform split\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset,\n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator()\n",
    ")\n",
    "print(\"Train Size\", train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "472a6855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,) (100,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak lag: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x248b24397d0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = sent_frames_time[100].cpu().numpy()\n",
    "r = received_frames_time[100].cpu().numpy()\n",
    "\n",
    "print(s.shape, r.shape)\n",
    "corr = np.correlate(s, r, mode='full')\n",
    "T = len(s)\n",
    "zero_lag_index = T - 1\n",
    "\n",
    "lags = np.arange(-T + 1, T)  # lag axis\n",
    "plt.plot(lags, corr)\n",
    "plt.axvline(0, color='k', linestyle='--')\n",
    "plt.xlabel('Lag (samples)')\n",
    "plt.ylabel('Cross-correlation amplitude')\n",
    "plt.title('Sent vs Received Cross-Correlation (Frame 0)')\n",
    "plt.show()\n",
    "\n",
    "# Find best alignment\n",
    "best_lag = lags[np.argmax(corr)]\n",
    "print(\"Peak lag:\", best_lag)\n",
    "\n",
    "window = 4\n",
    "lags = np.arange(-window, window + 1)\n",
    "plt.plot(lags, corr[zero_lag_index - window:zero_lag_index + window + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8188201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_last_layer(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.zeros_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "class StateSpaceModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 deterministic_num_taps,\n",
    "                 deterministic_state_size,\n",
    "                 deterministic_hidden_size,\n",
    "                 stochastic_state_size,\n",
    "                 stochastic_hidden_size\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.deterministic_state_size = deterministic_state_size\n",
    "        self.stochastic_state_size = stochastic_state_size\n",
    "        self.deterministic_num_taps = deterministic_num_taps\n",
    "        self.deterministic_state_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(deterministic_hidden_size, deterministic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(deterministic_hidden_size, deterministic_state_size)\n",
    "        )\n",
    "        self.deterministic_out_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(deterministic_hidden_size, 1) # Predict next scalar ouptut\n",
    "        )\n",
    "        self.stochastic_state_map = nn.Sequential(\n",
    "            nn.Linear(stochastic_state_size + deterministic_num_taps + 1, stochastic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(stochastic_hidden_size, stochastic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(stochastic_hidden_size, stochastic_state_size)\n",
    "        )\n",
    "        self.stochastic_out_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + stochastic_state_size + deterministic_state_size, stochastic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(stochastic_hidden_size, 1)\n",
    "        )\n",
    "        self.linear_det_out_map = nn.Linear(deterministic_num_taps + deterministic_state_size, 1)\n",
    "        self.linear_det_state_map = nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_state_size)\n",
    "        self.linear_stoch_state_map = nn.Linear(stochastic_state_size + deterministic_num_taps + 1, stochastic_state_size)\n",
    "        self.linear_stoch_out_map = nn.Linear(deterministic_num_taps + stochastic_state_size + deterministic_state_size, 1)\n",
    "\n",
    "        self.n0 = nn.Parameter(torch.zeros(deterministic_state_size))\n",
    "        self.z0 = nn.Parameter(torch.zeros(stochastic_state_size))\n",
    "\n",
    "        # Make it so that the stochastic output starts at zero\n",
    "        self.deterministic_state_map[-1].apply(zero_last_layer)\n",
    "        self.deterministic_out_map[-1].apply(zero_last_layer)\n",
    "        self.stochastic_state_map[-1].apply(zero_last_layer)\n",
    "        self.stochastic_out_map[-1].apply(zero_last_layer)\n",
    "        self.mode = \"nonlinear\"\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        mode = self.mode\n",
    "        device = x.device\n",
    "        y_pred = torch.zeros_like(x, device=device)\n",
    "        e_pred = torch.zeros_like(x, device=device)\n",
    "        T = x.size(-1)\n",
    "        B = x.size(0)\n",
    "        # n_t = torch.zeros(B, self.deterministic_state_size, device=device)\n",
    "        # z_t = torch.zeros(B, self.stochastic_state_size, device=device)\n",
    "        n_t = self.n0.unsqueeze(0).expand(B, -1)  # [B, nx]\n",
    "        z_t = self.z0.unsqueeze(0).expand(B, -1)  # [B, nz]\n",
    "        # add zeros in front equal to num_taps - 1\n",
    "        x = torch.cat([torch.zeros(B, self.deterministic_num_taps - 1, device=device), x], dim=-1)\n",
    "        for t in range(T):\n",
    "            x_t = x[:, t: t + self.deterministic_num_taps]\n",
    "\n",
    "            if mode == \"linear\":\n",
    "                y_t_pred = self.linear_det_out_map(torch.cat([x_t, n_t], dim=-1))\n",
    "            else:\n",
    "                y_t_pred = self.deterministic_out_map(torch.cat([x_t, n_t], dim=-1)) + self.linear_det_out_map(torch.cat([x_t, n_t], dim=-1))\n",
    "\n",
    "            if y is None:\n",
    "                '''INFERENCE MODE'''\n",
    "                y_pred[:, t] = y_t_pred.squeeze(-1)\n",
    "                # Assume residuals are an innovation process with zero mean\n",
    "                if mode == \"linear\":\n",
    "                    n_t = n_t + self.linear_det_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "                else:\n",
    "                    n_t = n_t + self.deterministic_state_map(torch.cat([x_t, n_t], dim=-1)) + self.linear_det_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "\n",
    "            else:\n",
    "                '''TRAINING MODE'''\n",
    "                # Training mode\n",
    "                y_t = y[:, t]\n",
    "                r_t = y_t.unsqueeze(-1) - y_t_pred\n",
    "\n",
    "                if mode == \"linear\":\n",
    "                    nonlinear_noise_t = self.linear_stoch_out_map(torch.cat([x_t, n_t, z_t], dim=-1))\n",
    "                else:\n",
    "                    nonlinear_noise_t = self.stochastic_out_map(torch.cat([x_t, n_t, z_t], dim=-1)) + self.linear_stoch_out_map(torch.cat([x_t, n_t, z_t], dim=-1))\n",
    "                y_t_next_pred = y_t_pred + nonlinear_noise_t\n",
    "                y_pred[:, t] = y_t_next_pred.squeeze(-1)\n",
    "                e_t = r_t - nonlinear_noise_t\n",
    "                e_pred[:, t] = e_t.squeeze(-1)\n",
    "                # Make state updates\n",
    "\n",
    "                if mode == \"linear\":\n",
    "                    z_t = z_t + self.linear_stoch_state_map(torch.cat([x_t, z_t, r_t], dim=-1))\n",
    "                    n_t = n_t + self.linear_det_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "                else:\n",
    "                    z_t = z_t + self.stochastic_state_map(torch.cat([x_t, z_t, r_t], dim=-1)) + self.linear_stoch_state_map(torch.cat([x_t, z_t, r_t], dim=-1))\n",
    "                    n_t = n_t + self.deterministic_state_map(torch.cat([x_t, n_t], dim=-1)) + self.linear_det_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "        return y_pred, e_pred\n",
    "\n",
    "class ProbabilisticStateSpaceModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_taps,\n",
    "                 state_size,\n",
    "                 hidden_size,\n",
    "                 ar_taps\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.state_size = state_size\n",
    "        self.num_taps = num_taps\n",
    "        def sn_linear(in_f, out_f):\n",
    "            return nn.utils.spectral_norm(nn.Linear(in_f, out_f))\n",
    "        self.state_map = nn.Sequential(\n",
    "            nn.Linear(num_taps + state_size, hidden_size),\n",
    "            # sn_linear(num_taps + state_size, hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            # sn_linear(hidden_size, hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, state_size)\n",
    "        )\n",
    "        self.state_out_map = nn.Sequential(\n",
    "            nn.Linear(num_taps + state_size, hidden_size),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, 2) # Predict mean and std\n",
    "        )\n",
    "        # self.linear_det_out_map = nn.Linear(deterministic_num_taps + deterministic_state_size, 2 + ar_taps)\n",
    "        # self.linear_det_state_map = nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_state_size)\n",
    "        self.fast_feedthrough = nn.Linear(num_taps, 1, bias=False)\n",
    "        nn.init.zeros_(self.fast_feedthrough.weight)\n",
    "        self.n0 = nn.Parameter(torch.zeros(state_size))\n",
    "        self.alpha = nn.Parameter(torch.tensor(0.5))\n",
    "        # self.state_map[-1].apply(zero_last_layer)\n",
    "        # self.state_out_map[-1].apply(zero_last_layer)\n",
    "\n",
    "    \n",
    "    def _step(self, xt, nt):\n",
    "        inp = torch.cat([xt, nt], dim=-1)\n",
    "        out = self.state_out_map(inp)\n",
    "        y_pred = out[:, 0]\n",
    "        # y_pred = y_pred + y_fast\n",
    "        std_pred = F.softplus(out[:, 1]) + 1e-6\n",
    "        delta_n = self.state_map(inp)\n",
    "        alpha = torch.sigmoid(self.alpha)\n",
    "        nt_next = (1.0 - alpha) * nt  + delta_n\n",
    "        return y_pred, std_pred, nt_next\n",
    "\n",
    "    def forward_train(self, x, y):\n",
    "        device = x.device\n",
    "        T = x.size(-1)\n",
    "        B = x.size(0)\n",
    "        y_pred = torch.zeros(B, T, device=device)\n",
    "        std_pred = torch.zeros(B, T, device=device)\n",
    "        residuals = torch.zeros(B, T, device=device)\n",
    "        innovations = torch.zeros(B, T, device=device)\n",
    "        nt = self.n0.unsqueeze(0).repeat(B, 1).clone()  # [B, nx]\n",
    "        # add zeros in front equal to num_taps - 1\n",
    "        x = torch.cat([torch.zeros(B, self.num_taps - 1, device=device), x], dim=-1)\n",
    "\n",
    "        for t in range(T):\n",
    "            xt = x[:, t: t + self.num_taps]\n",
    "            y_pred_t, std_pred_t, nt = self._step(xt, nt)\n",
    "            y_pred[:, t] = y_pred_t\n",
    "\n",
    "            # get residuals\n",
    "            \n",
    "            # detach phi_t to invoid inplace gradient errors\n",
    "            # phi_t = phi_t.detach()\n",
    "            r_t = (y[:, t] - y_pred_t)\n",
    "            residuals[:, t] = r_t.detach()\n",
    "            std_pred[:, t] = std_pred_t\n",
    "\n",
    "\n",
    "            # max_lags = min(self.ar_taps, t)\n",
    "            # if max_lags > 0:\n",
    "            #     window = residuals[:, t - max_lags: t]\n",
    "            #     window = torch.flip(window, dims=[1])\n",
    "\n",
    "            #     phis = phi_t[:, :max_lags]\n",
    "            #     eps_t = r_t - (phis * window).sum(dim=-1)\n",
    "            # else:\n",
    "            #     eps_t = r_t\n",
    "            eps_t = r_t\n",
    "            innovations[:, t] = eps_t\n",
    "\n",
    "\n",
    "        return y_pred, std_pred, innovations\n",
    "    \n",
    "\n",
    "    def forward_simulate(self, x, eps=None):\n",
    "        device = x.device\n",
    "        T = x.size(-1)\n",
    "        B = x.size(0)\n",
    "        y_pred = torch.zeros(B, T, device=device)\n",
    "        if eps is None:\n",
    "            eps = torch.randn(B, T, device=device)\n",
    "        residuals = torch.zeros_like(x, device=device)\n",
    "        x = torch.cat([torch.zeros(B, self.num_taps - 1, device=device), x], dim=-1)\n",
    "        n_t = self.n0.unsqueeze(0).expand(B, -1)\n",
    "        for t in range(T):\n",
    "            xt = x[:, t: t + self.deterministic_num_taps]\n",
    "            y_pred_t, std_pred_t, n_t = self._step(xt, n_t)\n",
    "            ar_term = torch.zeros_like(y_pred_t)\n",
    "            for i in range(self.ar_taps):\n",
    "                lag = t - i - 1\n",
    "                if lag < 0:\n",
    "                    break\n",
    "            \n",
    "            r_t = std_pred_t * eps[:, t]\n",
    "            residuals[:, t] = r_t\n",
    "            y_pred[:, t] = y_pred_t + r_t\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "\n",
    "# class ProbabilisticStateSpaceModel(nn.Module):\n",
    "#     def __init__(self,\n",
    "#                  num_taps,\n",
    "#                  state_size,\n",
    "#                  hidden_size,\n",
    "#                  ar_taps\n",
    "#                  ):\n",
    "#         super().__init__()\n",
    "#         self.state_size = state_size\n",
    "#         self.deterministic_num_taps = num_taps\n",
    "        \n",
    "#         # --- LRU Parameters ---\n",
    "#         # 1. Eigenvalues lambda = exp(-nu + i*theta)\n",
    "#         # Initialize nu to ensure magnitudes are between 0 and 1 (stable)\n",
    "#         u_min, u_max = 0.0, 1.0\n",
    "#         rand_u = torch.rand(state_size) * (u_max - u_min) + u_min\n",
    "#         self.nu_log = nn.Parameter(torch.log(-torch.log(rand_u)))\n",
    "        \n",
    "#         # Initialize theta uniform on [0, 2pi]\n",
    "#         self.theta_log = nn.Parameter(torch.log(torch.rand(state_size) * 2 * np.pi))\n",
    "        \n",
    "#         # Gamma parameter (normalization factor, helps with gradient scaling)\n",
    "#         # Init to sqrt(1 - |lambda|^2) roughly\n",
    "#         self.gamma_log = nn.Parameter(torch.log(torch.ones(state_size) * np.sqrt(1 - 0.9**2)))\n",
    "        \n",
    "#         # 2. Input projections B (Complex)\n",
    "#         # Maps input (num_taps) -> State (state_size)\n",
    "#         self.B_re = nn.Linear(num_taps, state_size, bias=False)\n",
    "#         self.B_im = nn.Linear(num_taps, state_size, bias=False)\n",
    "#         # ----------------------\n",
    "\n",
    "#         # Output MLP (Readout)\n",
    "#         # Takes [Input, Real(State)] -> Outputs\n",
    "#         self.state_out_map = nn.Sequential(\n",
    "#             nn.Linear(num_taps + state_size, hidden_size),\n",
    "#             nn.LayerNorm(hidden_size),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Linear(hidden_size, hidden_size),\n",
    "#             nn.LayerNorm(hidden_size),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Linear(hidden_size, 2) # Predict mean, std\n",
    "#         )\n",
    "\n",
    "#         # Initialize initial state as complex parameter (Real + Imag parts)\n",
    "#         self.n0_re = nn.Parameter(torch.zeros(state_size))\n",
    "#         self.n0_im = nn.Parameter(torch.zeros(state_size))\n",
    "        \n",
    "#         self.ar_taps = ar_taps\n",
    "\n",
    "#     def _step(self, xt, nt_complex):\n",
    "#         \"\"\"\n",
    "#         xt: [Batch, num_taps]\n",
    "#         nt_complex: [Batch, state_size] (Complex dtype)\n",
    "#         \"\"\"\n",
    "#         # --- 1. Materialize LRU Parameters ---\n",
    "#         # Ensure Lambda is stable: |lambda| = exp(-exp(nu_log)) < 1\n",
    "#         lambda_mod = torch.exp(-torch.exp(self.nu_log))\n",
    "#         theta = torch.exp(self.theta_log)\n",
    "        \n",
    "#         # Create diagonal Lambda (Batch broadcasting handled automatically)\n",
    "#         lambdas = torch.complex(lambda_mod * torch.cos(theta), lambda_mod * torch.sin(theta))\n",
    "        \n",
    "#         gamma = torch.exp(self.gamma_log)\n",
    "        \n",
    "#         # --- 2. Linear Recurrence ---\n",
    "#         # B * u_t\n",
    "#         u_in = torch.complex(self.B_re(xt), self.B_im(xt))\n",
    "        \n",
    "#         # h_t = Lambda * h_{t-1} + Gamma * B * u_t\n",
    "#         nt_next = lambdas * nt_complex + gamma * u_in\n",
    "        \n",
    "#         # --- 3. Output Projection ---\n",
    "#         # We use the Real part of the state as features for the MLP\n",
    "#         nt_real = nt_next.real \n",
    "        \n",
    "#         inp = torch.cat([xt, nt_real], dim=-1)\n",
    "#         out = self.state_out_map(inp)\n",
    "        \n",
    "#         y_pred = out[:, 0]\n",
    "#         std_pred = F.softplus(out[:, 1]) + 1e-6\n",
    "\n",
    "#         return y_pred, std_pred, nt_next\n",
    "\n",
    "#     def forward_train(self, x, y, initial_state=None):\n",
    "#         device = x.device\n",
    "#         T = x.size(-1)\n",
    "#         B = x.size(0)\n",
    "        \n",
    "#         # Pre-allocate outputs\n",
    "#         y_pred = torch.zeros(B, T, device=device)\n",
    "#         std_pred = torch.zeros(B, T, device=device)\n",
    "#         innovations = torch.zeros(B, T, device=device)\n",
    "#         phis_pred = torch.zeros(B, T, self.ar_taps, device=device)\n",
    "\n",
    "#         # Initialize State (Complex)\n",
    "#         if initial_state is None:\n",
    "#             n0_complex = torch.complex(self.n0_re, self.n0_im)\n",
    "#             nt = n0_complex.unsqueeze(0).expand(B, -1).clone()\n",
    "#         else:\n",
    "#             nt = initial_state\n",
    "\n",
    "#         # Pad input\n",
    "#         x_padded = torch.cat([torch.zeros(B, self.deterministic_num_taps - 1, device=device), x], dim=-1)\n",
    "\n",
    "#         for t in range(T):\n",
    "#             xt = x_padded[:, t: t + self.deterministic_num_taps]\n",
    "            \n",
    "#             # Step\n",
    "#             y_pred_t, std_pred_t, nt = self._step(xt, nt)\n",
    "            \n",
    "#             # Store outputs\n",
    "#             y_pred[:, t] = y_pred_t\n",
    "#             std_pred[:, t] = std_pred_t\n",
    "            \n",
    "#             # Residuals/Innovations\n",
    "#             r_t = (y[:, t] - y_pred_t)\n",
    "#             # Use raw residual as innovation (or apply AR filtering if desired)\n",
    "#             innovations[:, t] = r_t\n",
    "\n",
    "#         return y_pred, std_pred, innovations\n",
    "\n",
    "#     def forward_simulate(self, x, eps=None):\n",
    "#         device = x.device\n",
    "#         T = x.size(-1)\n",
    "#         B = x.size(0)\n",
    "#         y_pred = torch.zeros(B, T, device=device)\n",
    "        \n",
    "#         if eps is None:\n",
    "#             eps = torch.randn(B, T, device=device)\n",
    "            \n",
    "#         residuals = torch.zeros_like(x, device=device)\n",
    "        \n",
    "#         # Initialize State\n",
    "#         n0_complex = torch.complex(self.n0_re, self.n0_im)\n",
    "#         n_t = n0_complex.unsqueeze(0).expand(B, -1)\n",
    "        \n",
    "#         x_padded = torch.cat([torch.zeros(B, self.deterministic_num_taps - 1, device=device), x], dim=-1)\n",
    "        \n",
    "#         for t in range(T):\n",
    "#             xt = x_padded[:, t: t + self.deterministic_num_taps]\n",
    "#             y_pred_t, std_pred_t, phi_t, n_t = self._step(xt, n_t)\n",
    "            \n",
    "#             ar_term = torch.zeros_like(y_pred_t)\n",
    "#             for i in range(self.ar_taps):\n",
    "#                 lag = t - i - 1\n",
    "#                 if lag >= 0:\n",
    "#                     ar_term = ar_term + phi_t[:, i] * residuals[:, lag]\n",
    "            \n",
    "#             r_t = std_pred_t * eps[:, t] + ar_term\n",
    "#             residuals[:, t] = r_t\n",
    "#             y_pred[:, t] = y_pred_t + r_t\n",
    "        \n",
    "#         return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8420b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_std(model, input_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        noisy_sample, mean_pred, std_pred, _ = model(input_tensor)\n",
    "\n",
    "    xin = input_tensor[0].cpu().numpy()\n",
    "    mean = mean_pred[0].cpu().numpy()\n",
    "    std = std_pred[0].cpu().numpy()\n",
    "    sample = noisy_sample[0].cpu().numpy()\n",
    "\n",
    "    time_steps = np.arange(len(xin))\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    plt.plot(time_steps, mean, label='Predicted Mean', color='blue', linewidth=2)\n",
    "\n",
    "    plt.fill_between(\n",
    "        time_steps,\n",
    "        mean - 2 * std,\n",
    "        mean + 2 * std,\n",
    "        color='blue',\n",
    "        alpha=0.2,\n",
    "        label='Uncertainty (±2σ)'\n",
    "    )\n",
    "\n",
    "    plt.plot(time_steps, sample, label='Generated Sample', color='green', alpha=0.7)\n",
    "\n",
    "    plt.title('Model Prediction with Learned Uncertainty')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=':')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a06a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def regularizer(model, rho_theta, tau, rho_w):\n",
    "#     # θ = all parameters of both models\n",
    "#     l2_theta = 0.0\n",
    "#     l1_theta = 0.0\n",
    "#     for p in list(model.parameters()):\n",
    "#         l2_theta = l2_theta + torch.sum(p ** 2)\n",
    "#         l1_theta = l1_theta + torch.sum(p.abs())\n",
    "\n",
    "#     # \\hat w_0 = [n0, z0] from the state-space model\n",
    "#     w0_vec = torch.cat([model.n0.view(-1), model.z0.view(-1)])\n",
    "#     l2_w0 = torch.sum(w0_vec ** 2)\n",
    "\n",
    "#     reg = 0.5 * float(rho_theta) * l2_theta + float(tau) * l1_theta + 0.5 * float(rho_w) * l2_w0\n",
    "#     return reg\n",
    "\n",
    "def correlation(x: torch.Tensor, y: torch.Tensor, lag_max: int) -> torch.Tensor:\n",
    "    '''\n",
    "    Computes batched and normalized correlation between x and y [B, N] up to lag_max times\n",
    "    '''\n",
    "    x_centered = x - x.mean(dim=-1, keepdims=True)\n",
    "    y_centered = y - y.mean(dim=-1, keepdims=True)\n",
    "    cross_corrs = []\n",
    "    N = x_centered.shape[1]\n",
    "    assert lag_max <= N, \"Lag max too long\"\n",
    "    x_rms = torch.sqrt((1 / N) * torch.sum(x_centered ** 2, dim=-1, keepdims=True))\n",
    "    y_rms = torch.sqrt((1 / N) * torch.sum(y_centered ** 2, dim=-1, keepdims=True))\n",
    "    for lag in range(-lag_max, lag_max+1):\n",
    "        if lag >= 0:\n",
    "            shifted_x = x_centered[:, lag:]\n",
    "            shifted_y = y_centered[:, :N-lag]\n",
    "        else:\n",
    "            shifted_x = x_centered[:, :N+lag]\n",
    "            shifted_y = y_centered[:, -lag:]\n",
    "\n",
    "        corr = torch.mean(shifted_x * shifted_y, dim=-1, keepdim=True)\n",
    "        corr_norm = torch.mean(corr / (x_rms * y_rms), dim=0) # Average across batches\n",
    "        cross_corrs.append(corr_norm)\n",
    "\n",
    "    return torch.stack(cross_corrs, dim=0)\n",
    "\n",
    "\n",
    "def compute_billings_corrs(batched_residuals: torch.Tensor, batched_inputs: torch.Tensor,\n",
    "                           lag_max: int, log_wandb: bool = False, prefix: str = \"billings_correlation\"):\n",
    "    '''\n",
    "    Computs the Billing's et al correlation parameters to determine whether a model\n",
    "    has captured the system's nonlinearity\n",
    "\n",
    "    Args:\n",
    "        batched_residuals: model errors of shape [B, N]\n",
    "        batched_inputs: model inputs of shape [B, N]\n",
    "    '''\n",
    "\n",
    "\n",
    "    batched_residuals = batched_residuals - batched_residuals.mean(dim=-1, keepdim=True)\n",
    "    batched_inputs = batched_inputs - batched_inputs.mean(dim=-1, keepdim=True)\n",
    "\n",
    "    def _plot_and_log(y_np, title, key):\n",
    "        fig, ax = plt.subplots(figsize=(6, 3.5))\n",
    "        ax.plot(lags, y_np.ravel(), label=key)\n",
    "        ax.hlines(confidence_value, -lag_max, lag_max, colors='r', linestyles='dashed', label=\"95% CI\")\n",
    "        ax.hlines(-confidence_value, -lag_max, lag_max, colors='r', linestyles='dashed')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"Lag\")\n",
    "        ax.set_ylabel(\"Correlation\")\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if log_wandb:\n",
    "            wandb.log({f\"{prefix}/{key}\": wandb.Image(fig)})\n",
    "        else:\n",
    "            plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "    confidence_value = 1.96 / np.sqrt(batched_residuals.shape[1])\n",
    "    lags = lags = np.arange(-lag_max, lag_max + 1)\n",
    "\n",
    "    phi_r_r = correlation(batched_residuals, batched_residuals, lag_max).cpu().numpy()\n",
    "    _plot_and_log(phi_r_r, \"Residual Autocorrelation\", \"residual_autocorr\")\n",
    "    phi_u_r = correlation(batched_inputs, batched_residuals, lag_max).cpu().numpy()\n",
    "    _plot_and_log(phi_u_r, \"Input-Residual Correlation\", \"input_residual_corr\")\n",
    "    # shifted_product = batched_residuals[:, 1:] * batched_inputs[:, 1:]\n",
    "    phi_r_ru = correlation(batched_residuals, batched_inputs * batched_residuals, lag_max).cpu().numpy()\n",
    "    _plot_and_log(phi_r_ru, \"Residual-Residual*Input Correlation\", \"residual_residual_input_corr\")\n",
    "\n",
    "    u_prime_squared = torch.square(batched_inputs) - torch.mean(batched_inputs ** 2, dim=-1, keepdim=True)\n",
    "    phi_u_prime_squared_r = correlation(u_prime_squared, batched_residuals, lag_max).cpu().numpy()\n",
    "    _plot_and_log(phi_u_prime_squared_r, \"(U^2)' Residual Correlation\", \"u_squared_prime_residual_corr\")\n",
    "\n",
    "    phi_u_prime_squared_r_squared = correlation(u_prime_squared, batched_residuals ** 2, lag_max).cpu().numpy()\n",
    "    _plot_and_log(phi_u_prime_squared_r_squared, \"(U^2)' Residual ^2 Correlation\", \"u_squared_prime_residual_squared_corr\")\n",
    "\n",
    "\n",
    "sns.reset_defaults()      # resets seaborn styles\n",
    "\n",
    "\n",
    "def log_mean_std_plot(y, y_pred, std_pred, tag=\"val/mean_std\"):\n",
    "    \"\"\"\n",
    "    y, y_pred, std_pred: tensors [B, T]\n",
    "    Logs a wandb image showing predicted mean ±2σ for a 100-sample snippet.\n",
    "    \"\"\"\n",
    "\n",
    "    # Pick first sample in batch and first 100 steps\n",
    "    y_np = y[0, :100].detach().cpu().numpy()\n",
    "    mean_np = y_pred[0, :100].detach().cpu().numpy()\n",
    "    std_np = std_pred[0, :100].detach().cpu().numpy()\n",
    "\n",
    "    t = np.arange(100)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "    ax.plot(t, mean_np, label=\"Predicted Mean\", color=\"blue\", linewidth=2)\n",
    "    ax.fill_between(t, mean_np - 2*std_np, mean_np + 2*std_np,\n",
    "                    color=\"blue\", alpha=0.20, label=\"±2σ\")\n",
    "\n",
    "    ax.plot(t, y_np, label=\"Ground Truth\", color=\"black\", alpha=0.8)\n",
    "\n",
    "    ax.set_title(\"Predicted Mean ± 2σ (first 100 samples)\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Amplitude\")\n",
    "    ax.grid(True, linestyle=\":\")\n",
    "    ax.legend()\n",
    "\n",
    "    wandb.log({tag: wandb.Image(fig)})\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def log_phi_heatmap(phis, tag=\"val/phi_heatmap\", max_T=100):\n",
    "    \"\"\"\n",
    "    phis: tensor [B, T, ar_taps]\n",
    "    Logs a heatmap of the AR kernels over time.\n",
    "    \"\"\"\n",
    "\n",
    "    # Use first sample in batch\n",
    "    phi_np = phis[0].detach().cpu().numpy()\n",
    "\n",
    "    T = phi_np.shape[0]\n",
    "    p = phi_np.shape[1]\n",
    "\n",
    "    # Optionally crop long sequences\n",
    "    if T > max_T:\n",
    "        phi_np = phi_np[:max_T]\n",
    "        T = max_T\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    im = ax.imshow(phi_np.T, aspect='auto', origin='lower', cmap='viridis')\n",
    "\n",
    "    ax.set_title(\"AR Coefficients φᵢ[t] Over Time\")\n",
    "    ax.set_xlabel(\"Time t\")\n",
    "    ax.set_ylabel(\"AR tap index i\")\n",
    "\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    wandb.log({tag: wandb.Image(fig)})\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def gaussian_nll(difference, y_pred_std):\n",
    "    term1 = 0.5 * torch.log(2 * torch.pi * (y_pred_std ** 2))\n",
    "    term2 = 0.5 * torch.square((difference) / y_pred_std)\n",
    "    loss = torch.mean(term1 + term2)\n",
    "    if torch.isnan(loss):\n",
    "        raise ValueError(\"NaN in loss\")\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train(model, optimizer, loop, config):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    batch_count = 0\n",
    "    for batch in loop:\n",
    "        x, y = batch[0], batch[1]\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred, std_pred, e_pred = model.forward_train(x, y)\n",
    "        # loss = torch.mean((e_pred ** 2)) #+ regularizer(model, config.rho_theta, config.tau, config.rho_w)\n",
    "        loss = gaussian_nll(e_pred, std_pred)\n",
    "        mse_loss = F.mse_loss(y, y_pred)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        wandb.log({\"innovation_nll_train_loss\": loss.item()})\n",
    "        wandb.log({\"mse_train_loss\": mse_loss.item()})\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        wandb.log({\"learning_rate\": lr})\n",
    "        batch_count += 1\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        if batch_count % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                compute_billings_corrs(e_pred, x, 20, log_wandb=True, prefix=\"train_billings_correlation\")\n",
    "                # log_phi_heatmap(phis, tag=\"val/phi_heatmap\")\n",
    "\n",
    "    loop.close()\n",
    "    return model\n",
    "\n",
    "def val(model, val_loader, config, step):\n",
    "    model.eval()\n",
    "    # val_loss = 0\n",
    "    # batch_count = 0\n",
    "    # y_preds = []\n",
    "    # val_mse_loss = 0\n",
    "    # with torch.no_grad():\n",
    "    #     for x, y in val_loader:\n",
    "    #         x = x.to(device)\n",
    "    #         y = y.to(device)\n",
    "    #         mean_y, std_pred, e_pred = model.forward_train(x, y)\n",
    "    #         y_preds.append(mean_y)\n",
    "    #         loss = gaussian_nll(e_pred, std_pred)\n",
    "    #         # loss = torch.mean((e_pred ** 2))\n",
    "    #         mse_loss = F.mse_loss(y, mean_y)\n",
    "    #         val_mse_loss += mse_loss.item()\n",
    "    #         val_loss += loss.item()\n",
    "    #         batch_count += 1\n",
    "    # avg_val_loss = (val_loss / batch_count)\n",
    "    # avg_val_mse_loss = (val_mse_loss / batch_count)\n",
    "    # # wandb.log({\n",
    "    # #     \"val_innovation_loss\": avg_val_loss,\n",
    "    # #     \"avg_val_mse_loss\": avg_val_mse_loss\n",
    "    # # })\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        stds = []\n",
    "        mse_list = []\n",
    "        snr_list = []\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred, std_pred, e_pred = model.forward_train(x, y)\n",
    "\n",
    "            stds.append(std_pred)\n",
    "            mse_list.append(F.mse_loss(y_pred, y, reduction=\"mean\").item())\n",
    "\n",
    "            # simple SNR estimate: var(y)/var(innovation)\n",
    "            num = y.var(dim=-1).mean().item()\n",
    "            den = e_pred.var(dim=-1).mean().item()\n",
    "            snr_list.append(num / (den + 1e-8))\n",
    "\n",
    "\n",
    "        \n",
    "        log_mean_std_plot(\n",
    "            y, y_pred, std_pred,\n",
    "            tag=\"val/mean_std_plot\"\n",
    "        )\n",
    "\n",
    "        stds_all = torch.cat(stds, dim=0)  # [N, T]\n",
    "        wandb.log({\n",
    "            \"val/std_mean\": stds_all.mean().item(),\n",
    "            \"val/std_std\": stds_all.std().item(),\n",
    "            \"val/std_min\": stds_all.min().item(),\n",
    "            \"val/std_max\": stds_all.max().item(),\n",
    "            \"val/mse_y\": np.mean(mse_list),\n",
    "            \"val/snr_y_over_eps\": np.mean(snr_list),\n",
    "        })\n",
    "    return np.mean(mse_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d015368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\maild\\mldrivenpeled\\notebooks\\wandb\\run-20251126_211254-d2aj4ek8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/d2aj4ek8' target=\"_blank\">glowing-plant-7388</a></strong> to <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/d2aj4ek8' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/d2aj4ek8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run info:\n",
      "  Name: glowing-plant-7388\n",
      "  ID: d2aj4ek8\n",
      "  URL: https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/d2aj4ek8\n",
      "Chosen hyperparameters for this session:\n",
      "{'batch_size': 32, 'num_taps': 10, 'hidden_size': 16, 'state_size': 8, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': '1e-4', 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'epochs': 6, 'mode': 'normal'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.65it/s, loss=-0.741] \n",
      "Epoch 2 [normal]: 100%|██████████| 57/57 [00:09<00:00,  6.07it/s, loss=-1.85] \n",
      "Epoch 3 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.59it/s, loss=-2.72]\n",
      "Epoch 4 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.51it/s, loss=-2.99]\n",
      "Epoch 5 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.82it/s, loss=-3.18]\n",
      "Epoch 6 [normal]: 100%|██████████| 57/57 [00:09<00:00,  6.23it/s, loss=-3.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 1,405\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best found!\n",
      "Best Run ID: glowing-plant-7388\n",
      "Best Validation Loss: 0.00011992590797100482\n",
      "Best Configuration: {'batch_size': 32, 'num_taps': 4, 'hidden_size': 8, 'state_size': 2, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': 0.01, 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0.0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'epochs': 6, 'mode': 'normal'}]}\n",
      "New best found!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>███▇▇▆▅▅▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mse_train_loss</td><td>█▆▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/mse_y</td><td>█▂▁▁▁▁</td></tr><tr><td>val/snr_y_over_eps</td><td>▁▂▆▇██</td></tr><tr><td>val/std_max</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_mean</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_min</td><td>█▃▂▁▁▁</td></tr><tr><td>val/std_std</td><td>█▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>-3.24784</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>mse_train_loss</td><td>0.0001</td></tr><tr><td>val/mse_y</td><td>0.00012</td></tr><tr><td>val/snr_y_over_eps</td><td>48.86543</td></tr><tr><td>val/std_max</td><td>0.07483</td></tr><tr><td>val/std_mean</td><td>0.01052</td></tr><tr><td>val/std_min</td><td>0.00972</td></tr><tr><td>val/std_std</td><td>0.00154</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glowing-plant-7388</strong> at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/d2aj4ek8' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/d2aj4ek8</a><br> View project at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a><br>Synced 5 W&B file(s), 161 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251126_211254-d2aj4ek8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\maild\\mldrivenpeled\\notebooks\\wandb\\run-20251126_211352-dob7674d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/dob7674d' target=\"_blank\">dutiful-sun-7389</a></strong> to <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/dob7674d' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/dob7674d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run info:\n",
      "  Name: dutiful-sun-7389\n",
      "  ID: dob7674d\n",
      "  URL: https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/dob7674d\n",
      "Chosen hyperparameters for this session:\n",
      "{'batch_size': 32, 'num_taps': 10, 'hidden_size': 16, 'state_size': 8, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': '1e-4', 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'epochs': 6, 'mode': 'normal'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.72it/s, loss=-0.929] \n",
      "Epoch 2 [normal]: 100%|██████████| 57/57 [00:13<00:00,  4.37it/s, loss=-1.94]\n",
      "Epoch 3 [normal]: 100%|██████████| 57/57 [00:13<00:00,  4.37it/s, loss=-2.78]\n",
      "Epoch 4 [normal]: 100%|██████████| 57/57 [00:10<00:00,  5.61it/s, loss=-3.12]\n",
      "Epoch 5 [normal]: 100%|██████████| 57/57 [00:10<00:00,  5.32it/s, loss=-3.16]\n",
      "Epoch 6 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.35it/s, loss=-3.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 1,405\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best found!\n",
      "Best Run ID: dutiful-sun-7389\n",
      "Best Validation Loss: 0.00011626271173424487\n",
      "Best Configuration: {'batch_size': 32, 'num_taps': 4, 'hidden_size': 8, 'state_size': 2, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': 0.001, 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0.0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'epochs': 6, 'mode': 'normal'}]}\n",
      "New best found!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>█▇▇▆▆▅▅▅▅▅▄▄▄▄▄▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mse_train_loss</td><td>█▇▃▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/mse_y</td><td>█▃▁▁▁▁</td></tr><tr><td>val/snr_y_over_eps</td><td>▁▃▅▇▇█</td></tr><tr><td>val/std_max</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_mean</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_min</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_std</td><td>█▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>-3.14156</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>mse_train_loss</td><td>0.00012</td></tr><tr><td>val/mse_y</td><td>0.00012</td></tr><tr><td>val/snr_y_over_eps</td><td>51.9481</td></tr><tr><td>val/std_max</td><td>0.02923</td></tr><tr><td>val/std_mean</td><td>0.01043</td></tr><tr><td>val/std_min</td><td>0.0098</td></tr><tr><td>val/std_std</td><td>0.00099</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dutiful-sun-7389</strong> at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/dob7674d' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/dob7674d</a><br> View project at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a><br>Synced 5 W&B file(s), 161 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251126_211352-dob7674d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\maild\\mldrivenpeled\\notebooks\\wandb\\run-20251126_211504-dy8ptfnw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/dy8ptfnw' target=\"_blank\">upbeat-cosmos-7390</a></strong> to <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/dy8ptfnw' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/dy8ptfnw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run info:\n",
      "  Name: upbeat-cosmos-7390\n",
      "  ID: dy8ptfnw\n",
      "  URL: https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/dy8ptfnw\n",
      "Chosen hyperparameters for this session:\n",
      "{'batch_size': 32, 'num_taps': 10, 'hidden_size': 16, 'state_size': 8, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': '1e-4', 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'epochs': 6, 'mode': 'normal'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.71it/s, loss=-0.864] \n",
      "Epoch 2 [normal]: 100%|██████████| 57/57 [00:09<00:00,  6.33it/s, loss=-2.06]\n",
      "Epoch 3 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.39it/s, loss=-2.86]\n",
      "Epoch 4 [normal]: 100%|██████████| 57/57 [00:11<00:00,  5.15it/s, loss=-3.17]\n",
      "Epoch 5 [normal]: 100%|██████████| 57/57 [00:10<00:00,  5.63it/s, loss=-3.18]\n",
      "Epoch 6 [normal]: 100%|██████████| 57/57 [00:09<00:00,  6.30it/s, loss=-3.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 1,405\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>██▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mse_train_loss</td><td>█▇▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/mse_y</td><td>█▂▁▁▁▁</td></tr><tr><td>val/snr_y_over_eps</td><td>▁▃▆▇██</td></tr><tr><td>val/std_max</td><td>█▂▁▁▁▁</td></tr><tr><td>val/std_mean</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_min</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_std</td><td>█▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>-3.08178</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>mse_train_loss</td><td>0.00014</td></tr><tr><td>val/mse_y</td><td>0.00012</td></tr><tr><td>val/snr_y_over_eps</td><td>48.75466</td></tr><tr><td>val/std_max</td><td>0.03805</td></tr><tr><td>val/std_mean</td><td>0.01059</td></tr><tr><td>val/std_min</td><td>0.00975</td></tr><tr><td>val/std_std</td><td>0.00169</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">upbeat-cosmos-7390</strong> at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/dy8ptfnw' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/dy8ptfnw</a><br> View project at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a><br>Synced 5 W&B file(s), 161 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251126_211504-dy8ptfnw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\maild\\mldrivenpeled\\notebooks\\wandb\\run-20251126_211607-8si9gsr9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/8si9gsr9' target=\"_blank\">glamorous-universe-7391</a></strong> to <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/8si9gsr9' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/8si9gsr9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run info:\n",
      "  Name: glamorous-universe-7391\n",
      "  ID: 8si9gsr9\n",
      "  URL: https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/8si9gsr9\n",
      "Chosen hyperparameters for this session:\n",
      "{'batch_size': 32, 'num_taps': 10, 'hidden_size': 16, 'state_size': 8, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': '1e-4', 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'epochs': 6, 'mode': 'normal'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.83it/s, loss=-0.76]  \n",
      "Epoch 2 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.70it/s, loss=-2.02]\n",
      "Epoch 3 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.43it/s, loss=-2.91]\n",
      "Epoch 4 [normal]: 100%|██████████| 57/57 [00:09<00:00,  6.22it/s, loss=-3.16]\n",
      "Epoch 5 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.71it/s, loss=-3.03]\n",
      "Epoch 6 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.46it/s, loss=-3.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 1,405\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best found!\n",
      "Best Run ID: glamorous-universe-7391\n",
      "Best Validation Loss: 0.00011516912075291787\n",
      "Best Configuration: {'batch_size': 32, 'num_taps': 4, 'hidden_size': 8, 'state_size': 4, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': 0.01, 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0.0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'epochs': 6, 'mode': 'normal'}]}\n",
      "New best found!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>███▇▇▇▇▆▅▅▄▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mse_train_loss</td><td>█▅▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/mse_y</td><td>█▂▁▁▁▁</td></tr><tr><td>val/snr_y_over_eps</td><td>▁▃▅▇██</td></tr><tr><td>val/std_max</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_mean</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_min</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_std</td><td>█▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>-3.22276</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>mse_train_loss</td><td>0.0001</td></tr><tr><td>val/mse_y</td><td>0.00012</td></tr><tr><td>val/snr_y_over_eps</td><td>51.35183</td></tr><tr><td>val/std_max</td><td>0.02158</td></tr><tr><td>val/std_mean</td><td>0.01041</td></tr><tr><td>val/std_min</td><td>0.00971</td></tr><tr><td>val/std_std</td><td>0.00098</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glamorous-universe-7391</strong> at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/8si9gsr9' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/8si9gsr9</a><br> View project at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a><br>Synced 5 W&B file(s), 161 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251126_211607-8si9gsr9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\maild\\mldrivenpeled\\notebooks\\wandb\\run-20251126_211706-5ylt1vi2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/5ylt1vi2' target=\"_blank\">happy-galaxy-7392</a></strong> to <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/5ylt1vi2' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/5ylt1vi2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run info:\n",
      "  Name: happy-galaxy-7392\n",
      "  ID: 5ylt1vi2\n",
      "  URL: https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/5ylt1vi2\n",
      "Chosen hyperparameters for this session:\n",
      "{'batch_size': 32, 'num_taps': 10, 'hidden_size': 16, 'state_size': 8, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': '1e-4', 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'epochs': 6, 'mode': 'normal'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.65it/s, loss=-0.819] \n",
      "Epoch 2 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.50it/s, loss=-1.73] \n",
      "Epoch 3 [normal]: 100%|██████████| 57/57 [00:09<00:00,  6.10it/s, loss=-2.61]\n",
      "Epoch 4 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.97it/s, loss=-3.06]\n",
      "Epoch 5 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.46it/s, loss=-3.12]\n",
      "Epoch 6 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.45it/s, loss=-3.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 1,405\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best found!\n",
      "Best Run ID: happy-galaxy-7392\n",
      "Best Validation Loss: 0.00010969628056045622\n",
      "Best Configuration: {'batch_size': 32, 'num_taps': 4, 'hidden_size': 8, 'state_size': 4, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': 0.001, 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0.0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'epochs': 6, 'mode': 'normal'}]}\n",
      "New best found!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>███▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mse_train_loss</td><td>█▇▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/mse_y</td><td>█▃▁▁▁▁</td></tr><tr><td>val/snr_y_over_eps</td><td>▁▂▅▇██</td></tr><tr><td>val/std_max</td><td>█▅▁▁▁▁</td></tr><tr><td>val/std_mean</td><td>█▄▂▁▁▁</td></tr><tr><td>val/std_min</td><td>█▄▂▁▁▁</td></tr><tr><td>val/std_std</td><td>█▃▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>-3.25939</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>mse_train_loss</td><td>0.0001</td></tr><tr><td>val/mse_y</td><td>0.00011</td></tr><tr><td>val/snr_y_over_eps</td><td>52.5783</td></tr><tr><td>val/std_max</td><td>0.04436</td></tr><tr><td>val/std_mean</td><td>0.01021</td></tr><tr><td>val/std_min</td><td>0.00956</td></tr><tr><td>val/std_std</td><td>0.00151</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">happy-galaxy-7392</strong> at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/5ylt1vi2' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/5ylt1vi2</a><br> View project at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a><br>Synced 5 W&B file(s), 161 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251126_211706-5ylt1vi2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\maild\\mldrivenpeled\\notebooks\\wandb\\run-20251126_211805-6if8ewfi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/6if8ewfi' target=\"_blank\">smart-snowball-7393</a></strong> to <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/6if8ewfi' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/6if8ewfi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run info:\n",
      "  Name: smart-snowball-7393\n",
      "  ID: 6if8ewfi\n",
      "  URL: https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/6if8ewfi\n",
      "Chosen hyperparameters for this session:\n",
      "{'batch_size': 32, 'num_taps': 10, 'hidden_size': 16, 'state_size': 8, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': '1e-4', 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'epochs': 6, 'mode': 'normal'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.36it/s, loss=-0.757] \n",
      "Epoch 2 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.38it/s, loss=-1.74] \n",
      "Epoch 3 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.71it/s, loss=-2.64]\n",
      "Epoch 4 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.90it/s, loss=-3.11]\n",
      "Epoch 5 [normal]: 100%|██████████| 57/57 [00:09<00:00,  6.12it/s, loss=-3.17]\n",
      "Epoch 6 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.83it/s, loss=-3.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 1,405\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>██▇▇▇▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▄▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mse_train_loss</td><td>█▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/mse_y</td><td>█▃▁▁▁▁</td></tr><tr><td>val/snr_y_over_eps</td><td>▁▂▅▇██</td></tr><tr><td>val/std_max</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_mean</td><td>█▃▂▁▁▁</td></tr><tr><td>val/std_min</td><td>█▃▂▁▁▁</td></tr><tr><td>val/std_std</td><td>█▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>-3.14882</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>mse_train_loss</td><td>0.00011</td></tr><tr><td>val/mse_y</td><td>0.00012</td></tr><tr><td>val/snr_y_over_eps</td><td>49.2385</td></tr><tr><td>val/std_max</td><td>0.01999</td></tr><tr><td>val/std_mean</td><td>0.01093</td></tr><tr><td>val/std_min</td><td>0.01032</td></tr><tr><td>val/std_std</td><td>0.00054</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smart-snowball-7393</strong> at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/6if8ewfi' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/6if8ewfi</a><br> View project at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a><br>Synced 5 W&B file(s), 161 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251126_211805-6if8ewfi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\maild\\mldrivenpeled\\notebooks\\wandb\\run-20251126_211906-qlfnby16</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/qlfnby16' target=\"_blank\">atomic-wind-7394</a></strong> to <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/qlfnby16' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/qlfnby16</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run info:\n",
      "  Name: atomic-wind-7394\n",
      "  ID: qlfnby16\n",
      "  URL: https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/qlfnby16\n",
      "Chosen hyperparameters for this session:\n",
      "{'batch_size': 32, 'num_taps': 10, 'hidden_size': 16, 'state_size': 8, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': '1e-4', 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'epochs': 6, 'mode': 'normal'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [normal]: 100%|██████████| 57/57 [00:13<00:00,  4.23it/s, loss=-0.741]  \n",
      "Epoch 2 [normal]: 100%|██████████| 57/57 [00:10<00:00,  5.42it/s, loss=-1.84] \n",
      "Epoch 3 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.71it/s, loss=-2.69]\n",
      "Epoch 4 [normal]: 100%|██████████| 57/57 [00:10<00:00,  5.53it/s, loss=-2.98]\n",
      "Epoch 5 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.98it/s, loss=-3.16]\n",
      "Epoch 6 [normal]: 100%|██████████| 57/57 [00:09<00:00,  6.02it/s, loss=-3.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 1,405\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>██▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mse_train_loss</td><td>█▄▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/mse_y</td><td>█▃▁▁▁▁</td></tr><tr><td>val/snr_y_over_eps</td><td>▁▂▅▇██</td></tr><tr><td>val/std_max</td><td>█▃▂▁▁▁</td></tr><tr><td>val/std_mean</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_min</td><td>█▃▂▁▁▁</td></tr><tr><td>val/std_std</td><td>█▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>-3.14494</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>mse_train_loss</td><td>0.00014</td></tr><tr><td>val/mse_y</td><td>0.00015</td></tr><tr><td>val/snr_y_over_eps</td><td>44.96007</td></tr><tr><td>val/std_max</td><td>0.07249</td></tr><tr><td>val/std_mean</td><td>0.01085</td></tr><tr><td>val/std_min</td><td>0.00974</td></tr><tr><td>val/std_std</td><td>0.00344</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">atomic-wind-7394</strong> at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/qlfnby16' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/qlfnby16</a><br> View project at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a><br>Synced 5 W&B file(s), 161 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251126_211906-qlfnby16\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\maild\\mldrivenpeled\\notebooks\\wandb\\run-20251126_212015-12yzh9j2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/12yzh9j2' target=\"_blank\">wandering-totem-7395</a></strong> to <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/12yzh9j2' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/12yzh9j2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run info:\n",
      "  Name: wandering-totem-7395\n",
      "  ID: 12yzh9j2\n",
      "  URL: https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/12yzh9j2\n",
      "Chosen hyperparameters for this session:\n",
      "{'batch_size': 32, 'num_taps': 10, 'hidden_size': 16, 'state_size': 8, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': '1e-4', 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'epochs': 6, 'mode': 'normal'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [normal]: 100%|██████████| 57/57 [00:09<00:00,  6.08it/s, loss=-1.05]   \n",
      "Epoch 2 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.88it/s, loss=-2.22]\n",
      "Epoch 3 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.79it/s, loss=-2.89]\n",
      "Epoch 4 [normal]: 100%|██████████| 57/57 [00:11<00:00,  5.05it/s, loss=-3.15]\n",
      "Epoch 5 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.97it/s, loss=-3.14]\n",
      "Epoch 6 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.79it/s, loss=-3.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 1,405\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>███▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mse_train_loss</td><td>█▆▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/mse_y</td><td>█▂▁▁▁▁</td></tr><tr><td>val/snr_y_over_eps</td><td>▁▄▆▇▇█</td></tr><tr><td>val/std_max</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_mean</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_min</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_std</td><td>█▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>-3.12802</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>mse_train_loss</td><td>0.00012</td></tr><tr><td>val/mse_y</td><td>0.00011</td></tr><tr><td>val/snr_y_over_eps</td><td>53.71182</td></tr><tr><td>val/std_max</td><td>0.01849</td></tr><tr><td>val/std_mean</td><td>0.01084</td></tr><tr><td>val/std_min</td><td>0.0104</td></tr><tr><td>val/std_std</td><td>0.00059</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wandering-totem-7395</strong> at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/12yzh9j2' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/12yzh9j2</a><br> View project at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a><br>Synced 5 W&B file(s), 161 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251126_212015-12yzh9j2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\maild\\mldrivenpeled\\notebooks\\wandb\\run-20251126_212120-ktnj01l6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/ktnj01l6' target=\"_blank\">soft-disco-7396</a></strong> to <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/ktnj01l6' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/ktnj01l6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run info:\n",
      "  Name: soft-disco-7396\n",
      "  ID: ktnj01l6\n",
      "  URL: https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/ktnj01l6\n",
      "Chosen hyperparameters for this session:\n",
      "{'batch_size': 32, 'num_taps': 10, 'hidden_size': 16, 'state_size': 8, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': '1e-4', 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'epochs': 6, 'mode': 'normal'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [normal]: 100%|██████████| 57/57 [00:09<00:00,  6.24it/s, loss=-0.649] \n",
      "Epoch 2 [normal]: 100%|██████████| 57/57 [00:12<00:00,  4.65it/s, loss=-1.9]  \n",
      "Epoch 3 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.76it/s, loss=-2.79]\n",
      "Epoch 4 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.92it/s, loss=-3.02]\n",
      "Epoch 5 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.94it/s, loss=-3.23]\n",
      "Epoch 6 [normal]: 100%|██████████| 57/57 [00:09<00:00,  6.02it/s, loss=-3.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 1,405\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>████▇▇▇▇▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mse_train_loss</td><td>█▅▄▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/mse_y</td><td>█▂▁▁▁▁</td></tr><tr><td>val/snr_y_over_eps</td><td>▁▂▆▇██</td></tr><tr><td>val/std_max</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_mean</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_min</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_std</td><td>█▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>-3.16157</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>mse_train_loss</td><td>0.00012</td></tr><tr><td>val/mse_y</td><td>0.00012</td></tr><tr><td>val/snr_y_over_eps</td><td>47.03186</td></tr><tr><td>val/std_max</td><td>0.04464</td></tr><tr><td>val/std_mean</td><td>0.0107</td></tr><tr><td>val/std_min</td><td>0.00945</td></tr><tr><td>val/std_std</td><td>0.0032</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">soft-disco-7396</strong> at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/ktnj01l6' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/ktnj01l6</a><br> View project at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a><br>Synced 5 W&B file(s), 161 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251126_212120-ktnj01l6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\maild\\mldrivenpeled\\notebooks\\wandb\\run-20251126_212225-a2o7n8f4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/a2o7n8f4' target=\"_blank\">fancy-galaxy-7397</a></strong> to <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/a2o7n8f4' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/a2o7n8f4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run info:\n",
      "  Name: fancy-galaxy-7397\n",
      "  ID: a2o7n8f4\n",
      "  URL: https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/a2o7n8f4\n",
      "Chosen hyperparameters for this session:\n",
      "{'batch_size': 32, 'num_taps': 10, 'hidden_size': 16, 'state_size': 8, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': '1e-4', 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'epochs': 6, 'mode': 'normal'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [normal]: 100%|██████████| 57/57 [00:09<00:00,  6.01it/s, loss=-0.603] \n",
      "Epoch 2 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.80it/s, loss=-1.79] \n",
      "Epoch 3 [normal]: 100%|██████████| 57/57 [00:09<00:00,  6.17it/s, loss=-2.62]\n",
      "Epoch 4 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.91it/s, loss=-3.07]\n",
      "Epoch 5 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.74it/s, loss=-3.07]\n",
      "Epoch 6 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.93it/s, loss=-3.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 1,405\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>█▇▇▇▇▆▆▆▆▅▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mse_train_loss</td><td>██▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/mse_y</td><td>█▃▂▁▁▁</td></tr><tr><td>val/snr_y_over_eps</td><td>▁▂▆▇██</td></tr><tr><td>val/std_max</td><td>█▃▂▁▁▁</td></tr><tr><td>val/std_mean</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_min</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_std</td><td>█▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>-3.07426</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>mse_train_loss</td><td>0.00013</td></tr><tr><td>val/mse_y</td><td>0.00012</td></tr><tr><td>val/snr_y_over_eps</td><td>48.15163</td></tr><tr><td>val/std_max</td><td>0.01943</td></tr><tr><td>val/std_mean</td><td>0.01077</td></tr><tr><td>val/std_min</td><td>0.01027</td></tr><tr><td>val/std_std</td><td>0.00054</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fancy-galaxy-7397</strong> at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/a2o7n8f4' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/a2o7n8f4</a><br> View project at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a><br>Synced 5 W&B file(s), 161 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251126_212225-a2o7n8f4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\maild\\mldrivenpeled\\notebooks\\wandb\\run-20251126_212328-tm2fwwus</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/tm2fwwus' target=\"_blank\">lucky-disco-7398</a></strong> to <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/tm2fwwus' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/tm2fwwus</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run info:\n",
      "  Name: lucky-disco-7398\n",
      "  ID: tm2fwwus\n",
      "  URL: https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/tm2fwwus\n",
      "Chosen hyperparameters for this session:\n",
      "{'batch_size': 32, 'num_taps': 10, 'hidden_size': 16, 'state_size': 8, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': '1e-4', 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'epochs': 6, 'mode': 'normal'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [normal]: 100%|██████████| 57/57 [00:15<00:00,  3.77it/s, loss=-0.822]  \n",
      "Epoch 2 [normal]: 100%|██████████| 57/57 [00:14<00:00,  3.88it/s, loss=-2.05]\n",
      "Epoch 3 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.74it/s, loss=-2.89]\n",
      "Epoch 4 [normal]: 100%|██████████| 57/57 [00:09<00:00,  6.05it/s, loss=-3.05]\n",
      "Epoch 5 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.91it/s, loss=-3.18]\n",
      "Epoch 6 [normal]: 100%|██████████| 57/57 [00:11<00:00,  4.85it/s, loss=-3.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 1,405\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>██▇▇▇▆▆▆▆▆▅▅▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mse_train_loss</td><td>█▅▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/mse_y</td><td>█▃▂▁▁▁</td></tr><tr><td>val/snr_y_over_eps</td><td>▁▂▅▇██</td></tr><tr><td>val/std_max</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_mean</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_min</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_std</td><td>█▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>-3.22581</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>mse_train_loss</td><td>0.00011</td></tr><tr><td>val/mse_y</td><td>0.00013</td></tr><tr><td>val/snr_y_over_eps</td><td>48.78001</td></tr><tr><td>val/std_max</td><td>0.03689</td></tr><tr><td>val/std_mean</td><td>0.01088</td></tr><tr><td>val/std_min</td><td>0.01006</td></tr><tr><td>val/std_std</td><td>0.00209</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lucky-disco-7398</strong> at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/tm2fwwus' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/tm2fwwus</a><br> View project at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a><br>Synced 5 W&B file(s), 161 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251126_212328-tm2fwwus\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\maild\\mldrivenpeled\\notebooks\\wandb\\run-20251126_212444-279n3usy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/279n3usy' target=\"_blank\">absurd-oath-7399</a></strong> to <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/279n3usy' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/279n3usy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run info:\n",
      "  Name: absurd-oath-7399\n",
      "  ID: 279n3usy\n",
      "  URL: https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/279n3usy\n",
      "Chosen hyperparameters for this session:\n",
      "{'batch_size': 32, 'num_taps': 10, 'hidden_size': 16, 'state_size': 8, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': '1e-4', 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'epochs': 6, 'mode': 'normal'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [normal]: 100%|██████████| 57/57 [00:09<00:00,  6.00it/s, loss=-0.492]  \n",
      "Epoch 2 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.56it/s, loss=-1.82] \n",
      "Epoch 3 [normal]: 100%|██████████| 57/57 [00:09<00:00,  6.06it/s, loss=-2.76]\n",
      "Epoch 4 [normal]: 100%|██████████| 57/57 [00:08<00:00,  6.55it/s, loss=-3.1] \n",
      "Epoch 5 [normal]: 100%|██████████| 57/57 [00:11<00:00,  4.78it/s, loss=-3.12]\n",
      "Epoch 6 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.85it/s, loss=-3.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 1,405\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>████▇▆▅▅▅▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mse_train_loss</td><td>█▆▆▄▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/mse_y</td><td>█▃▂▁▁▁</td></tr><tr><td>val/snr_y_over_eps</td><td>▁▂▅▇██</td></tr><tr><td>val/std_max</td><td>█▃▁▁▁▂</td></tr><tr><td>val/std_mean</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_min</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_std</td><td>█▂▁▁▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>-3.161</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>mse_train_loss</td><td>0.00013</td></tr><tr><td>val/mse_y</td><td>0.00013</td></tr><tr><td>val/snr_y_over_eps</td><td>43.22101</td></tr><tr><td>val/std_max</td><td>0.07713</td></tr><tr><td>val/std_mean</td><td>0.0114</td></tr><tr><td>val/std_min</td><td>0.00971</td></tr><tr><td>val/std_std</td><td>0.00526</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">absurd-oath-7399</strong> at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/279n3usy' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/279n3usy</a><br> View project at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a><br>Synced 5 W&B file(s), 161 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251126_212444-279n3usy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\maild\\mldrivenpeled\\notebooks\\wandb\\run-20251126_212548-ncq5jxa1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/ncq5jxa1' target=\"_blank\">wobbly-water-7400</a></strong> to <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/ncq5jxa1' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/ncq5jxa1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run info:\n",
      "  Name: wobbly-water-7400\n",
      "  ID: ncq5jxa1\n",
      "  URL: https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/ncq5jxa1\n",
      "Chosen hyperparameters for this session:\n",
      "{'batch_size': 32, 'num_taps': 10, 'hidden_size': 16, 'state_size': 8, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': '1e-4', 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'mode': 'normal', 'epochs': 6}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.92it/s, loss=-0.815] \n",
      "Epoch 2 [normal]: 100%|██████████| 57/57 [00:09<00:00,  6.19it/s, loss=-1.88]\n",
      "Epoch 3 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.78it/s, loss=-2.78]\n",
      "Epoch 4 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.90it/s, loss=-3.08]\n",
      "Epoch 5 [normal]: 100%|██████████| 57/57 [00:10<00:00,  5.65it/s, loss=-3.23]\n",
      "Epoch 6 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.71it/s, loss=-3.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 1,405\n",
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best found!\n",
      "Best Run ID: wobbly-water-7400\n",
      "Best Validation Loss: 0.00010731061878946743\n",
      "Best Configuration: {'batch_size': 32, 'num_taps': 8, 'hidden_size': 8, 'state_size': 4, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': 0.01, 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0.0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'epochs': 6, 'mode': 'normal'}]}\n",
      "New best found!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>██▇▇▇▆▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mse_train_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/mse_y</td><td>█▃▁▁▁▁</td></tr><tr><td>val/snr_y_over_eps</td><td>▁▂▆███</td></tr><tr><td>val/std_max</td><td>█▃▁▁▁▁</td></tr><tr><td>val/std_mean</td><td>█▃▂▁▁▁</td></tr><tr><td>val/std_min</td><td>█▃▂▁▁▁</td></tr><tr><td>val/std_std</td><td>█▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>innovation_nll_train_loss</td><td>-3.21544</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>mse_train_loss</td><td>0.00011</td></tr><tr><td>val/mse_y</td><td>0.00011</td></tr><tr><td>val/snr_y_over_eps</td><td>53.1607</td></tr><tr><td>val/std_max</td><td>0.03674</td></tr><tr><td>val/std_mean</td><td>0.01012</td></tr><tr><td>val/std_min</td><td>0.00969</td></tr><tr><td>val/std_std</td><td>0.00116</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wobbly-water-7400</strong> at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/ncq5jxa1' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/ncq5jxa1</a><br> View project at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a><br>Synced 5 W&B file(s), 161 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251126_212548-ncq5jxa1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\maild\\mldrivenpeled\\notebooks\\wandb\\run-20251126_212652-0ey7d0mw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/0ey7d0mw' target=\"_blank\">genial-dragon-7401</a></strong> to <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/0ey7d0mw' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/0ey7d0mw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run info:\n",
      "  Name: genial-dragon-7401\n",
      "  ID: 0ey7d0mw\n",
      "  URL: https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/0ey7d0mw\n",
      "Chosen hyperparameters for this session:\n",
      "{'batch_size': 32, 'num_taps': 10, 'hidden_size': 16, 'state_size': 8, 'ar_taps': 0, 'num_adam_epochs': 25, 'num_LBFGS_epochs': 20, 'gain': 20, 'lr': 0.001, 'wd': '1e-4', 'hidden_channels': 8, 'dilation_base': 2, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'rho_theta': '2e-4', 'Nf': 1499, 'Nt': 1, 'flow': 300000, 'fhigh': '15e6', 'fnyquist': '30e6', 'subcarrier_spacing': '1e4', 'dc_offset': 3.5, 'deterministic_num_taps': 4, 'deterministic_hidden_size': 16, 'stochastic_hidden_size': 16, 'stochastic_state_size': 2, 'deterministic_state_size': 2, 'tau': 0, 'rho_w': '2e-8', 'lr_channel': '1e-3', 'lr_noise': '1e-3', 'lr_joint': '1e-3', 'lr_linear': '1e-3', 'wd_channel': '1e-2', 'wd_noise': '1e-2', 'wd_joint': '1e-2', 'wd_linear': '1e-2', 'training_schedule': [{'epochs': 6, 'mode': 'normal'}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.88it/s, loss=-0.836] \n",
      "Epoch 2 [normal]: 100%|██████████| 57/57 [00:10<00:00,  5.46it/s, loss=-2.14]\n",
      "Epoch 3 [normal]: 100%|██████████| 57/57 [00:09<00:00,  5.96it/s, loss=-2.82]\n",
      "Epoch 4 [normal]:  77%|███████▋  | 44/57 [00:07<00:02,  5.72it/s, loss=-3.1] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 192\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# override base config\u001b[39;00m\n\u001b[0;32m    190\u001b[0m base_cfg\u001b[38;5;241m.\u001b[39mupdate(config)\n\u001b[1;32m--> 192\u001b[0m val_loss, run_id, channel_model, train_loader, val_loader \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m innovations \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    195\u001b[0m all_residuals \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[14], line 136\u001b[0m, in \u001b[0;36mrun_experiment\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    134\u001b[0m epoch_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    135\u001b[0m loop \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_counter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 136\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannel_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m avg_val_loss \u001b[38;5;241m=\u001b[39m val(channel_model, val_loader, config, local_epoch)\n\u001b[0;32m    138\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep(avg_val_loss)\n",
      "Cell \u001b[1;32mIn[13], line 175\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, loop, config)\u001b[0m\n\u001b[0;32m    173\u001b[0m x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    174\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 175\u001b[0m y_pred, std_pred, e_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;66;03m# loss = torch.mean((e_pred ** 2)) #+ regularizer(model, config.rho_theta, config.tau, config.rho_w)\u001b[39;00m\n\u001b[0;32m    177\u001b[0m loss \u001b[38;5;241m=\u001b[39m gaussian_nll(e_pred, std_pred)\n",
      "Cell \u001b[1;32mIn[11], line 177\u001b[0m, in \u001b[0;36mProbabilisticStateSpaceModel.forward_train\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(T):\n\u001b[0;32m    176\u001b[0m     xt \u001b[38;5;241m=\u001b[39m x[:, t: t \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_taps]\n\u001b[1;32m--> 177\u001b[0m     y_pred_t, std_pred_t, nt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m     y_pred[:, t] \u001b[38;5;241m=\u001b[39m y_pred_t\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# get residuals\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \n\u001b[0;32m    182\u001b[0m     \u001b[38;5;66;03m# detach phi_t to invoid inplace gradient errors\u001b[39;00m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# phi_t = phi_t.detach()\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 158\u001b[0m, in \u001b[0;36mProbabilisticStateSpaceModel._step\u001b[1;34m(self, xt, nt)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# y_pred = y_pred + y_fast\u001b[39;00m\n\u001b[0;32m    157\u001b[0m std_pred \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftplus(out[:, \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-6\u001b[39m\n\u001b[1;32m--> 158\u001b[0m delta_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m alpha \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha)\n\u001b[0;32m    160\u001b[0m nt_next \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m alpha) \u001b[38;5;241m*\u001b[39m nt  \u001b[38;5;241m+\u001b[39m delta_n\n",
      "File \u001b[1;32mc:\\Users\\maild\\miniconda3\\envs\\mldrivenpeled\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maild\\miniconda3\\envs\\mldrivenpeled\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\maild\\miniconda3\\envs\\mldrivenpeled\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\maild\\miniconda3\\envs\\mldrivenpeled\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maild\\miniconda3\\envs\\mldrivenpeled\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\maild\\miniconda3\\envs\\mldrivenpeled\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def make_optimizer(mode, channel_model, noise_model, channel_model_linear, config):\n",
    "    if mode == \"linear_only\":\n",
    "        return optim.AdamW(\n",
    "            list(channel_model_linear),\n",
    "            lr=float(config.lr_linear),\n",
    "            weight_decay=float(config.wd_linear)\n",
    "        )\n",
    "    if mode == \"channel_only\":\n",
    "        return optim.AdamW(\n",
    "            list(channel_model),\n",
    "            lr=float(config.lr_channel),\n",
    "            weight_decay=float(config.wd_channel)\n",
    "        )\n",
    "\n",
    "    elif mode == \"noise_only\":\n",
    "        return optim.AdamW(\n",
    "            list(noise_model),\n",
    "            lr=float(config.lr_noise),\n",
    "            weight_decay=float(config.wd_noise)\n",
    "        )\n",
    "\n",
    "    elif mode == \"joint\":\n",
    "        return optim.AdamW(\n",
    "            list(channel_model) +\n",
    "            list(noise_model),\n",
    "            lr=float(config.lr_joint),\n",
    "            weight_decay=float(config.wd_joint)\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown mode\")\n",
    "    \n",
    "\n",
    "\n",
    "def run_experiment(config):\n",
    "    script_dir = os.getcwd()\n",
    "    config_path = os.path.join(script_dir, \"..\", \"state_space_config.yml\")\n",
    "    with open(config_path, \"r\") as f:\n",
    "        hyperparams = yaml.safe_load(f)\n",
    "\n",
    "    # Start Weights and Biases session\n",
    "    wandb.init(project=\"mldrivenpeled\",\n",
    "            config=hyperparams, tags=['channel_model'])\n",
    "    config = wandb.config\n",
    "\n",
    "    print(f\"WandB run info:\")\n",
    "    print(f\"  Name: {wandb.run.name}\")\n",
    "    print(f\"  ID: {wandb.run.id}\")\n",
    "    print(f\"  URL: {wandb.run.url}\")\n",
    "    print(\"Chosen hyperparameters for this session:\")\n",
    "    print(config)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=config.batch_size, drop_last=False)\n",
    "    test_loader = DataLoader(test_dataset)\n",
    "    val_loader = DataLoader(val_dataset, shuffle=True, batch_size=config.batch_size, drop_last=False)\n",
    "\n",
    "    # channel_model = StateSpaceModel(\n",
    "    #     deterministic_num_taps=config.deterministic_num_taps,\n",
    "    #     deterministic_hidden_size=config.deterministic_hidden_size,\n",
    "    #     stochastic_hidden_size=config.stochastic_hidden_size,\n",
    "    #     stochastic_state_size=config.stochastic_state_size,\n",
    "    #     deterministic_state_size=config.deterministic_state_size\n",
    "    # ).to(device)\n",
    "\n",
    "    channel_model = ProbabilisticStateSpaceModel(\n",
    "        num_taps=config.num_taps,\n",
    "        hidden_size=config.hidden_size,\n",
    "        state_size=config.state_size,\n",
    "        ar_taps=config.ar_taps\n",
    "    ).to(device)\n",
    "\n",
    "    # def init_xavier_zero_bias(m):\n",
    "    #     if isinstance(m, nn.Linear):\n",
    "    #         nn.init.xavier_uniform_(m.weight)\n",
    "    #         nn.init.zeros_(m.bias)\n",
    "\n",
    "    # channel_model.apply(init_xavier_zero_bias)\n",
    "\n",
    "\n",
    "\n",
    "    # channel_model_params = (\n",
    "    #     list(channel_model.deterministic_out_map.parameters()) +\n",
    "    #     list(channel_model.deterministic_state_map.parameters()) +\n",
    "    #     [channel_model.n0]\n",
    "    # )\n",
    "\n",
    "    # channel_model_linear_params = (\n",
    "    #     list(channel_model.linear_det_out_map.parameters()) +\n",
    "    #     list(channel_model.linear_det_state_map.parameters()) +\n",
    "    #     list(channel_model.linear_stoch_state_map.parameters()) +\n",
    "    #     list(channel_model.linear_stoch_out_map.parameters())\n",
    "    # )\n",
    "\n",
    "    # noise_model_params = (\n",
    "    #     list(channel_model.stochastic_out_map.parameters()) +\n",
    "    #     list(channel_model.stochastic_state_map.parameters()) +\n",
    "    #     [channel_model.z0]\n",
    "    # )\n",
    "\n",
    "\n",
    "\n",
    "    # lbfgs = torch.optim.LBFGS(\n",
    "    #         channel_model.parameters(),\n",
    "    #         lr=1.0,\n",
    "    #         max_iter=20,\n",
    "    #         history_size=10,\n",
    "    #         line_search_fn=\"strong_wolfe\"\n",
    "    #     )\n",
    "\n",
    "    # num_adam_epochs = config.num_adam_epochs\n",
    "    # num_LBFGS_epochs = config.num_LBFGS_epochs\n",
    "    # for epoch in range(num_adam_epochs):\n",
    "    #     loop = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_adam_epochs}', leave=False)\n",
    "    #     train(channel_model, adam, loop, config)\n",
    "    #     avg_val_loss = val(channel_model, val_loader, config)\n",
    "    #     scheduler.step(avg_val_loss)\n",
    "\n",
    "\n",
    "    schedule = config.training_schedule\n",
    "    epoch_counter = 0\n",
    "    for phase in schedule:\n",
    "        mode = phase[\"mode\"]\n",
    "        num_phase_epochs = phase[\"epochs\"]\n",
    "\n",
    "        # optimizer = make_optimizer(mode, channel_model_params, noise_model_params, channel_model_linear_params, config)\n",
    "        optimizer = optim.AdamW(\n",
    "            channel_model.parameters(),\n",
    "            lr=float(config.lr),\n",
    "            weight_decay=float(config.wd))\n",
    "\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1, min_lr=1e-6)\n",
    "        channel_model.mode = mode\n",
    "        for local_epoch in range(num_phase_epochs):\n",
    "            epoch_counter += 1\n",
    "            loop = tqdm(train_loader, desc=f'Epoch {epoch_counter} [{mode}]')\n",
    "            train(channel_model, optimizer, loop, config)\n",
    "            avg_val_loss = val(channel_model, val_loader, config, local_epoch)\n",
    "            scheduler.step(avg_val_loss)\n",
    "\n",
    "    def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(f\"Trainable parameters: {count_parameters(channel_model):,}\")\n",
    "    # Freeze modelj\n",
    "    for param in channel_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Save model\n",
    "    torch.save({\n",
    "        \"channel_model\": channel_model.state_dict(),\n",
    "    }, \"channel_model_final.pth\")\n",
    "\n",
    "    artifact = wandb.Artifact(\"channel_model\", type=\"model\")\n",
    "    artifact.add_file(\"channel_model_final.pth\")\n",
    "    wandb.log_artifact(artifact)\n",
    "    print(\"Finished!\")\n",
    "    run_name = wandb.run.name\n",
    "    return avg_val_loss, run_name, channel_model, train_loader, val_loader\n",
    "\n",
    "# param_grid = {\n",
    "#     'lr': [1e-3],\n",
    "#     'deterministic_hidden_size': [16],\n",
    "#     'stochastic_hidden_size': [16],\n",
    "#     'deterministic_num_taps': [4],\n",
    "#     'stochastic_state_size': [2],\n",
    "#     'deterministic_state_size': [2]\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'lr': [1e-3],\n",
    "    'hidden_size': [8, 16, 32],\n",
    "    'num_taps': [4, 8, 10, 12],\n",
    "    'state_size': [2, 4, 6],\n",
    "    'wd': [1e-2, 1e-3, 1e-4]\n",
    "}\n",
    "\n",
    "keys, values = zip(*param_grid.items())\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_config = None\n",
    "best_run_id = None\n",
    "for v in itertools.product(*values):\n",
    "    config = dict(zip(keys, v))\n",
    "\n",
    "    # load static config defaults\n",
    "    with open(\"../state_space_config.yml\", \"r\") as f:\n",
    "        base_cfg = yaml.safe_load(f)\n",
    "\n",
    "    # override base config\n",
    "    base_cfg.update(config)\n",
    "\n",
    "    val_loss, run_id, channel_model, train_loader, val_loader = run_experiment(base_cfg)\n",
    "\n",
    "    innovations = []\n",
    "    all_residuals = []\n",
    "    all_inputs = []\n",
    "    all_stds = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(device)\n",
    "            all_inputs.append(x)\n",
    "            y = y.to(device)\n",
    "            y_pred, std_pred, e_pred = channel_model.forward_train(x, y)\n",
    "            innovations.append(e_pred)\n",
    "            all_stds.append(std_pred)\n",
    "    all_inputs_tensor = torch.cat(all_inputs, dim=0)[:100, :]\n",
    "    all_innovations_tensor = torch.cat(innovations, dim=0)[:100, :]\n",
    "    al_stds_innovations_tensor = torch.cat(innovations, dim=0)[:100, :]\n",
    "\n",
    "\n",
    "    compute_billings_corrs(all_innovations_tensor, all_inputs_tensor, 20, log_wandb=True, prefix=\"val_billings_correlation\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_config = base_cfg\n",
    "        best_run_id = run_id\n",
    "        print(\"New best found!\")\n",
    "        print(f\"Best Run ID: {best_run_id}\")\n",
    "        print(f\"Best Validation Loss: {best_val_loss}\")\n",
    "        print(f\"Best Configuration: {best_config}\")\n",
    "        print(\"New best found!\")\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b87f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best Run ID: {best_run_id}\")\n",
    "print(f\"Best Validation Loss: {best_val_loss}\")\n",
    "print(f\"Best Configuration: {best_config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ecb4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load in chosen model\n",
    "\n",
    "# api = wandb.Api()\n",
    "# run = api.run(\"dylanbackprops-university-of-washington/mldrivenpeled/oibih492\") # Variable\n",
    "# model_name = \"channel_model_final\"\n",
    "# artifact = api.artifact(\"dylanbackprops-university-of-washington/mldrivenpeled/channel_model:v581\") # Variable\n",
    "# artifact_dir = artifact.download()\n",
    "# remote_config = run.config\n",
    "# run_name = run.name\n",
    "# print(\"Channel Run name:\", run_name)\n",
    "\n",
    "# channel_model = StateSpaceModel(\n",
    "#     nlayers=remote_config['nlayers'],\n",
    "#     dilation_base=remote_config['dilation_base'],\n",
    "#     num_taps=remote_config['num_taps'],\n",
    "#     hidden_channels=remote_config['hidden_channels'],\n",
    "#     learn_noise=remote_config['learn_noise'],\n",
    "#     gaussian=remote_config['gaussian']\n",
    "# ).to(device)\n",
    "\n",
    "\n",
    "# channel_model_path = os.path.join(artifact_dir, model_name + \".pth\")\n",
    "# checkpoint = torch.load(channel_model_path)\n",
    "# channel_model.load_state_dict(checkpoint[\"channel_model\"])\n",
    "\n",
    "# # Freeze before moving to device\n",
    "# for param in channel_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# channel_model = channel_model.to(device).float()\n",
    "# channel_model.eval()\n",
    "\n",
    "# print(\"Channel model parameters frozen:\",\n",
    "#       all(not param.requires_grad for param in channel_model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fbd2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b0d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "t = torch.linspace(0, 1, NUM_POINTS_FRAME)\n",
    "\n",
    "\n",
    "freqs = torch.arange(K_MIN, 3000)[::100]\n",
    "\n",
    "# # Downsample frequency sweep\n",
    "# freqs = KS[::200].cpu()\n",
    "\n",
    "\n",
    "# print(freqs)\n",
    "freq_step_hz = 10e3\n",
    "freqs_hz = freqs * freq_step_hz\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Normalize by real frequency values\n",
    "norm = plt.Normalize(vmin=min(freqs_hz), vmax=max(freqs_hz))\n",
    "cmap = cm.get_cmap('viridis')\n",
    "\n",
    "\n",
    "\n",
    "def loop_area(x, y):\n",
    "    # x, y are 1D numpy arrays\n",
    "    return 0.5 * np.trapezoid(y, x)\n",
    "\n",
    "areas = []\n",
    "for f_idx, f_hz in zip(freqs, freqs_hz):\n",
    "    x = 3 * torch.sin(2 * np.pi * f_idx * t).unsqueeze(0).to(device)\n",
    "    _, y, _, _ = channel_model(x)\n",
    "\n",
    "    x = x.squeeze().cpu().numpy()\n",
    "    y = y.squeeze().cpu().numpy()\n",
    "\n",
    "    ax.scatter(x, y, color=cmap(norm(f_hz)), s=0.5, alpha=0.5)\n",
    "    areas.append(loop_area(x,y))\n",
    "\n",
    "\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "sm.set_array([])\n",
    "\n",
    "cbar = fig.colorbar(sm, ax=ax)\n",
    "cbar.set_label(\"Frequency (kHz)\")\n",
    "tick_vals = np.linspace(min(freqs_hz), max(freqs_hz), 6)\n",
    "cbar.set_ticks(tick_vals)\n",
    "cbar.set_ticklabels((tick_vals.numpy() / 1e3).astype(int))  # display in kHz\n",
    "\n",
    "ax.set_title(\"Model Prediction for Sinusoidal Inputs at Various Frequencies\")\n",
    "ax.set_xlabel(\"Input\")\n",
    "ax.set_ylabel(\"Output\")\n",
    "ax.grid(True, linestyle=':')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldrivenpeled",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
