{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ebde2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import h5py\n",
    "import torchaudio\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.special import beta\n",
    "from torch.special import psi\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Subset\n",
    "import copy\n",
    "import math\n",
    "import wandb\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import gc\n",
    "import datetime\n",
    "import optuna\n",
    "import zarr\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "if wandb.run is not None:\n",
    "    wandb.run.tags = list(wandb.run.tags) + [\"junk\"]\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be64339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/wideband_twocarrier_3.1V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/wideband_single_carrier_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/wideband_2.83V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/time_channel_2.83V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_channel_2.83V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_channel_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/normalized_channel_2.83V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/single_X_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_wide_channel_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_wide_channel_3.5V_scale2.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_wide_channel_test_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_wide_channel_3.13V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_25MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_15MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_15MHz_3.5V_scale4.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_7.5MHz_3.5V_scale8.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_4MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_3e5-4MHz_3.5V_scale4.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/channel_3e5-4MHz_3.5V_scale2.zarr\"\n",
    "file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/channel_3e5-15MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/channel_3e5-30MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_7.5MHz_3.5V_scale4.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_1e4-15MHz_3.5V_scale4.zarr\"\n",
    "\n",
    "# Set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\") # for M chip Macs\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "# print(device)\n",
    "\n",
    "\n",
    "WIDE_BAND = False\n",
    "TIME_MODEL = True\n",
    "\n",
    "cache_path = file_path.replace(\".zarr\", \"_cached.pt\").replace(\".h5\", \"_cached.pt\")\n",
    "\n",
    "if os.path.exists(cache_path):\n",
    "    data = torch.load(cache_path, map_location=device)\n",
    "    sent_frames_time = data[\"sent_frames_time\"].to(device)\n",
    "    received_frames_time_resampled = data[\"received_frames_time\"].to(device)\n",
    "    FREQUENCIES = data[\"frequencies\"].to(device)\n",
    "    NUM_POINTS_SYMBOL = data[\"NUM_POINTS_SYMBOL\"]\n",
    "    CP_LENGTH = data[\"CP_LENGTH\"]\n",
    "    delta_f = FREQUENCIES[1] - FREQUENCIES[0]\n",
    "    KS = (FREQUENCIES / delta_f).to(torch.int)\n",
    "    K_MIN = int(KS[0].item())\n",
    "    K_MAX = int(KS[-1].item())\n",
    "    NUM_ZEROS = K_MIN - 1\n",
    "    CP_RATIO = 0.25\n",
    "    NUM_POINTS_FRAME = NUM_POINTS_SYMBOL - CP_LENGTH\n",
    "    NUM_POS_FREQS_LOW_BAND = K_MAX + 1\n",
    "    print(NUM_POINTS_FRAME  - 2 * NUM_POS_FREQS_LOW_BAND)\n",
    "    UPSAMPLING_ZEROS = (NUM_POINTS_FRAME  - 2 * NUM_POS_FREQS_LOW_BAND) // 2\n",
    "\n",
    "    print(\"Loaded from cache!\")\n",
    "else:\n",
    "    print(\"No cache found — loading original dataset...\")\n",
    "\n",
    "\n",
    "    H5 = False\n",
    "    FREQUENCIES = None\n",
    "    if H5:\n",
    "        # Extract all frame data\n",
    "        DTYPE = torch.complex64\n",
    "        sent = []\n",
    "        received = []\n",
    "        received_time = []\n",
    "        FREQUENCIES = None\n",
    "        with h5py.File(file_path, \"r\") as f:\n",
    "            # Get frequency\n",
    "            first_frame = list(f.keys())[-1]\n",
    "            FREQUENCIES = torch.tensor(f[first_frame]['freqs'][:], dtype=DTYPE).to(device).real\n",
    "            NUM_POINTS_SYMBOL = int(f[first_frame]['num_points_symbol'][()])\n",
    "            CP_LENGTH = int(f[first_frame]['cp_length'][()])\n",
    "            for frame in f:\n",
    "                group = f[frame]\n",
    "                sent.append(torch.tensor(group['sent'][:], dtype=DTYPE))\n",
    "                received.append(torch.tensor(group['received'][:], dtype=DTYPE))\n",
    "                received_time.append(torch.tensor(group['received_time'][:], dtype=DTYPE))\n",
    "    else:\n",
    "        # Open the Zarr root\n",
    "        root = zarr.open(file_path, mode=\"r\")\n",
    "\n",
    "        # Get first frame\n",
    "\n",
    "\n",
    "        # Load metadata (attributes live under .attrs)\n",
    "        sent, received, received_time = [], [], []\n",
    "\n",
    "        # Loop through frames\n",
    "        num_skipped = 0\n",
    "        for frame_key in root.group_keys():\n",
    "            try:\n",
    "                frame = root[frame_key]\n",
    "                if FREQUENCIES is None:\n",
    "                    FREQUENCIES = torch.tensor(frame[\"freqs\"][:], dtype=torch.int).real\n",
    "                    NUM_POINTS_SYMBOL = int(frame.attrs[\"num_points_symbol\"])\n",
    "                    CP_LENGTH = int(frame.attrs[\"cp_length\"])\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                sent.append(torch.tensor(frame[\"sent\"][:], dtype=torch.complex64))\n",
    "                received.append(torch.tensor(frame[\"received\"][:], dtype=torch.complex64))\n",
    "                if \"received_time\" in frame:\n",
    "                    received_time.append(torch.tensor(frame[\"received_time\"][:], dtype=torch.float32))\n",
    "            except:\n",
    "                num_skipped += 1\n",
    "                pass # skip corrupted frames\n",
    "    print(f\"Skipped {num_skipped} corrupted frames\")\n",
    "\n",
    "    sent_frames = torch.stack(sent).squeeze(1)\n",
    "    sent_frames_active = sent_frames\n",
    "    received_frames = torch.stack(received).squeeze(1)\n",
    "\n",
    "\n",
    "    delta_f = FREQUENCIES[1] - FREQUENCIES[0]\n",
    "    KS = (FREQUENCIES / delta_f).to(torch.int)\n",
    "    K_MIN = int(KS[0].item())\n",
    "    K_MAX = int(KS[-1].item())\n",
    "    NUM_ZEROS = K_MIN - 1\n",
    "    CP_RATIO = 0.25\n",
    "    NUM_POINTS_FRAME = NUM_POINTS_SYMBOL - CP_LENGTH\n",
    "    NUM_POS_FREQS_LOW_BAND = K_MAX + 1\n",
    "    UPSAMPLING_ZEROS = (NUM_POINTS_FRAME  - 2 * NUM_POS_FREQS_LOW_BAND) // 2\n",
    "\n",
    "    def normalize_inband_power(symbols_arr, inband_mask):\n",
    "        freq = torch.fft.fft(symbols_arr, dim=1)\n",
    "        freq_inband = freq[:, inband_mask]\n",
    "        pow_inband = torch.mean(torch.abs(freq_inband) ** 2, dim=1, keepdim=True)\n",
    "        scale = torch.sqrt(pow_inband)\n",
    "        normalized = symbols_arr / scale\n",
    "        return normalized\n",
    "\n",
    "    def symbols_to_time(X, num_padding_zeros: int, num_leading_zeros=0):\n",
    "        # Make hermetian symmetric\n",
    "        Nt, Nf = X.shape\n",
    "        padding_zeros = torch.zeros(Nt, num_padding_zeros, device=device)\n",
    "        leading_zeros = torch.zeros(Nt, num_leading_zeros, device=device)\n",
    "        X = torch.cat([leading_zeros, X.to(device), padding_zeros], dim=-1)\n",
    "        DC_Nyquist = torch.zeros((X.shape[0], 1), device=X.device)\n",
    "        X_hermitian = torch.flip(X, dims=[1]).conj()\n",
    "        X_full = torch.hstack([DC_Nyquist, X, DC_Nyquist, X_hermitian])\n",
    "\n",
    "        # Convert to time domain\n",
    "        x_time = torch.fft.ifft(X_full, dim=-1, norm=\"ortho\").real\n",
    "        return x_time.to(device)\n",
    "\n",
    "    if len(received_time) > 0:\n",
    "        N_shortest = min(t.size(-1) for t in received_time)\n",
    "        N_longest = max(t.size(-1) for t in received_time)\n",
    "        good_indices = [i for i, x in enumerate(received_time) if x.size(-1) == N_shortest]\n",
    "        received_frames_time = torch.stack([t for t in received_time if t.size(-1) == N_shortest], dim=0).real\n",
    "        sent_frames = sent_frames[good_indices]\n",
    "\n",
    "\n",
    "        # Handle case where Nt > 1\n",
    "    if len(sent_frames.shape) > 2:\n",
    "        print(\"Nt > 1\")\n",
    "        sent_frames = sent_frames[:, 1:-1, :]\n",
    "        received_frames = received_frames[:, 1:-1, :] # trim final harsh symbol\n",
    "        received_frames_time = received_frames_time[:, 1:-1, :]\n",
    "        sent_frames = sent_frames.reshape(sent_frames.shape[0] * sent_frames.shape[1], -1)\n",
    "        received_frames = received_frames.reshape(received_frames.shape[0] * received_frames.shape[1], -1)\n",
    "        received_frames_time = received_frames_time.reshape(received_frames_time.shape[0] * received_frames_time.shape[1], -1)\n",
    "\n",
    "    else:\n",
    "        received_frames_time = received_frames_time.squeeze(1)\n",
    "\n",
    "    # print(f\"Min length {N_shortest} | Max length {N_longest}\")\n",
    "    # print(np.unique_counts(np.array([t.size(1) for t in received_frames_time])))\n",
    "\n",
    "\n",
    "    # Attach leading and following zeros if wideband\n",
    "\n",
    "    if TIME_MODEL:\n",
    "        sent_frames_time = symbols_to_time(sent_frames, UPSAMPLING_ZEROS, NUM_ZEROS)\n",
    "        # Add cyclic prefix\n",
    "        sent_frames_time = torch.hstack((sent_frames_time[:, -CP_LENGTH:], sent_frames_time))\n",
    "        sent_frames_time = sent_frames_time[:, :-2] # Trim last sample\n",
    "        # received_frames_time_resampled = torchaudio.functional.resample(received_frames_time, orig_freq=received_frames_time.size(1), new_freq=sent_frames_time.size(1))\n",
    "        received_frames_time_resampled = received_frames_time[:, :-2] # Trim last sample\n",
    "        received_frames_time_resampled = received_frames_time_resampled - received_frames_time_resampled.mean(dim=1, keepdim=True)\n",
    "        # sent_frames_time -= sent_frames_time.min()\n",
    "\n",
    "        # enforce OSA causality\n",
    "        # sent_frames_time = sent_frames_time[:, :-1]\n",
    "        # received_frames_time_resampled = received_frames_time_resampled[:,  1:]\n",
    "        sent_frames_time = sent_frames_time.to(device)\n",
    "        received_frames_time_resampled = received_frames_time_resampled.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Create a cache path\n",
    "    cache_path = file_path.replace(\".zarr\", \"_cached.pt\").replace(\".h5\", \"_cached.pt\")\n",
    "\n",
    "    torch.save({\n",
    "        \"sent_frames_time\": sent_frames_time.cpu(),\n",
    "        \"received_frames_time\": received_frames_time_resampled.cpu(),\n",
    "        \"frequencies\": FREQUENCIES.cpu(),\n",
    "        \"NUM_POINTS_SYMBOL\": NUM_POINTS_SYMBOL,\n",
    "        \"CP_LENGTH\": CP_LENGTH\n",
    "    }, cache_path)\n",
    "\n",
    "class ChannelData(Dataset):\n",
    "        def __init__(self,\n",
    "                    sent_frames,\n",
    "                    received_frames,\n",
    "                    frequencies,\n",
    "                    transform=None,\n",
    "                    target_transform=None):\n",
    "\n",
    "            self.sent_frames = sent_frames\n",
    "            self.received_frames = received_frames\n",
    "            assert len(sent_frames) == len(received_frames)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.sent_frames)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.sent_frames[idx], self.received_frames[idx]\n",
    "\n",
    "if TIME_MODEL:\n",
    "    dataset = ChannelData(sent_frames_time, received_frames_time_resampled, FREQUENCIES)\n",
    "else:\n",
    "    dataset = ChannelData(sent_frames, received_frames, FREQUENCIES)\n",
    "\n",
    "# Split sizes\n",
    "train_size = int(0.9 * len(dataset))\n",
    "\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size  # ensures total = 100%\n",
    "\n",
    "# Perform split\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset,\n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator()\n",
    ")\n",
    "print(\"Train Size\", train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sent_frames_time[100].cpu().numpy()\n",
    "r = received_frames_time_resampled[100].cpu().numpy()\n",
    "\n",
    "corr = np.correlate(s, r, mode='full')\n",
    "T = len(s)\n",
    "zero_lag_index = T - 1\n",
    "\n",
    "lags = np.arange(-T + 1, T)  # lag axis\n",
    "plt.plot(lags, corr)\n",
    "plt.axvline(0, color='k', linestyle='--')\n",
    "plt.xlabel('Lag (samples)')\n",
    "plt.ylabel('Cross-correlation amplitude')\n",
    "plt.title('Sent vs Received Cross-Correlation (Frame 0)')\n",
    "plt.show()\n",
    "\n",
    "# Find best alignment\n",
    "best_lag = lags[np.argmax(corr)]\n",
    "print(\"Peak lag:\", best_lag)\n",
    "\n",
    "window = 4\n",
    "lags = np.arange(-window, window + 1)\n",
    "plt.plot(lags, corr[zero_lag_index - window:zero_lag_index + window + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b337ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289c7e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f20a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_MIN + len(KS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad68a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ZEROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8c0c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POINTS_FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42601e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "CP_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b475b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POINTS_SYMBOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8545c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sent_frames_time.shape, received_frames_time_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8188201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABC_time_model(nn.Module):\n",
    "    def __init__(self, theta=None):\n",
    "        super().__init__()\n",
    "        if theta is None:\n",
    "            self.theta = torch.nn.Parameter(torch.zeros(5))\n",
    "        else:\n",
    "            self.theta = theta\n",
    "        self.last_n_traj = None\n",
    "\n",
    "\n",
    "    def forward(self, x, return_n=True):\n",
    "        # x: [B, T]\n",
    "        B, T = x.shape\n",
    "        device = x.device\n",
    "        dtype = x.dtype\n",
    "        n = torch.zeros(B, device=device, dtype=dtype)\n",
    "        n_traj = torch.empty(B, T, device=device, dtype=dtype) if return_n else None\n",
    "        outputs = torch.empty(B, T, device=device, dtype=dtype)\n",
    "        theta0, theta1, theta2, theta3, theta4 = self.theta[0], self.theta[1], self.theta[2], self.theta[3], self.theta[4]\n",
    "        for t in range(T):\n",
    "            nsq = n * n\n",
    "            n = (x[:, t] + theta0 * n + theta1 * nsq + theta2 * nsq * n)\n",
    "            n = torch.tanh(n)\n",
    "            outputs[:, t] = theta3 * n + theta4 * nsq\n",
    "            assert not torch.isnan(n).any(), f\"NaN detected at step {t}\"\n",
    "            if return_n:\n",
    "                n_traj[:, t] = n\n",
    "        self.last_n_traj = n_traj\n",
    "\n",
    "        return outputs\n",
    "\n",
    "class WarmupThenPlateau:\n",
    "    \"\"\"\n",
    "    A learning rate scheduler that first performs a linear warmup for a given\n",
    "    number of steps, and then hands over control to another scheduler (e.g., ReduceLROnPlateau).\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, warmup_steps, after_scheduler, target_lr):\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.after_scheduler = after_scheduler\n",
    "        self.step_num = 0\n",
    "        self.target_lr = target_lr\n",
    "\n",
    "    def step(self, metrics=None):\n",
    "        self.step_num += 1\n",
    "\n",
    "        if self.step_num <= self.warmup_steps:\n",
    "            # During the warmup phase, linearly increase the learning rate.\n",
    "            lr_scale = self.step_num / self.warmup_steps\n",
    "            for i, param_group in enumerate(self.optimizer.param_groups):\n",
    "                param_group['lr'] = lr_scale * self.target_lr\n",
    "        else:\n",
    "            # On the first step after warmup, ensure the LR is set to the base value.\n",
    "            # This creates a clean handoff to the after_scheduler.\n",
    "            if self.step_num == self.warmup_steps + 1:\n",
    "                for i, param_group in enumerate(self.optimizer.param_groups):\n",
    "                    param_group['lr'] = self.target_lr\n",
    "\n",
    "            # After the warmup, let the after_scheduler manage the LR.\n",
    "            self.after_scheduler.step(metrics)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.0, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "        self.dtype = torch.float32\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        # Add positional encoding to the input tensor\n",
    "        x = x + self.pe[:x.size(1), :].transpose(0, 1)\n",
    "        return x\n",
    "\n",
    "class TimeSymbolEmbedding(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        # Input features: Real, Imag, Magnitude, Phase, Normalized Frequency Index\n",
    "        self.linear = nn.Linear(2, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout=0, max_len=sent_frames_time.size(1))  # Create an instance\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        # x shape: [Nt, 2Nf + 2, 2] (complex)\n",
    "        x_power = x.square().unsqueeze(-1)\n",
    "        x_combined = torch.cat([x.unsqueeze(-1), x_power], dim=-1)\n",
    "        x = self.linear(x_combined) # [Nt, Nf, d_model]\n",
    "        x = self.positional_encoding(x)\n",
    "        return x # [Nt, Nf, d_model]\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Adds information about the position of each token in the sequence.\"\"\"\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Args: x: Tensor, shape [batch_size, seq_len, embedding_dim]\"\"\"\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    \"\"\"Embeds a 1D time-series input to a d_model dimension.\"\"\"\n",
    "    def __init__(self, d_model: int):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Linear(1, d_model)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.embed(x)\n",
    "\n",
    "class TimeTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model,\n",
    "                 nhead,\n",
    "                 nlayers,\n",
    "                 dim_feedforward,\n",
    "                 dropout):\n",
    "        super().__init__()\n",
    "        self.symbol_embed = TimeSymbolEmbedding(d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model,\n",
    "                                                   nhead,\n",
    "                                                   dim_feedforward=dim_feedforward,\n",
    "                                                   batch_first=True,\n",
    "                                                   dropout=dropout)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, nlayers)\n",
    "        self.output_unembed = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        x = self.symbol_embed(x) # [Nt, 2Nf + 2, d_model]\n",
    "        x = self.transformer(x)\n",
    "        x = self.output_unembed(x).squeeze(-1) # [Nt, 2Nf + 2] linear map\n",
    "        return x # [Nt, 2Nf + 2]\n",
    "\n",
    "\n",
    "class RecursiveTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 taps,\n",
    "                 d_model,\n",
    "                 nhead,\n",
    "                 dim_feedforward,\n",
    "                 nlayers,\n",
    "                 dropout):\n",
    "        super().__init__()\n",
    "        self.taps = taps\n",
    "        self.time_embed = TimeEmbedding(d_model)\n",
    "        self.pos_embed = PositionalEncoding(d_model, max_len=taps)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model,\n",
    "                                                   nhead,\n",
    "                                                   dim_feedforward=dim_feedforward,\n",
    "                                                   batch_first=True,\n",
    "                                                   dropout=dropout)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, nlayers)\n",
    "        self.output_unembed = nn.Linear(d_model, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pad input\n",
    "        B, N = x.shape\n",
    "        x_padded = F.pad(x, (self.taps - 1, 0))\n",
    "        sliding_windows = x_padded.unfold(dimension=1, size=self.taps, step=1)\n",
    "        sliding_windows_flat = sliding_windows.reshape(-1, self.taps)\n",
    "        embedded_windows = self.time_embed(sliding_windows_flat.unsqueeze(-1))\n",
    "        embedded_windows = self.pos_embed(embedded_windows)\n",
    "        out_windows = self.transformer(embedded_windows)\n",
    "        out = out_windows[:, -1, :] # [B, N, taps, dmodel] -> [B, N, dmodel]\n",
    "        out = self.output_unembed(out) # [B, N, 1]\n",
    "        out = out.reshape(B, N)\n",
    "        out -= torch.mean(out, dim=-1, keepdim=True) # Remove DC bias\n",
    "        return out\n",
    "\n",
    "class RecursiveStateTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 taps,\n",
    "                 d_model,\n",
    "                 nhead,\n",
    "                 dim_feedforward,\n",
    "                 nlayers,\n",
    "                 dropout,\n",
    "                 state_size=1):\n",
    "        super().__init__()\n",
    "        self.taps = taps\n",
    "        self.time_embed = TimeEmbedding(d_model)\n",
    "        self.pos_embed = PositionalEncoding(d_model, max_len=taps + state_size)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model,\n",
    "                                                   nhead,\n",
    "                                                   dim_feedforward=dim_feedforward,\n",
    "                                                   batch_first=True,\n",
    "                                                   dropout=dropout)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, nlayers)\n",
    "        self.output_unembed = nn.Linear(d_model, 1 + state_size)\n",
    "        self.state_embed = nn.Linear(state_size, d_model)\n",
    "        self.state_size = state_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N = x.shape\n",
    "        device = x.device\n",
    "        # Initialize the hidden state\n",
    "        state = torch.zeros(B, self.state_size, device=device)\n",
    "        outputs = []\n",
    "        x_padded = F.pad(x, (self.taps - 1, 0))\n",
    "        for t in range(N):\n",
    "            window = x_padded[:, t:t+self.taps]\n",
    "            embedded_window = self.time_embed(window.unsqueeze(-1)) # (B, taps, d_model)\n",
    "            embedded_state = self.state_embed(state).unsqueeze(1) # (B, 1, d_model)\n",
    "            transformer_input = torch.cat([embedded_window, embedded_state], dim=1) # (B, taps+1, d_model)\n",
    "            positioned_input = self.pos_embed(transformer_input)\n",
    "            transformer_out = self.transformer(positioned_input)\n",
    "            feature_vector = transformer_out[:, -2, :] # (B, d_model)\n",
    "            prediction_and_state = self.output_unembed(feature_vector)\n",
    "            y_pred_t = prediction_and_state[:, 0]\n",
    "            state = prediction_and_state[:, 1:]\n",
    "            outputs.append(y_pred_t)\n",
    "        out = torch.stack(outputs, dim=1)\n",
    "        out -= torch.mean(out, dim=-1, keepdim=True) # Remove DC bias\n",
    "        return out\n",
    "\n",
    "\n",
    "class LearnableFrequencyNoise(nn.Module):\n",
    "    def __init__(self, sequence_length: int):\n",
    "        super().__init__()\n",
    "        num_freq_bins = sequence_length // 2 + 1\n",
    "        self.noise_psd = nn.Parameter(torch.zeros(num_freq_bins))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        noise_power = F.softplus(self.noise_psd)\n",
    "        noise_amplitude = torch.sqrt(noise_power)\n",
    "        noise_amplitude_batch = noise_amplitude.unsqueeze(0).expand(batch_size, -1)\n",
    "        random_phase = torch.exp(1j * 2 * torch.pi * torch.rand_like(noise_amplitude_batch))\n",
    "        noise_fft = noise_amplitude_batch * random_phase\n",
    "        time_domain_noise = torch.fft.irfft(noise_fft, n=seq_len)\n",
    "        return time_domain_noise\n",
    "\n",
    "class StateSpaceModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 deterministic_num_taps,\n",
    "                 deterministic_state_size,\n",
    "                 deterministic_hidden_size,\n",
    "                 stochastic_state_size,\n",
    "                 stochastic_hidden_size\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.deterministic_state_size = deterministic_state_size\n",
    "        self.stochastic_state_size = stochastic_state_size\n",
    "        self.deterministic_num_taps = deterministic_num_taps\n",
    "        self.deterministic_state_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(deterministic_hidden_size, deterministic_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(deterministic_hidden_size, deterministic_state_size)\n",
    "        )\n",
    "        self.deterministic_out_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(deterministic_hidden_size, deterministic_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(deterministic_hidden_size, 1) # Predict next scalar ouptut\n",
    "        )\n",
    "        self.stochastic_state_map = nn.Sequential(\n",
    "            nn.Linear(stochastic_state_size + deterministic_num_taps + 1, stochastic_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(stochastic_hidden_size, stochastic_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(stochastic_hidden_size, stochastic_state_size)\n",
    "        )\n",
    "        self.stochastic_out_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + stochastic_state_size + deterministic_state_size, stochastic_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(stochastic_hidden_size, stochastic_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(stochastic_hidden_size, 1)\n",
    "        )\n",
    "    def forward(self, x, y):\n",
    "        device = x.device\n",
    "        y_pred = torch.zeros_like(y, device=device)\n",
    "        e_pred = torch.zeros_like(y, device=device)\n",
    "        T = x.size(-1)\n",
    "        B = x.size(0)\n",
    "        n_t = torch.zeros(B, self.deterministic_state_size, device=device)\n",
    "        z_t = torch.zeros(B, self.stochastic_state_size, device=device)\n",
    "        # add zeros in front equal to num_taps - 1\n",
    "        x = torch.cat([torch.zeros(B, self.deterministic_num_taps - 1, device=device), x], dim=-1)\n",
    "        for t in range(T):\n",
    "            x_t = x[:, t: t + self.deterministic_num_taps]\n",
    "            y_t = y[:, t]\n",
    "            y_t_pred = self.deterministic_out_map(torch.cat([x_t, n_t], dim=-1))\n",
    "            r_t = y_t.unsqueeze(-1) - y_t_pred\n",
    "            nonlinear_noise_t = self.stochastic_out_map(torch.cat([x_t, n_t, z_t], dim=-1))\n",
    "            y_t_next_pred = y_t_pred + nonlinear_noise_t\n",
    "            y_pred[:, t] = y_t_next_pred.squeeze(-1)\n",
    "            e_t = r_t - nonlinear_noise_t\n",
    "            e_pred[:, t] = e_t.squeeze(-1)\n",
    "            # Make state updates\n",
    "            z_t = self.stochastic_state_map(torch.cat([x_t, z_t, r_t], dim=-1))\n",
    "            n_t = self.deterministic_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "        return y_pred, e_pred\n",
    "\n",
    "class TCNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation=dilation,\n",
    "            padding=0\n",
    "        )\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        self.relu = nn.ReLU()\n",
    "        self.resample = None\n",
    "        if in_channels != out_channels:\n",
    "            self.resample = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.pad(x, (self.padding, 0))\n",
    "        out = self.conv(out)\n",
    "        out = self.relu(out)\n",
    "        # bilinear_out = x * out\n",
    "        if self.resample:\n",
    "            x = self.resample(x)\n",
    "        return out + x  # residual connection\n",
    "\n",
    "\n",
    "def sample_student_t_mps(mean, std, nu):\n",
    "    '''\n",
    "    Wilson-Hilferty Approximation for chi^2 converted to scaled and shifted student t\n",
    "    '''\n",
    "    z = torch.randn_like(mean)\n",
    "    z_chi = torch.randn_like(mean)\n",
    "    chi2_approx = nu * (1 - 2/(9*nu) + z_chi * torch.sqrt(2/(9*nu))).pow(3)\n",
    "    scale = torch.sqrt(nu / (chi2_approx + 1e-6))\n",
    "    return mean + std * z * scale\n",
    "\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, nlayers=3, dilation_base=2, num_taps=10, hidden_channels=32):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "        for i in range(nlayers):\n",
    "            dilation = dilation_base ** i\n",
    "            layers.append(\n",
    "                TCNBlock(in_channels, hidden_channels, num_taps, dilation)\n",
    "            )\n",
    "            in_channels = hidden_channels\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.readout = nn.Conv1d(hidden_channels, 1, kernel_size=1)\n",
    "\n",
    "        # Calculate the total receptive field for the whole TCN stack\n",
    "        self.receptive_field = 1\n",
    "        for i in range(nlayers):\n",
    "            dilation = dilation_base ** i\n",
    "            self.receptive_field += (num_taps - 1) * dilation\n",
    "\n",
    "    def forward(self, xin1):\n",
    "        x = xin1.unsqueeze(1)   # [B,1,T]\n",
    "        # xin2 = xin2.unsqueeze(1)   # [B,1,T]\n",
    "        # x = torch.cat([xin1, xin2], dim=1)   # [B,2,T]\n",
    "        out = self.tcn(x)     # [B,H,T]\n",
    "        out = self.readout(out).squeeze(1)\n",
    "        # out = out - out.mean(dim=1, keepdim=True)  # [B,T]\n",
    "        return out\n",
    "\n",
    "\n",
    "class TCN_noise_model(nn.Module):\n",
    "    def __init__(self, nlayers=3, dilation_base=2, num_taps=10, hidden_channels=32, gaussian=True):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels = 3 # rin\n",
    "        for i in range(nlayers):\n",
    "            dilation = dilation_base ** i\n",
    "            layers.append(\n",
    "                TCNBlock(in_channels, hidden_channels, num_taps, dilation)\n",
    "            )\n",
    "            in_channels = hidden_channels\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        if gaussian:\n",
    "            self.readout = nn.Conv1d(hidden_channels, 1, kernel_size=1) # 1 channels\n",
    "        self.num_taps = num_taps\n",
    "        self.gaussian = gaussian\n",
    "\n",
    "    def forward(self, xin, rin, xin_shifted):\n",
    "        xin = xin.unsqueeze(1)\n",
    "        rin = rin.unsqueeze(1)\n",
    "        xin_shifted = xin_shifted.unsqueeze(1)\n",
    "        x = torch.cat([xin, xin_shifted, rin], dim=1)\n",
    "        # x = torch.cat([xin, rin], dim=1)    # [B,2,T]\n",
    "        out = self.tcn(x)     # [B,H,T]\n",
    "        out = self.readout(out).squeeze(1) # [B, T]\n",
    "        return out\n",
    "\n",
    "\n",
    "class TCN_channel(nn.Module):\n",
    "    def __init__(self, nlayers=3, dilation_base=2, num_taps=10, hidden_channels=32, learn_noise=False, gaussian=True):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "        for i in range(nlayers):\n",
    "            dilation = dilation_base ** i\n",
    "            layers.append(\n",
    "                TCNBlock(in_channels, hidden_channels, num_taps, dilation)\n",
    "            )\n",
    "            in_channels = hidden_channels\n",
    "        self.learn_noise = learn_noise\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        if gaussian:\n",
    "            self.readout = nn.Conv1d(hidden_channels, 2, kernel_size=1) # 2 channels mean | std\n",
    "        else:\n",
    "            self.readout = nn.Conv1d(hidden_channels, 3, kernel_size=1) # 3 channels mean | std | nu\n",
    "        self.num_taps = num_taps\n",
    "        self.gaussian = gaussian\n",
    "\n",
    "        if not gaussian:\n",
    "            with torch.no_grad():\n",
    "                # Initialize log_nu bias\n",
    "                self.readout.bias[2].fill_(48)\n",
    "\n",
    "    def forward(self, xin):\n",
    "        x = xin.unsqueeze(1)    # [B,1,T]\n",
    "        # x = torch.cat([x, torch.square(x)], dim=1)\n",
    "                # add y delayed\n",
    "        # y_lag = torch.roll(y_in, shifts=1, dims=1)\n",
    "        # y_lag[:, 0] = 0.0\n",
    "        # x = torch.stack([xin, xi], dim=1)\n",
    "        out = self.tcn(x)     # [B,H,T]\n",
    "        out = self.readout(out) # [B, 3, T] mean | std | nu\n",
    "        mean_out = out[:, 0, :]\n",
    "        log_std_out = out[:, 1, :]\n",
    "        std_out = torch.exp(log_std_out)\n",
    "        # std_out = torch.clamp(std_out, min=1e-6)\n",
    "        if not self.gaussian:\n",
    "            log_nu_out = out[:, 2, :]\n",
    "            nu_out = torch.nn.functional.softplus(log_nu_out)\n",
    "            # nu_out = torch.exp(log_nu_out)\n",
    "            nu_out = torch.clamp(nu_out, 2, 50) # nu between 2 and 50\n",
    "        mean_out = mean_out - mean_out.mean(dim=1, keepdim=True)  # [B ,T]\n",
    "\n",
    "        # # Produce noisy output\n",
    "        if self.gaussian:\n",
    "            z = torch.randn_like(mean_out)\n",
    "            noisy_out = mean_out + std_out * z\n",
    "            nu_out = torch.zeros_like(mean_out)\n",
    "        else:\n",
    "            noisy_out = sample_student_t_mps(mean_out, std_out, nu_out)\n",
    "        if self.learn_noise:\n",
    "            return noisy_out, mean_out, std_out, nu_out\n",
    "        else:\n",
    "            return mean_out, mean_out, torch.zeros_like(mean_out), torch.zeros_like(mean_out)\n",
    "\n",
    "\n",
    "class CausalCNNChannel(nn.Module):\n",
    "    def __init__(self, nlayers=4, hidden=32, kernel=13, gaussian=True, learn_noise=False):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(nlayers):\n",
    "            layers.append(nn.Conv1d(\n",
    "                in_channels=1 if i==0 else hidden,\n",
    "                out_channels=hidden,\n",
    "                kernel_size=kernel,\n",
    "                padding=kernel-1,   # temporary padding\n",
    "            ))\n",
    "            layers.append(nn.ReLU())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "        self.gaussian = gaussian\n",
    "        self.learn_noise = learn_noise\n",
    "        self.readout = nn.Conv1d(hidden, 2 if gaussian else 3, kernel_size=1)\n",
    "\n",
    "    def forward(self, xin):\n",
    "        x = xin.unsqueeze(1)\n",
    "        out = self.net(x)\n",
    "        out = out[..., :xin.size(-1)]\n",
    "        out = self.readout(out)\n",
    "        mean = out[:,0]\n",
    "        mean = mean - mean.mean(dim=1, keepdim=True)\n",
    "        std = torch.exp(out[:,1])\n",
    "        if self.gaussian:\n",
    "            return mean, mean, std, torch.zeros_like(mean)\n",
    "        else:\n",
    "            nu = torch.nn.functional.softplus(out[:,2]) + 2\n",
    "            noisy = sample_student_t_mps(mean, std, nu)\n",
    "            return noisy, mean, std, nu\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8420b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_in_band_snr(y, y_pred, band_indices):\n",
    "    y_freq = torch.fft.fft(y[CP_LENGTH:], norm=\"ortho\")[band_indices]\n",
    "    y_pred_freq = torch.fft.fft(y_pred[CP_LENGTH:], norm=\"ortho\")[band_indices]\n",
    "    noise_power = (y_freq - y_pred_freq).abs().pow(2)\n",
    "    snr_est = (y_pred_freq.abs().pow(2)) / (noise_power)\n",
    "    return snr_est.mean()\n",
    "\n",
    "def visualize_std(model, input_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        noisy_sample, mean_pred, std_pred, _ = model(input_tensor)\n",
    "\n",
    "    xin = input_tensor[0].cpu().numpy()\n",
    "    mean = mean_pred[0].cpu().numpy()\n",
    "    std = std_pred[0].cpu().numpy()\n",
    "    sample = noisy_sample[0].cpu().numpy()\n",
    "\n",
    "    time_steps = np.arange(len(xin))\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    plt.plot(time_steps, mean, label='Predicted Mean', color='blue', linewidth=2)\n",
    "\n",
    "    plt.fill_between(\n",
    "        time_steps,\n",
    "        mean - 2 * std,\n",
    "        mean + 2 * std,\n",
    "        color='blue',\n",
    "        alpha=0.2,\n",
    "        label='Uncertainty (±2σ)'\n",
    "    )\n",
    "\n",
    "    plt.plot(time_steps, sample, label='Generated Sample', color='green', alpha=0.7)\n",
    "\n",
    "    plt.title('Model Prediction with Learned Uncertainty')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=':')\n",
    "    plt.show()\n",
    "\n",
    "def compute_snr_loss_frequency_domain(y, y_pred_mean, noisy_y_pred, cp_length):\n",
    "    \"\"\"\n",
    "    Compute SNR matching loss in frequency domain.\n",
    "\n",
    "    Args:\n",
    "        y: [batch, time] - true outputs\n",
    "        y_pred_mean: [batch, time] - predicted means\n",
    "        target_snr_per_freq: [num_freq_bins] - target SNR for each frequency\n",
    "        cp_length: int - cyclic prefix length\n",
    "\n",
    "    Returns:\n",
    "        snr_loss: scalar\n",
    "    \"\"\"\n",
    "    # Remove CP\n",
    "    y_no_cp = y[:, cp_length:]\n",
    "    noisy_y_pred_no_cp = noisy_y_pred[:, cp_length:]\n",
    "    y_pred_no_cp = y_pred_mean[:, cp_length:]\n",
    "    # Compute residuals\n",
    "    predicted_noise = y_pred_no_cp - noisy_y_pred_no_cp\n",
    "    approximate_exp_noise = y_no_cp - y_pred_no_cp.detach()\n",
    "\n",
    "    # FFT to frequency domain\n",
    "    y_freq = torch.fft.rfft(y_no_cp, dim=-1, norm='ortho')\n",
    "    y_pred_freq = torch.fft.rfft(y_pred_no_cp, dim=-1, norm='ortho')\n",
    "    predicted_noise_freq = torch.fft.rfft(predicted_noise, dim=-1, norm='ortho')\n",
    "    approximate_exp_noise_freq = torch.fft.rfft(approximate_exp_noise, dim=-1, norm='ortho')\n",
    "\n",
    "    # Power per frequency (average over batch)\n",
    "    signal_power_model = y_pred_freq.abs().pow(2).mean(dim=0)\n",
    "    signal_power_exp = y_freq.abs().pow(2).mean(dim=0)\n",
    "    predicted_noise_power = predicted_noise_freq.abs().pow(2).mean(dim=0)\n",
    "    approximate_exp_noise_power = approximate_exp_noise_freq.abs().pow(2).mean(dim=0)\n",
    "\n",
    "    # Model's predicted SNR per frequency\n",
    "    predicted_snr = signal_power_model / (predicted_noise_power + 1e-8)\n",
    "    exp_snr = signal_power_exp / (approximate_exp_noise_power + 1e-8)\n",
    "\n",
    "    # MSE loss\n",
    "    snr_loss = F.mse_loss(predicted_snr, exp_snr)\n",
    "\n",
    "    return snr_loss\n",
    "\n",
    "\n",
    "def add_noise_floort(x, noise_std):\n",
    "    noise = torch.randn_like(x) * noise_std\n",
    "    return x + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a06a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ast import mod\n",
    "\n",
    "\n",
    "CP_BUFFER = CP_LENGTH\n",
    "\n",
    "\n",
    "def evm_loss(true_symbols, predicted_symbols):\n",
    "    return torch.mean((torch.abs(true_symbols - predicted_symbols)) ** 2)\n",
    "\n",
    "def train(model, noise_model, optimizer, loss_fn, loop, scheduler, train_ABC=True, slice_length=10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    batch_count = 0\n",
    "    thetas = []\n",
    "    for batch in loop:\n",
    "        x, y = batch[0], batch[1]\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # if train_ABC:\n",
    "        #     y_pred = model(x)\n",
    "        # else:\n",
    "        #     noisy_y_pred, y_pred, y_pred_std, y_pred_nu = model(x)\n",
    "        # if train_ABC:\n",
    "        #     y_pred = torch.clamp(y_pred, -1e2, 1e2)\n",
    "        # LOSS_INDICES = slice(CP_BUFFER, None)\n",
    "        # LOSS_INDICES = slice(model.num_taps, -model.num_taps)\n",
    "        LOSS_INDICES = slice(slice_length, -slice_length)\n",
    "\n",
    "        # y_pred, e_pred = model(x, y)\n",
    "\n",
    "        y_pred = model(x)\n",
    "        # calculate residuals\n",
    "        r = (y - y_pred)\n",
    "\n",
    "        # shift r s.t. only past residuals t-1 are available to the noise model\n",
    "        r_shifted = torch.roll(r, shifts=1, dims=1)\n",
    "\n",
    "        # zero-out the first timestep (no past residual available)\n",
    "        r_shifted[:, 0] = 0.0\n",
    "        x_shifted = torch.roll(x, shifts=1, dims=1)\n",
    "        x_shifted[:, 0] = 0.0\n",
    "        # send through noise inverter to create an innovation process e ~ i.i.d. N(0, 1) to T(0, 1)\n",
    "        v_pred = noise_model(x, r_shifted, x_shifted)\n",
    "\n",
    "        # trunacte window considered to avoid loss in bad regions\n",
    "        r = r[:, LOSS_INDICES]\n",
    "        e_pred = r - v_pred[:, LOSS_INDICES]\n",
    "        # y_pred_nu = y_pred_nu[:, LOSS_INDICES]\n",
    "        # y = y[:, LOSS_INDICES]\n",
    "        # y_pred = y_pred[:, LOSS_INDICES]\n",
    "        # e_pred = e_pred[:, LOSS_INDICES]\n",
    "\n",
    "        # y_pred_std = y_pred_std[:, LOSS_INDICES]\n",
    "\n",
    "        if train_ABC:\n",
    "            loss = loss_fn(y, y_pred)\n",
    "        if noise_model.gaussian:\n",
    "            loss = torch.mean((e_pred ** 2))\n",
    "            # loss = loss_fn(e_pred, e_pred_std) # Compare to standard Gaussian\n",
    "            # else:\n",
    "            #     loss = loss_fn(e_pred, std_standard, y_pred_nu) # Compare to t-dist with unit variance\n",
    "        else:\n",
    "            loss = loss_fn(y, y_pred)\n",
    "\n",
    "        mse_loss = evm_loss(y, y_pred)\n",
    "        # loss += 0.2 * mse_loss\n",
    "        if train_ABC:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        wandb.log({\"nnl_train_loss\": loss.item()})\n",
    "        wandb.log({\"mse_train_loss\": mse_loss.item()})\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        wandb.log({\"learning_rate\": lr})\n",
    "        batch_count += 1\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        if train_ABC:\n",
    "            theta_i = model.theta.detach().cpu().clone()\n",
    "            thetas.append(theta_i)\n",
    "        if batch_count % 10 == 0 and train_ABC:\n",
    "            with torch.no_grad():\n",
    "                theta_array = torch.stack(thetas, dim=0).numpy()\n",
    "                plt.figure(figsize=(8, 5))\n",
    "                print(f\"Theta: {model.theta.detach().cpu().clone()}\")\n",
    "                for i in range(theta_array.shape[1]):\n",
    "                    plt.plot(theta_array[:, i], label=f\"$\\\\theta_{i}$\")\n",
    "                plt.xlabel(\"Batch\")\n",
    "                plt.ylabel(\"Theta value\")\n",
    "                plt.title(\"Evolution of Thetas during Training\")\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "                plt.show()\n",
    "                plt.plot(model.last_n_traj[0].cpu()[:100].numpy())\n",
    "                plt.xlabel(\"Batch\")\n",
    "                plt.ylabel(\"N value\")\n",
    "                plt.title(\"Evolution of N during Training\")\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "                plt.show()\n",
    "\n",
    "    loop.close()\n",
    "    avg_train_loss = total_loss / batch_count\n",
    "\n",
    "def val(model, noise_model, loss_fn, val_loader, config, slice_length, train_abc):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    batch_count = 0\n",
    "    snr_track = []\n",
    "    y_preds = []\n",
    "    std_preds = []\n",
    "    nu_preds = []\n",
    "    true_ys = []\n",
    "    noisy_ys = []\n",
    "    val_mse_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            # noisy_y, mean_y, std_y, nu_y = model(x)\n",
    "            # mean_y, e_pred = model(x, y)\n",
    "            mean_y = model(x)\n",
    "            y_preds.append(mean_y)\n",
    "            # std_preds.append(std_y)\n",
    "            # nu_preds.append(nu_y)\n",
    "            # true_ys.append(y)\n",
    "            # noisy_ys.append(noisy_y)\n",
    "            # LOSS_INDICES = slice(CP_BUFFER, None)\n",
    "            LOSS_INDICES = slice(slice_length, -slice_length)\n",
    "            # LOSS_INDICES = slice(model.num_taps, -model.num_taps)\n",
    "            # y = y[:, LOSS_INDICES]\n",
    "            # std_y = std_y[:, LOSS_INDICES]\n",
    "            # nu_y =nu_y[:, LOSS_INDICES]\n",
    "\n",
    "            r = (y - mean_y)\n",
    "\n",
    "            # shift r s.t. only past residuals t-1 are available to the noise model\n",
    "            r_shifted = torch.roll(r, shifts=1, dims=1)\n",
    "\n",
    "            # zero-out the first timestep (no past residual available)\n",
    "            r_shifted[:, 0] = 0.0\n",
    "            x_shifted = torch.roll(x, shifts=1, dims=1)\n",
    "            x_shifted[:, 0] = 0.0\n",
    "            e_pred = r - noise_model(x, r_shifted, x_shifted)\n",
    "            # r = r[:, LOSS_INDICES]\n",
    "            # e_pred = e_pred[:, LOSS_INDICES]\n",
    "\n",
    "\n",
    "            if noise_model.gaussian:\n",
    "                loss = torch.mean((e_pred ** 2))\n",
    "                # loss = loss_fn(e_pred, e_pred_std) # Compare to standard Gaussian\n",
    "\n",
    "            mse_loss = evm_loss(y, mean_y)\n",
    "            val_mse_loss += mse_loss.item()\n",
    "            val_loss += loss.item()\n",
    "            batch_count += 1\n",
    "    avg_val_loss = (val_loss / batch_count)\n",
    "    avg_val_mse_loss = (val_mse_loss / batch_count)\n",
    "\n",
    "    # y_preds = torch.vstack(y_preds)\n",
    "    # std_preds = torch.vstack(std_preds)\n",
    "    # nu_preds = torch.vstack(nu_preds)\n",
    "    # true_ys = torch.vstack(true_ys)\n",
    "    # noisy_ys = torch.vstack(noisy_ys)\n",
    "\n",
    "\n",
    "    # noise_pred = noisy_ys - y_preds\n",
    "    # noise_power_pred_k = torch.fft.fft(noise_pred[:, CP_LENGTH:], norm='ortho', dim=-1).abs().square().mean(dim=0)\n",
    "    # signal_power_model = torch.fft.fft(y_preds[:, CP_LENGTH:], norm='ortho', dim=-1).abs().square().mean(dim=0)\n",
    "    # snr_k_model = (signal_power_model / (noise_power_pred_k + 1e-8))\n",
    "    # sample_rate = delta_f * NUM_POINTS_FRAME\n",
    "    # # snr_mag_exp = 10 * torch.log10(torch.abs(snr_k_exp) + 1e-8)\n",
    "    # snr_mag_model = 10 * torch.log10(torch.abs(snr_k_model) + 1e-8)\n",
    "    # freqs = torch.fft.fftfreq(len(snr_mag_model), d=1/sample_rate)\n",
    "    # half = len(freqs)//2\n",
    "    # freqs = freqs[:half]\n",
    "    # # snr_mag_exp = snr_mag_exp[:half]\n",
    "    # snr_mag_model = snr_mag_model[:half]\n",
    "\n",
    "\n",
    "    # fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    # # ax.plot(freqs, snr_mag_exp.cpu(), lw=1.5, color=\"steelblue\")\n",
    "    # ax.plot(freqs, snr_mag_model.cpu(), lw=1.5, color=\"orange\")\n",
    "\n",
    "    # ax.set_title(\"SNR vs Frequency (Model)\", fontsize=11)\n",
    "    # ax.set_xlabel(\"Frequency\", fontsize=9)\n",
    "    # ax.set_ylabel(\"SNR Magnitude (dB)\", fontsize=9)\n",
    "    # # ax.legend([\"Experimental SNR\", \"Model SNR\"], fontsize=9)\n",
    "    # ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "\n",
    "    # # ---- Log to WandB ----\n",
    "    # wandb.log({\"SNR_Frequency\": wandb.Image(fig)})\n",
    "    # plt.close(fig)\n",
    "\n",
    "\n",
    "    # Log both scalar and histogram\n",
    "    wandb.log({\n",
    "        \"val_nll_loss\": avg_val_loss,\n",
    "        \"avg_val_mse_loss\": avg_val_mse_loss\n",
    "    })\n",
    "\n",
    "    # print(f\"Average Val Loss: {avg_val_loss:.2e}\")\n",
    "\n",
    "    # visualize_std(model, x[:, :200])\n",
    "    return avg_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d015368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def students_t_loss(residual, y_pred_std, y_pred_nu):\n",
    "    # nu = y_pred_nu.clamp_min(2.0)\n",
    "    nu = y_pred_nu\n",
    "    z_resid = (residual) / (y_pred_std)\n",
    "    term1 = -1 * torch.lgamma((nu + 1) / 2) + 0.5 * torch.log(torch.pi * nu) + torch.lgamma(nu / 2) + torch.log(y_pred_std + 1e-8)\n",
    "    term2 = ((nu + 1) / 2) * torch.log(1 + (1 / nu) * torch.square(z_resid) + 1e-8)\n",
    "    loss = torch.mean(term1 + term2)\n",
    "    if torch.isnan(loss):\n",
    "        raise ValueError(\"NaN in loss\")\n",
    "    return loss\n",
    "\n",
    "def gaussian_nll(residual, y_pred_std):\n",
    "    term1 = 0.5 * torch.log(2 * torch.pi * (y_pred_std ** 2))\n",
    "    term2 = 0.5 * torch.square((residual) / y_pred_std)\n",
    "    loss = torch.mean(term1 + term2)\n",
    "    if torch.isnan(loss):\n",
    "        raise ValueError(\"NaN in loss\")\n",
    "    return loss\n",
    "\n",
    "\n",
    "script_dir = os.getcwd()\n",
    "config_path = os.path.join(script_dir, \"..\", \"offline_time_channel_config.yml\")\n",
    "with open(config_path, \"r\") as f:\n",
    "    hyperparams = yaml.safe_load(f)\n",
    "\n",
    "# Start Weights and Biases session\n",
    "wandb.init(project=\"mldrivenpeled\",\n",
    "           config=hyperparams, tags=['channel_model'])\n",
    "config = wandb.config\n",
    "\n",
    "RECEPTIVE_FIELD = (1 + (config.num_taps - 1) * (config.dilation_base**config.nlayers - 1) // (config.dilation_base - 1))\n",
    "\n",
    "\n",
    "print(f\"WandB run info:\")\n",
    "print(f\"  Name: {wandb.run.name}\")\n",
    "print(f\"  ID: {wandb.run.id}\")\n",
    "print(f\"  URL: {wandb.run.url}\")\n",
    "print(\"Chosen hyperparameters for this session:\")\n",
    "print(config)\n",
    "\n",
    "\n",
    "# Create dataloader\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=config.batch_size, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset)\n",
    "val_loader = DataLoader(val_dataset, shuffle=True, batch_size=config.batch_size, drop_last=False)\n",
    "\n",
    "\n",
    "\n",
    "# channel_model = ABC_time_model()\n",
    "\n",
    "channel_model = TCN(\n",
    "    nlayers=config.nlayers,\n",
    "    dilation_base=config.dilation_base,\n",
    "    num_taps=config.num_taps,\n",
    "    hidden_channels=config.hidden_channels\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# channel_model = StateSpaceModel(\n",
    "#     deterministic_num_taps=4,\n",
    "#     deterministic_hidden_size=6,\n",
    "#     stochastic_hidden_size=6,\n",
    "#     stochastic_state_size=2,\n",
    "#     deterministic_state_size=2\n",
    "# ).to(device)\n",
    "\n",
    "noise_model = TCN_noise_model(\n",
    "    nlayers=1,\n",
    "    dilation_base=2,\n",
    "    num_taps=2,\n",
    "    hidden_channels=1,\n",
    "    gaussian=True\n",
    ").to(device)\n",
    "\n",
    "# channel_model = CausalCNNChannel(\n",
    "#     nlayers=config.nlayers,\n",
    "#     hidden=config.hidden_channels,\n",
    "#     kernel=config.num_taps,\n",
    "#     gaussian=config.gaussian,\n",
    "#     learn_noise=config.learn_noise\n",
    "# ).to(device)\n",
    "\n",
    "initial_model_state = copy.deepcopy(channel_model.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(list(channel_model.parameters()) + list(noise_model.parameters()), lr=config.lr, weight_decay=1e-4)\n",
    "\n",
    "if noise_model.gaussian:\n",
    "    loss_fn = gaussian_nll\n",
    "else:\n",
    "    loss_fn = students_t_loss\n",
    "\n",
    "# loss_fn = F.mse_loss\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1, min_lr=1e-6)\n",
    "\n",
    "num_epochs = config.epochs\n",
    "for epoch in range(num_epochs):\n",
    "    loop = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False)\n",
    "    train(channel_model, noise_model, optimizer, loss_fn, loop, scheduler, train_ABC=False, slice_length=RECEPTIVE_FIELD)\n",
    "    avg_val_loss = val(channel_model, noise_model, loss_fn, val_loader, config, slice_length=RECEPTIVE_FIELD, train_abc=False)\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Trainable parameters: {count_parameters(channel_model):,}\")\n",
    "# Freeze model\n",
    "for param in channel_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Save model\n",
    "torch.save({\n",
    "    \"channel_model\": channel_model.state_dict(),\n",
    "}, \"channel_model_final.pth\")\n",
    "\n",
    "artifact = wandb.Artifact(\"channel_model\", type=\"model\")\n",
    "artifact.add_file(\"channel_model_final.pth\")\n",
    "wandb.log_artifact(artifact)\n",
    "print(\"Finished!\")\n",
    "run_name = wandb.run.name\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fbd2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(x: torch.Tensor, y: torch.Tensor, lag_max: int) -> torch.Tensor:\n",
    "    '''\n",
    "    Computes batched and normalized correlation between x and y [B, N] up to lag_max times\n",
    "    '''\n",
    "    x_centered = x - x.mean(dim=-1, keepdims=True)\n",
    "    y_centered = y - y.mean(dim=-1, keepdims=True)\n",
    "    cross_corrs = []\n",
    "    N = x_centered.shape[1]\n",
    "    assert lag_max <= N, \"Lag max too long\"\n",
    "    x_rms = torch.sqrt((1 / N) * torch.sum(x_centered ** 2, dim=-1, keepdims=True))\n",
    "    y_rms = torch.sqrt((1 / N) * torch.sum(y_centered ** 2, dim=-1, keepdims=True))\n",
    "    for lag in range(-lag_max, lag_max+1):\n",
    "        if lag >= 0:\n",
    "            shifted_x = x_centered[:, lag:]\n",
    "            shifted_y = y_centered[:, :N-lag]\n",
    "        else:\n",
    "            shifted_x = x_centered[:, :N+lag]\n",
    "            shifted_y = y_centered[:, -lag:]\n",
    "\n",
    "        corr = torch.mean(shifted_x * shifted_y, dim=-1)\n",
    "        corr_norm = torch.mean(corr / (x_rms * y_rms)) # Average across batches\n",
    "        cross_corrs.append(corr_norm)\n",
    "    return torch.stack(cross_corrs, dim=0)\n",
    "\n",
    "\n",
    "def compute_billings_corrs(batched_residuals: torch.Tensor, batched_inputs: torch.Tensor, lag_max: int):\n",
    "    '''\n",
    "    Computs the Billing's et al correlation parameters to determine whether a model\n",
    "    has captured the system's nonlinearity\n",
    "\n",
    "    Args:\n",
    "        batched_residuals: model errors of shape [B, N]\n",
    "        batched_inputs: model inputs of shape [B, N]\n",
    "    '''\n",
    "\n",
    "    confidence_value = 1.96 / np.sqrt(batched_residuals.shape[1])\n",
    "    lags = lags = np.arange(-lag_max, lag_max + 1)\n",
    "\n",
    "    phi_r_r = correlation(batched_residuals, batched_residuals, lag_max).cpu().numpy()\n",
    "    plt.plot(lags, phi_r_r)\n",
    "    plt.hlines(confidence_value, -lag_max, lag_max + 1, colors='r', linestyles='dashed', label=\"95 percent confidence interval\")\n",
    "    plt.hlines(-confidence_value, -lag_max, lag_max + 1, colors='r', linestyles='dashed')\n",
    "    plt.title(\"Residual Autocorrelation\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    phi_u_r = correlation(batched_inputs, batched_residuals, lag_max).cpu().numpy()\n",
    "    plt.plot(lags, phi_u_r)\n",
    "    plt.hlines(confidence_value, -lag_max, lag_max + 1, colors='r', linestyles='dashed', label=\"95 percent confidence interval\")\n",
    "    plt.hlines(-confidence_value, -lag_max, lag_max + 1, colors='r', linestyles='dashed')\n",
    "    plt.title(\"Input-Residual Correlation\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    shifted_product = batched_residuals[:, 1:] * batched_inputs[:, 1:]\n",
    "    phi_r_ru = correlation(batched_residuals[:, :-1], shifted_product, lag_max).cpu().numpy()\n",
    "    plt.plot(lags, phi_r_ru)\n",
    "    plt.hlines(confidence_value, -lag_max, lag_max + 1, colors='r', linestyles='dashed', label=\"95 percent confidence interval\")\n",
    "    plt.hlines(-confidence_value, -lag_max, lag_max + 1, colors='r', linestyles='dashed')\n",
    "    plt.title(\"Residual (RU)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    u_prime_squared = torch.square(batched_inputs) - torch.mean(batched_inputs ** 2, dim=-1, keepdim=True)\n",
    "    phi_u_prime_squared_r = correlation(u_prime_squared, batched_residuals, lag_max).cpu().numpy()\n",
    "    plt.plot(lags, phi_u_prime_squared_r)\n",
    "    plt.hlines(confidence_value, -lag_max, lag_max + 1, colors='r', linestyles='dashed', label=\"95 percent confidence interval\")\n",
    "    plt.hlines(-confidence_value, -lag_max, lag_max + 1, colors='r', linestyles='dashed')\n",
    "    plt.title(\"(U^2)' Residual\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    phi_u_prime_squared_r_squared = correlation(u_prime_squared, batched_residuals ** 2, lag_max).cpu().numpy()\n",
    "    plt.plot(lags, phi_u_prime_squared_r_squared)\n",
    "    plt.hlines(confidence_value, -lag_max, lag_max + 1, colors='r', linestyles='dashed', label=\"95 percent confidence interval\")\n",
    "    plt.hlines(-confidence_value, -lag_max, lag_max + 1, colors='r', linestyles='dashed')\n",
    "    plt.title(\"(U^2)' Residual ^2\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "innovations = []\n",
    "all_residuals = []\n",
    "all_nu = []\n",
    "all_std = []\n",
    "all_inputs = []\n",
    "v_preds = []\n",
    "with torch.no_grad():\n",
    "    for x, y in val_loader:\n",
    "        x = x.to(device)\n",
    "        all_inputs.append(x[:, RECEPTIVE_FIELD:])\n",
    "        y = y.to(device)\n",
    "        y_pred = channel_model(x)\n",
    "        # # Compute standardized residuals\n",
    "        r = y - y_pred\n",
    "        all_residuals.append(r[:, RECEPTIVE_FIELD:])\n",
    "        # shift r s.t. only past residuals t-1 are available to the noise model\n",
    "        r_shifted = torch.roll(r.detach(), shifts=1, dims=1)\n",
    "        # zero-out the first timestep (no past residual available)\n",
    "        r_shifted[:, 0] = 0.0\n",
    "        x_shifted = torch.roll(x, shifts=1, dims=1)\n",
    "        x_shifted[:, 0] = 0.0\n",
    "        v_pred = noise_model(x, r_shifted, x_shifted)\n",
    "        v_preds.append(v_pred[:, RECEPTIVE_FIELD:])\n",
    "        e_pred = r - v_pred\n",
    "\n",
    "        innovations.append(e_pred[:, RECEPTIVE_FIELD:])\n",
    "\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "all_inputs_tensor = torch.cat(all_inputs, dim=0)[:100, CP_LENGTH:]\n",
    "all_innovations_tensor = torch.cat(innovations, dim=0)[:100, CP_LENGTH:]\n",
    "all_v_preds_tensor = torch.cat(v_preds, dim=0)[:100, CP_LENGTH:]\n",
    "all_residuals_tensor = torch.cat(all_residuals, dim=0)[:100, CP_LENGTH:]\n",
    "\n",
    "# Ensure they are 0 mean\n",
    "all_inputs_tensor -= all_inputs_tensor.mean(dim=-1, keepdim=True)\n",
    "all_innovations_tensor -= all_innovations_tensor.mean(dim=-1, keepdim=True)\n",
    "\n",
    "all_inputs_np  = all_inputs_tensor.cpu().numpy()\n",
    "all_innovations_np  = all_innovations_tensor.cpu().numpy()\n",
    "\n",
    "sns.reset_defaults()      # resets seaborn styles\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "print(all_inputs_tensor.shape, all_innovations_tensor.shape)\n",
    "\n",
    "ljung_box = 0\n",
    "cross_corr = 0\n",
    "auto_corr = 0\n",
    "for i in range(all_inputs_np.shape[0]):\n",
    "    input_seq = all_inputs_np[i]\n",
    "    residual_seq = all_innovations_np[i]\n",
    "    x = acorr_ljungbox(residual_seq, lags=[20])\n",
    "    ljung_box += x['lb_pvalue'].values[0]\n",
    "    cross_corr += np.correlate(input_seq, residual_seq, mode='full')\n",
    "    auto_corr += np.correlate(residual_seq, residual_seq, mode='full')\n",
    "ljung_box /= all_inputs_np.shape[0]\n",
    "cross_corr /= all_inputs_np.shape[0]\n",
    "auto_corr /= all_inputs_np.shape[0]\n",
    "\n",
    "\n",
    "# Find zero-lag index\n",
    "zero_index = auto_corr.shape[0] // 2\n",
    "\n",
    "lag_window = 200\n",
    "lags = np.arange(-lag_window, lag_window)\n",
    "\n",
    "auto_window = auto_corr[-lag_window + zero_index: zero_index + lag_window]\n",
    "cross_window = cross_corr[-lag_window + zero_index: zero_index + lag_window]\n",
    "\n",
    "auto_window /= auto_corr[zero_index]\n",
    "cross_window /= np.max(np.abs(cross_window)) # normalize so signal energy does not dominate\n",
    "\n",
    "# Ljung-Box test for autocorrelation\n",
    "print(f\"Ljung-Box Value {ljung_box:.4f})\")\n",
    "sns.set_theme()\n",
    "# # Plot autocorrelation\n",
    "# plt.plot(lags, auto_window)\n",
    "# plt.title(\"Residual Autocorrelation\")\n",
    "# plt.xlabel(\"Lag\")\n",
    "# plt.ylabel(\"Normalized Corr\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(lags, cross_window)\n",
    "# # plt.axvline(RECEPTIVE_FIELD, color='red', linestyle='--', label='Receptive Field')\n",
    "# plt.title(\"Input-Residual Cross-Correlation (Raw Residuals)\")\n",
    "# plt.xlabel(\"Lag\")\n",
    "# plt.ylabel(\"Normalized Corr\")\n",
    "# # plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "print(type(all_innovations_tensor), type(all_inputs_tensor))\n",
    "compute_billings_corrs(all_innovations_tensor, all_inputs_tensor, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49829538",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_v_preds_tensor_cpu = all_v_preds_tensor.cpu().numpy()\n",
    "plt.plot(all_v_preds_tensor_cpu[0, :500])\n",
    "plt.title(\"Corrections\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()\n",
    "\n",
    "all_innovations_tensor_cpu = all_innovations_tensor.cpu().numpy()\n",
    "plt.plot(all_innovations_tensor_cpu[0, :500])\n",
    "plt.title(\"Actual Innovation Process Sample\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()\n",
    "\n",
    "all_residuals_np = all_residuals_tensor.cpu().numpy()\n",
    "plt.plot(all_residuals_np[0, :500])\n",
    "plt.title(\"Residual Process Sample\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()\n",
    "\n",
    "diff = all_residuals_np - all_v_preds_tensor_cpu\n",
    "plt.plot(diff[0, :500])\n",
    "plt.title(\"Residual - Predicted Innovation Process Sample\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\", rc={\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Arial\"],\n",
    "    \"font.size\": 6,\n",
    "    \"axes.labelsize\": 6,\n",
    "    \"axes.titlesize\": 6,\n",
    "    \"legend.fontsize\": 5,\n",
    "    \"xtick.labelsize\": 5,\n",
    "    \"ytick.labelsize\": 5,\n",
    "    \"axes.linewidth\": 0.5,\n",
    "    \"xtick.major.width\": 0.4,\n",
    "    \"ytick.major.width\": 0.4,\n",
    "    \"figure.dpi\": 300,\n",
    "})\n",
    "\n",
    "\n",
    "# ===== COMPUTE RESIDUALS FOR ALL VALIDATION SAMPLES =====\n",
    "raw_residuals = []\n",
    "all_residuals = []\n",
    "all_nu = []\n",
    "all_std = []\n",
    "all_inputs = []\n",
    "with torch.no_grad():\n",
    "    for x, y in val_loader:\n",
    "        x = x.to(device)\n",
    "        all_inputs.append(x[:, RECEPTIVE_FIELD:])\n",
    "        y = y.to(device)\n",
    "        _, mean_pred, std_pred, nu_pred = channel_model(x)\n",
    "\n",
    "        # Compute standardized residuals\n",
    "        r = y - mean_pred\n",
    "        residuals = noise_model(r)\n",
    "\n",
    "        raw_r = (y - mean_pred)\n",
    "        raw_residuals.append(raw_r[:, RECEPTIVE_FIELD:])\n",
    "        all_residuals.append(residuals[:, RECEPTIVE_FIELD:])\n",
    "        all_nu.append(nu_pred[:, RECEPTIVE_FIELD:])\n",
    "        all_std.append(std_pred[:, RECEPTIVE_FIELD:])\n",
    "\n",
    "\n",
    "\n",
    "# Flatten everything\n",
    "num_samps = 1000000\n",
    "residuals_flat = torch.cat(all_residuals, dim=0).flatten().cpu().numpy()[:num_samps]\n",
    "nu_flat = torch.cat(all_nu, dim=0).flatten().cpu().numpy()[:num_samps]\n",
    "std_flat = torch.cat(all_std, dim=0).flatten().cpu().numpy()[:num_samps]\n",
    "all_inputs_flat = torch.cat(all_inputs, dim=0).flatten().cpu().numpy()[:num_samps]\n",
    "\n",
    "print(f\"Residual std: {residuals_flat.std():.4f}\")\n",
    "print(f\"Residual mean: {residuals_flat.mean():.4f} (target: 0.0)\")\n",
    "print(f\"Number of residuals: {len(residuals_flat)}\")\n",
    "print(f\"Number of nu values: {len(nu_flat)}\")\n",
    "\n",
    "# ===== AUTO-DETECT MODEL TYPE =====\n",
    "# If nu is all zeros or very close to zero, it's a Gaussian model\n",
    "is_student_t = not channel_model.gaussian\n",
    "\n",
    "if is_student_t:\n",
    "    nu_mean = nu_flat.mean()\n",
    "    nu_std = nu_flat.std()\n",
    "    nu_min = nu_flat.min()\n",
    "    nu_max = nu_flat.max()\n",
    "    theoretical_residual_var = nu_mean / (nu_mean - 2)\n",
    "    print(f\"Model type: Student-t (ν: mean={nu_mean:.2f}, std={nu_std:.2f}, range=[{nu_min:.2f}, {nu_max:.2f}])\")\n",
    "    print(f\"Theoretical residual std: {np.sqrt(theoretical_residual_var):.4f} (for t(ν,0,1))\")\n",
    "else:\n",
    "    print(f\"Model type: Gaussian (ν values all near zero)\")\n",
    "    print(f\"Theoretical residual std: 1.0 (for N(0,1))\")\n",
    "\n",
    "# ===== COMPREHENSIVE DIAGNOSTICS =====\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Q-Q Plot\n",
    "if is_student_t:\n",
    "    # Compute PIT using matched residuals and nu values\n",
    "    pit_values = np.array([stats.t.cdf(r, nu) for r, nu in zip(residuals_flat, nu_flat)])\n",
    "\n",
    "    # Transform uniform to standard normal for Q-Q plot\n",
    "    transformed_residuals = stats.norm.ppf(pit_values)\n",
    "\n",
    "    # Remove inf values (from pit_values = 0 or 1)\n",
    "    mask = np.isfinite(transformed_residuals)\n",
    "    transformed_residuals = transformed_residuals[mask]\n",
    "\n",
    "    # Get Q-Q data without plotting automatically\n",
    "    (osm, osr), _ = stats.probplot(transformed_residuals, dist=\"norm\")\n",
    "    axes[0, 0].scatter(osm, osr, s=10, alpha=0.6)\n",
    "\n",
    "    # Add your own y = x line\n",
    "    axes[0, 0].plot([-6, 6], [-6, 6], 'r--', label='y = x (standard normal)')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].set_title('Q-Q Plot (PIT-transformed for time-varying Student-t)')\n",
    "else:\n",
    "    transformed_residuals = residuals_flat\n",
    "    (osm, osr), _ = stats.probplot(residuals_flat, dist=\"norm\")\n",
    "    axes[0, 0].scatter(osm, osr, s=10, alpha=0.6)\n",
    "    axes[0, 0].plot([-6, 6], [-6, 6], 'r--', label='y = x (standard normal)')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].set_title('Q-Q Plot vs Gaussian')\n",
    "\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Histogram with overlaid distributions\n",
    "axes[0, 1].hist(residuals_flat, bins=100, density=True, alpha=0.7,\n",
    "                edgecolor='black', label='Data')\n",
    "x = np.linspace(-5, 5, 200)\n",
    "\n",
    "# Gaussian reference\n",
    "axes[0, 1].plot(x, np.exp(-0.5*x**2)/np.sqrt(2*np.pi), 'r--', lw=1.5,\n",
    "                alpha=0.7, label='N(0,1)')\n",
    "\n",
    "# Student-t reference (use mean nu for visualization)\n",
    "if is_student_t:\n",
    "    student_t_pdf = stats.t.pdf(x, nu_mean)\n",
    "    axes[0, 1].plot(x, student_t_pdf, 'g-', lw=2, label=f't(ν={nu_mean:.1f})')\n",
    "\n",
    "axes[0, 1].set_yscale('log')\n",
    "axes[0, 1].set_xlabel('Normalized Residual')\n",
    "axes[0, 1].set_ylabel('Density (log scale)')\n",
    "axes[0, 1].set_title('Distribution (Log Scale - Shows Tails)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Variance comparison\n",
    "# Compute variance per timestep across all batches\n",
    "all_residuals_tensor = torch.cat(all_residuals, dim=0)  # [N_samples, time_length]\n",
    "all_nu_tensor = torch.cat(all_nu, dim=0)  # [N_samples, time_length]\n",
    "all_std_tensor = torch.cat(all_std, dim=0)\n",
    "\n",
    "# Empirical variance of residuals per timestep (across batch dimension)\n",
    "var_emp_per_time = all_residuals_tensor.var(dim=0).cpu().numpy()\n",
    "\n",
    "# Theoretical variance per timestep\n",
    "if is_student_t:\n",
    "    # For Student-t: Var[z] = ν/(ν-2)\n",
    "    theoretical_var_per_time = (all_nu_tensor.mean(dim=0) / (all_nu_tensor.mean(dim=0) - 2)).cpu().numpy()\n",
    "    var_label = 'Theoretical ν/(ν-2)'\n",
    "else:\n",
    "    # For Gaussian: Var[z] = 1\n",
    "    theoretical_var_per_time = np.ones_like(var_emp_per_time)\n",
    "    var_label = 'Theoretical (=1.0)'\n",
    "\n",
    "axes[1, 0].plot(var_emp_per_time, label='Empirical Var[z]', alpha=0.7, linewidth=2)\n",
    "axes[1, 0].plot(theoretical_var_per_time, label=var_label, linestyle='--', lw=2)\n",
    "axes[1, 0].axhline(var_emp_per_time.mean(), color='blue', linestyle=':', alpha=0.5,\n",
    "                   label=f'Emp Mean: {var_emp_per_time.mean():.3f}')\n",
    "axes[1, 0].axhline(theoretical_var_per_time.mean(), color='orange', linestyle=':', alpha=0.5,\n",
    "                   label=f'Theory Mean: {theoretical_var_per_time.mean():.3f}')\n",
    "axes[1, 0].set_xlabel('Time Index')\n",
    "axes[1, 0].set_ylabel('Variance')\n",
    "axes[1, 0].set_title('Variance of Standardized Residuals: Empirical vs Theoretical')\n",
    "axes[1, 0].legend(fontsize=8)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Show nu distribution over time (only for Student-t) or scale for Gaussian\n",
    "if is_student_t:\n",
    "    nu_mean_per_time = all_nu_tensor.mean(dim=0).cpu().numpy()\n",
    "    nu_std_per_time = all_nu_tensor.std(dim=0).cpu().numpy()\n",
    "\n",
    "    axes[1, 1].plot(nu_mean_per_time, label='Mean ν', linewidth=2)\n",
    "    axes[1, 1].fill_between(\n",
    "        range(len(nu_mean_per_time)),\n",
    "        nu_mean_per_time - nu_std_per_time,\n",
    "        nu_mean_per_time + nu_std_per_time,\n",
    "        alpha=0.3,\n",
    "        label='±1 std'\n",
    "    )\n",
    "    axes[1, 1].set_xlabel('Time Index')\n",
    "    axes[1, 1].set_ylabel('ν (degrees of freedom)')\n",
    "    axes[1, 1].set_title('Time-Varying ν Parameter')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "else:\n",
    "    # For Gaussian, show the scale parameter (std) variation\n",
    "    all_std_tensor = torch.cat(all_std, dim=0)\n",
    "    std_mean_per_time = all_std_tensor.mean(dim=0).cpu().numpy()\n",
    "    std_std_per_time = all_std_tensor.std(dim=0).cpu().numpy()\n",
    "\n",
    "    axes[1, 1].plot(std_mean_per_time, label='Mean σ', linewidth=2)\n",
    "    axes[1, 1].fill_between(\n",
    "        range(len(std_mean_per_time)),\n",
    "        std_mean_per_time - std_std_per_time,\n",
    "        std_mean_per_time + std_std_per_time,\n",
    "        alpha=0.3,\n",
    "        label='±1 std'\n",
    "    )\n",
    "    axes[1, 1].set_xlabel('Time Index')\n",
    "    axes[1, 1].set_ylabel('σ (scale parameter)')\n",
    "    axes[1, 1].set_title('Time-Varying Scale Parameter')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ===== STATISTICS =====\n",
    "skewness = stats.skew(residuals_flat)\n",
    "kurtosis = stats.kurtosis(residuals_flat)\n",
    "\n",
    "if is_student_t:\n",
    "    # Global KS test using PIT-transformed residuals\n",
    "    ks_stat, ks_pvalue = stats.kstest(pit_values, 'uniform')\n",
    "    test_name = \"KS test (PIT, uniform)\"\n",
    "    test_pvalue = ks_pvalue\n",
    "\n",
    "    # Theoretical kurtosis (weighted by time)\n",
    "    theoretical_kurtosis = np.mean([6/(nu-4) if nu > 4 else np.inf for nu in nu_flat])\n",
    "else:\n",
    "    _, test_pvalue = stats.shapiro(residuals_flat[:5000])\n",
    "    test_name = \"Shapiro-Wilk\"\n",
    "    theoretical_kurtosis = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b0d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "t = torch.linspace(0, 1, NUM_POINTS_FRAME)\n",
    "\n",
    "\n",
    "freqs = torch.arange(K_MIN, 3000)[::100]\n",
    "\n",
    "# # Downsample frequency sweep\n",
    "# freqs = KS[::200].cpu()\n",
    "\n",
    "\n",
    "# print(freqs)\n",
    "freq_step_hz = 10e3\n",
    "freqs_hz = freqs * freq_step_hz\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Normalize by real frequency values\n",
    "norm = plt.Normalize(vmin=min(freqs_hz), vmax=max(freqs_hz))\n",
    "cmap = cm.get_cmap('viridis')\n",
    "\n",
    "\n",
    "\n",
    "def loop_area(x, y):\n",
    "    # x, y are 1D numpy arrays\n",
    "    return 0.5 * np.trapezoid(y, x)\n",
    "\n",
    "areas = []\n",
    "for f_idx, f_hz in zip(freqs, freqs_hz):\n",
    "    x = 3 * torch.sin(2 * np.pi * f_idx * t).unsqueeze(0).to(device)\n",
    "    _, y, _, _ = channel_model(x)\n",
    "\n",
    "    x = x.squeeze().cpu().numpy()[RECEPTIVE_FIELD:]\n",
    "    y = y.squeeze().cpu().numpy()[RECEPTIVE_FIELD:]\n",
    "\n",
    "    ax.scatter(x, y, color=cmap(norm(f_hz)), s=0.5, alpha=0.5)\n",
    "    areas.append(loop_area(x,y))\n",
    "\n",
    "\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "sm.set_array([])\n",
    "\n",
    "cbar = fig.colorbar(sm, ax=ax)\n",
    "cbar.set_label(\"Frequency (kHz)\")\n",
    "tick_vals = np.linspace(min(freqs_hz), max(freqs_hz), 6)\n",
    "cbar.set_ticks(tick_vals)\n",
    "cbar.set_ticklabels((tick_vals.numpy() / 1e3).astype(int))  # display in kHz\n",
    "\n",
    "ax.set_title(\"Model Prediction for Sinusoidal Inputs at Various Frequencies\")\n",
    "ax.set_xlabel(\"Input\")\n",
    "ax.set_ylabel(\"Output\")\n",
    "ax.grid(True, linestyle=':')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(freqs, areas)\n",
    "plt.xlabel(\"Frequency (10 kHz)\")\n",
    "plt.ylabel(\"Loop Area (Memory Index)\")\n",
    "plt.title(\"Dynamic Nonlinearity vs Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e75bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_offset = config.dc_offset\n",
    "\n",
    "\n",
    "distribution_type = \"student-t\" if is_student_t else \"gaussian\"\n",
    "save_dir = f\"{run_name}_{distribution_type}_{dc_offset}\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Nature one-column figure size\n",
    "FIG_W, FIG_H = 3.46, 2.8   # inches (≈88 mm × 71 mm)\n",
    "fig, ax = plt.subplots(figsize=(FIG_W, FIG_H))\n",
    "\n",
    "if is_student_t:\n",
    "    pit_values = np.array([stats.t.cdf(r, nu) for r, nu in zip(residuals_flat, nu_flat)])\n",
    "    transformed = stats.norm.ppf(pit_values)\n",
    "    transformed = transformed[np.isfinite(transformed)]\n",
    "    if transformed.size == 0:\n",
    "        raise ValueError(\"No valid transformed residuals for Q–Q plot.\")\n",
    "    (osm, osr), _ = stats.probplot(transformed, dist=\"norm\")\n",
    "    title = \"Q–Q Plot (PIT-transformed for Student-t)\"\n",
    "else:\n",
    "    (osm, osr), _ = stats.probplot(residuals_flat, dist=\"norm\")\n",
    "    title = \"Q–Q Plot vs Gaussian\"\n",
    "\n",
    "sns.scatterplot(x=osm, y=osr, s=5, color=\"lightblue\", edgecolor=None, ax=ax, rasterized=True)\n",
    "\n",
    "lims = [min(osm.min(), osr.min()), max(osm.max(), osr.max())]\n",
    "ax.plot(lims, lims, \"r--\", lw=0.6, label=\"y = x\", c=\"black\")\n",
    "ax.set(xlabel=\"Theoretical quantiles\", ylabel=\"Sample quantiles\", title=title)\n",
    "ax.legend(frameon=False, loc=\"upper left\")\n",
    "sns.despine(trim=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"Fig1_QQplot.pdf\"), format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2️⃣ HISTOGRAM OF RESIDUALS (LOG SCALE)\n",
    "# ---------------------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(FIG_W, FIG_H))\n",
    "sns.histplot(residuals_flat, bins=100, stat=\"density\", color=\"0.5\", edgecolor=\"black\", alpha=0.7, ax=ax)\n",
    "\n",
    "x = np.linspace(-5, 5, 400)\n",
    "ax.plot(x, np.exp(-0.5*x**2)/np.sqrt(2*np.pi), \"r--\", lw=0.6, alpha=0.8, label=\"N(0,1)\")\n",
    "if is_student_t:\n",
    "    student_t_pdf = stats.t.pdf(x, nu_mean)\n",
    "    ax.plot(x, student_t_pdf, \"g-\", lw=0.8, label=f\"t(ν={nu_mean:.1f})\")\n",
    "\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set(xlabel=\"Normalized residual\", ylabel=\"Density (log scale)\",\n",
    "       title=\"Distribution (log scale – tails visible)\")\n",
    "ax.legend(frameon=False)\n",
    "sns.despine(trim=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"Fig2_ResidualHistogram.pdf\"), format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3️⃣ VARIANCE COMPARISON\n",
    "# ---------------------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(FIG_W, FIG_H))\n",
    "ax.plot(var_emp_per_time, label=\"Empirical Var[z]\", lw=0.7)\n",
    "ax.plot(theoretical_var_per_time, \"--\", lw=0.7, label=var_label)\n",
    "ax.axhline(var_emp_per_time.mean(), color=\"blue\", ls=\":\", lw=0.5,\n",
    "           label=f\"Emp Mean {var_emp_per_time.mean():.3f}\")\n",
    "ax.axhline(theoretical_var_per_time.mean(), color=\"orange\", ls=\":\", lw=0.5,\n",
    "           label=f\"Theory Mean {theoretical_var_per_time.mean():.3f}\")\n",
    "\n",
    "ax.set(xlabel=\"Time index\", ylabel=\"Variance\",\n",
    "       title=\"Variance of Standardized Residuals\")\n",
    "ax.legend(frameon=False)\n",
    "sns.despine(trim=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"Fig3_VarianceComparison.pdf\"), format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 4️⃣ TIME-VARYING ν OR σ\n",
    "# ---------------------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(FIG_W, FIG_H))\n",
    "\n",
    "if is_student_t:\n",
    "    nu_mean_per_time = all_nu_tensor.mean(dim=0).cpu().numpy()\n",
    "    nu_std_per_time  = all_nu_tensor.std(dim=0).cpu().numpy()\n",
    "    ax.plot(nu_mean_per_time, lw=0.7, label=\"Mean ν\")\n",
    "    ax.fill_between(\n",
    "        np.arange(len(nu_mean_per_time)),\n",
    "        nu_mean_per_time - nu_std_per_time,\n",
    "        nu_mean_per_time + nu_std_per_time,\n",
    "        alpha=0.3, label=\"±1 SD\")\n",
    "    ax.set_ylabel(\"ν (degrees of freedom)\")\n",
    "    title = \"Time-varying ν parameter\"\n",
    "else:\n",
    "    std_mean_per_time = all_std_tensor.mean(dim=0).cpu().numpy()\n",
    "    std_std_per_time  = all_std_tensor.std(dim=0).cpu().numpy()\n",
    "    ax.plot(std_mean_per_time, lw=0.7, label=\"Mean σ\")\n",
    "    ax.fill_between(\n",
    "        np.arange(len(std_mean_per_time)),\n",
    "        std_mean_per_time - std_std_per_time,\n",
    "        std_mean_per_time + std_std_per_time,\n",
    "        alpha=0.3, label=\"±1 SD\")\n",
    "    ax.set_ylabel(\"σ (scale parameter)\")\n",
    "    title = \"Time-varying Standard Deviation\"\n",
    "\n",
    "ax.set_xlabel(\"Time Index\")\n",
    "ax.set_title(title)\n",
    "ax.legend(frameon=False)\n",
    "sns.despine(trim=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, \"Fig4_TimeVaryingParameter.pdf\"), format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a6526",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.getcwd()\n",
    "config_path = os.path.join(script_dir, \"..\", \"offline_time_channel_config.yml\")\n",
    "with open(config_path, \"r\") as f:\n",
    "    hyperparams = yaml.safe_load(f)\n",
    "\n",
    "    wandb.init(project=\"mldrivenpeled\",\n",
    "            config=hyperparams,\n",
    "            tags=['autoencoder'])\n",
    "    config = wandb.config\n",
    "    if wandb.run.notes is None:\n",
    "        wandb.run.notes = \"\"\n",
    "    print(f\"WandB run info:\")\n",
    "    print(f\"  Name: {wandb.run.name}\")\n",
    "    print(f\"  ID: {wandb.run.id}\")\n",
    "    print(f\"  URL: {wandb.run.url}\")\n",
    "    print(\"Chosen hyperparameters for this session:\")\n",
    "    print(config)\n",
    "\n",
    "def objective(trial, tag):\n",
    "    # Sample hyperparameters\n",
    "    dilation_base = trial.suggest_categorical(\"dilation_base\", [2])\n",
    "    num_taps = trial.suggest_int(\"num_taps\", 10, 256, step=2)\n",
    "    hidden_channels = trial.suggest_int(\"hidden_channels\", 4, 64, step=8)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2)\n",
    "    nlayers = trial.suggest_categorical(\"nlayers\", [2])\n",
    "\n",
    "    local_config = {\n",
    "        \"dilation_base\": dilation_base,\n",
    "        \"num_taps\": num_taps,\n",
    "        \"hidden_channels\": hidden_channels,\n",
    "        \"lr\": lr,\n",
    "        \"epochs\": 50,\n",
    "        \"batch_size\": 16,\n",
    "        \"Nt\": 1,\n",
    "        \"Nf\": 599,\n",
    "        \"save_path\": \"./saved_models\",\n",
    "        \"nlayers\": nlayers,\n",
    "        \"weight_init\": \"default\",\n",
    "        \"scheduler_type\": \"reduce_lr_on_plateu\",\n",
    "        \"learn_noise\": True,\n",
    "        \"gaussian\": True\n",
    "    }\n",
    "\n",
    "    wandb.init(project=\"mldrivenpeled\", config=local_config, reinit=True,\n",
    "               tags=['autoencoder', f'{tag}', f'trial {trial.number}'], mode='online')\n",
    "\n",
    "    channel_model = None\n",
    "    optimizer = None\n",
    "    scheduler = None\n",
    "\n",
    "    try:\n",
    "\n",
    "        channel_model = TCN_channel(\n",
    "            nlayers=local_config['nlayers'],\n",
    "            dilation_base=local_config['dilation_base'],\n",
    "            num_taps=local_config['num_taps'],\n",
    "            hidden_channels=local_config['hidden_channels'],\n",
    "            learn_noise=local_config['learn_noise'],\n",
    "            gaussian=True\n",
    "        ).to(device)\n",
    "\n",
    "        if channel_model.gaussian:\n",
    "            loss_fn = gaussian_nll\n",
    "        else:\n",
    "            loss_fn = students_t_loss\n",
    "\n",
    "        optimizer = torch.optim.Adam(\n",
    "            list(channel_model.parameters()), lr=lr\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "        for epoch in range(local_config['epochs']):\n",
    "            loop = tqdm(train_loader, desc=f'Epoch {epoch+1}/{local_config[\"epochs\"]}', leave=False)\n",
    "            train_loss = train(channel_model, optimizer, loss_fn, loop, scheduler, train_ABC=False)\n",
    "            val_loss = val(channel_model, loss_fn, val_loader, local_config)\n",
    "\n",
    "        return val_loss\n",
    "\n",
    "    finally:\n",
    "        wandb.finish()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        del channel_model, optimizer, scheduler, loop\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "        gc.collect()\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "study_name = f\"optuna_offline_channel_model_{timestamp}\"\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=study_name, storage=\"sqlite:///optuna_results.db\", load_if_exists=True)\n",
    "study.optimize(lambda trial: objective(trial, study_name), n_trials=50)\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27e0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = \"sqlite:///optuna_results.db\"\n",
    "\n",
    "'''\n",
    "\n",
    "{'dilation_base': 2, 'num_taps': 18, 'hidden_channels': 36, 'lr': 0.003526635762093742, 'nlayers': 3}\n",
    "'''\n",
    "summaries = optuna.get_all_study_summaries(storage=storage)\n",
    "for summary in summaries:\n",
    "    print(f\"Study name: {summary.study_name}\")\n",
    "    print(f\"  Trial count: {summary.n_trials}\")\n",
    "    if summary.best_trial is not None:\n",
    "        print(f\"  Best value: {summary.best_trial.value}\")\n",
    "        print(f\"  Best params: {summary.best_trial.params}\")\n",
    "    else:\n",
    "        print(\"  No trials completed yet.\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e4f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    "    plot_slice,\n",
    "    plot_parallel_coordinate\n",
    ")\n",
    "\n",
    "# Step 1: Choose your study name (copy it from the summaries you printed earlier)\n",
    "study_name = \"optuna_offline_channel_model_20251013_142218\"\n",
    "storage = \"sqlite:///optuna_results.db\"\n",
    "\n",
    "# Step 2: Load the study\n",
    "study = optuna.load_study(study_name=study_name, storage=storage)\n",
    "\n",
    "# Step 3: Plot using interactive Plotly charts\n",
    "plot_optimization_history(study).show()\n",
    "plot_param_importances(study).show()\n",
    "plot_slice(study).show()\n",
    "plot_parallel_coordinate(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c0fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf674c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc572e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_sizes = (np.linspace(0.1, 1.0, 5) * len(train_dataset)).astype(int)\n",
    "train_sizes = [int(s) for s in train_sizes]\n",
    "\n",
    "all_val_losses = []\n",
    "print(f\"Testing training sizes: {train_sizes}\")\n",
    "\n",
    "\n",
    "wandb.init()\n",
    "for size in tqdm(train_sizes):\n",
    "    print(f\"--- Training on {size} samples ---\")\n",
    "\n",
    "    subset_indices = train_dataset.indices[:size]\n",
    "    train_subset = Subset(dataset, subset_indices)\n",
    "\n",
    "    train_loader_subset = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "\n",
    "    channel_model.load_state_dict(initial_model_state)\n",
    "    channel_model.to(device)\n",
    "    channel_model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(channel_model.parameters(), lr=1e-3)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "\n",
    "    NUM_EPOCHS = 3\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        loop = tqdm(train_loader_subset, desc=f'Epoch {epoch+1}/{NUM_EPOCHS}', leave=False)\n",
    "        train(channel_model, optimizer, loss_fn, loop, scheduler, train_ABC=False)\n",
    "        avg_val_loss = val(channel_model, loss_fn, val_loader)\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "    final_val_loss = val(channel_model, loss_fn, val_loader)\n",
    "    all_val_losses.append(final_val_loss)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, all_val_losses, 'o-', linewidth=2, markersize=8)\n",
    "plt.xlabel(\"Number of Training Samples\", fontsize=12)\n",
    "plt.ylabel(\"Final Validation Loss (log)\", fontsize=12)\n",
    "plt.title(\"Learning Curve for Channel Model\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve for least squares FIR channel model to get estimate of\n",
    "# channel delay\n",
    "\n",
    "print(sent_frames_time.shape, received_frames_time_resampled.shape)\n",
    "\n",
    "def make_toeplitz(x: torch.tensor, L):\n",
    "    N = len(x)\n",
    "    toeplitz = torch.zeros(N, L, device=x.device)\n",
    "    for i in range(N):\n",
    "        for j in range(L):\n",
    "            if i - j >= 0: # Grab lower left\n",
    "                toeplitz[i, j] = x[i - j]\n",
    "    return toeplitz\n",
    "\n",
    "def construct_A_and_b(x_sent, y_received, L):\n",
    "    N = x_sent.size(1)\n",
    "    A = torch.zeros(L, L, device=x_sent.device)\n",
    "    b = torch.zeros(L, device=x_sent.device)\n",
    "    for xi, yi in zip(x_sent, y_received):\n",
    "        X = make_toeplitz(xi, L)\n",
    "        A += X.T @ X\n",
    "        b += X.T @ yi\n",
    "    return A, b\n",
    "\n",
    "A, b = construct_A_and_b(sent_frames_time, received_frames_time_resampled, 20)\n",
    "h_best = torch.linalg.lstsq(A.cpu(), b.cpu()).solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4111a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(x_sent, y_received, h, L):\n",
    "    \"\"\"\n",
    "    Calculates the Mean Squared Error for the given filter h.\n",
    "    \"\"\"\n",
    "    B, N = x_sent.shape\n",
    "    device = x_sent.device\n",
    "    h = h.to(device)\n",
    "\n",
    "    # 1. Pad the input on the left with L-1 zeros.\n",
    "    x_padded = F.pad(x_sent, (L - 1, 0))\n",
    "\n",
    "    # 2. Create the indices for the Toeplitz matrices.\n",
    "    i = torch.arange(N, device=device).view(N, 1)\n",
    "    j = torch.arange(L, device=device).view(1, L)\n",
    "\n",
    "    # Fixed indexing - this ensures we get the right Toeplitz structure\n",
    "    indices = i + j  # Shape (N, L)\n",
    "\n",
    "    # Clamp indices to avoid any potential out-of-bounds access\n",
    "    indices = torch.clamp(indices, 0, x_padded.shape[1] - 1)\n",
    "\n",
    "    # 3. Create the batched Toeplitz matrix X\n",
    "    X = x_padded[:, indices]  # Shape (B, N, L)\n",
    "\n",
    "\n",
    "    # 5. Predict y for the entire batch using the filter h\n",
    "    y_pred = X @ h\n",
    "\n",
    "    # 6. Calculate the MSE\n",
    "    mse = F.mse_loss(y_pred, y_received)\n",
    "\n",
    "    return mse\n",
    "\n",
    "\n",
    "L = 20\n",
    "\n",
    "mse_value = calculate_mse(sent_frames_time, received_frames_time_resampled, h_best, L)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_value.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06166ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h_best.abs().numpy())\n",
    "plt.xlabel(\"Taps\")\n",
    "plt.ylabel(\"H Mag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a63691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def effective_length(h, alpha=0.98):\n",
    "    h = np.asarray(h)\n",
    "    energy = np.square(h)\n",
    "    cumu = np.cumsum(energy)\n",
    "    total = cumu[-1]\n",
    "    L_eff = int(np.searchsorted(cumu, alpha * total)) + 1\n",
    "    return L_eff\n",
    "effective_length(h_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldrivenpeled2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
