{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ebde2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import h5py\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.special import beta\n",
    "from torch.special import psi\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Subset\n",
    "import copy\n",
    "import math\n",
    "import wandb\n",
    "import itertools\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import gc\n",
    "import datetime\n",
    "import optuna\n",
    "import zarr\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "if wandb.run is not None:\n",
    "    wandb.run.tags = list(wandb.run.tags) + [\"junk\"]\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be64339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/wideband_twocarrier_3.1V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/wideband_single_carrier_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/wideband_2.83V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/time_channel_2.83V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_channel_2.83V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_channel_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/normalized_channel_2.83V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/single_X_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_wide_channel_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_wide_channel_3.5V_scale2.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_wide_channel_test_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_wide_channel_3.13V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_25MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_15MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_15MHz_3.5V_scale4.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_7.5MHz_3.5V_scale8.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_4MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_3e5-4MHz_3.5V_scale4.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/channel_3e5-4MHz_3.5V_scale2.zarr\"\n",
    "file_path = \"C:/Users/maild/mldrivenpeled/data/channel_measurements/zarr_files/test/channel_3e5-15MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/channel_3e5-15MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/channel_3e5-30MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_7.5MHz_3.5V_scale4.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_1e4-15MHz_3.5V_scale4.zarr\"\n",
    "\n",
    "# Set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\") # for M chip Macs\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "WIDE_BAND = False\n",
    "TIME_MODEL = True\n",
    "\n",
    "cache_path = file_path.replace(\".zarr\", \"_cached.pt\").replace(\".h5\", \"_cached.pt\")\n",
    "\n",
    "if os.path.exists(cache_path):\n",
    "    data = torch.load(cache_path, map_location=device)\n",
    "    sent_frames_time = data[\"sent_frames_time\"].to(device)\n",
    "    received_frames_time = data[\"received_frames_time\"].to(device)\n",
    "    FREQUENCIES = data[\"frequencies\"].to(device)\n",
    "    NUM_POINTS_SYMBOL = data[\"NUM_POINTS_SYMBOL\"]\n",
    "    CP_LENGTH = data[\"CP_LENGTH\"]\n",
    "    delta_f = FREQUENCIES[1] - FREQUENCIES[0]\n",
    "    KS = (FREQUENCIES / delta_f).to(torch.int)\n",
    "    K_MIN = int(KS[0].item())\n",
    "    K_MAX = int(KS[-1].item())\n",
    "    NUM_ZEROS = K_MIN - 1\n",
    "    CP_RATIO = 0.25\n",
    "    NUM_POINTS_FRAME = NUM_POINTS_SYMBOL - CP_LENGTH\n",
    "    NUM_POS_FREQS_LOW_BAND = K_MAX + 1\n",
    "    print(NUM_POINTS_FRAME  - 2 * NUM_POS_FREQS_LOW_BAND)\n",
    "    UPSAMPLING_ZEROS = (NUM_POINTS_FRAME  - 2 * NUM_POS_FREQS_LOW_BAND) // 2\n",
    "\n",
    "    print(\"Loaded from cache!\")\n",
    "else:\n",
    "    print(\"No cache found — loading original dataset...\")\n",
    "\n",
    "    H5 = False\n",
    "    FREQUENCIES = None\n",
    "    if H5:\n",
    "        # Extract all frame data\n",
    "        DTYPE = torch.complex64\n",
    "        sent = []\n",
    "        received = []\n",
    "        received_time = []\n",
    "        FREQUENCIES = None\n",
    "        with h5py.File(file_path, \"r\") as f:\n",
    "            # Get frequency\n",
    "            first_frame = list(f.keys())[-1]\n",
    "            FREQUENCIES = torch.tensor(f[first_frame]['freqs'][:], dtype=DTYPE).to(device).real\n",
    "            NUM_POINTS_SYMBOL = int(f[first_frame]['num_points_symbol'][()])\n",
    "            CP_LENGTH = int(f[first_frame]['cp_length'][()])\n",
    "            for frame in f:\n",
    "                group = f[frame]\n",
    "                sent.append(torch.tensor(group['sent'][:], dtype=DTYPE))\n",
    "                received.append(torch.tensor(group['received'][:], dtype=DTYPE))\n",
    "                received_time.append(torch.tensor(group['received_time'][:], dtype=DTYPE))\n",
    "    else:\n",
    "        # Open the Zarr root\n",
    "        root = zarr.open(file_path, mode=\"r\")\n",
    "\n",
    "        # Get first frame\n",
    "\n",
    "        # Load metadata (attributes live under .attrs)\n",
    "        sent, received, received_time = [], [], []\n",
    "\n",
    "        # Loop through frames\n",
    "        num_skipped = 0\n",
    "        for frame_key in root.group_keys():\n",
    "            try:\n",
    "                frame = root[frame_key]\n",
    "                if FREQUENCIES is None:\n",
    "                    FREQUENCIES = torch.tensor(frame[\"freqs\"][:], dtype=torch.int).real\n",
    "                    NUM_POINTS_SYMBOL = int(frame.attrs[\"num_points_symbol\"])\n",
    "                    CP_LENGTH = int(frame.attrs[\"cp_length\"])\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                sent.append(torch.tensor(frame[\"sent\"][:], dtype=torch.complex64))\n",
    "                received.append(torch.tensor(frame[\"received\"][:], dtype=torch.complex64))\n",
    "                if \"received_time\" in frame:\n",
    "                    received_time.append(torch.tensor(frame[\"received_time\"][:], dtype=torch.float32))\n",
    "            except:\n",
    "                num_skipped += 1\n",
    "                pass # skip corrupted frames\n",
    "    print(f\"Skipped {num_skipped} corrupted frames\")\n",
    "\n",
    "    sent_frames = torch.stack(sent).squeeze(1)\n",
    "    sent_frames_active = sent_frames\n",
    "    received_frames = torch.stack(received).squeeze(1)\n",
    "\n",
    "\n",
    "    delta_f = FREQUENCIES[1] - FREQUENCIES[0]\n",
    "    KS = (FREQUENCIES / delta_f).to(torch.int)\n",
    "    K_MIN = int(KS[0].item())\n",
    "    K_MAX = int(KS[-1].item())\n",
    "    NUM_ZEROS = K_MIN - 1\n",
    "    CP_RATIO = 0.25\n",
    "    NUM_POINTS_FRAME = NUM_POINTS_SYMBOL - CP_LENGTH\n",
    "    NUM_POS_FREQS_LOW_BAND = K_MAX + 1\n",
    "    UPSAMPLING_ZEROS = (NUM_POINTS_FRAME  - 2 * NUM_POS_FREQS_LOW_BAND) // 2\n",
    "\n",
    "\n",
    "    def symbols_to_time(X, num_padding_zeros: int, num_leading_zeros=0):\n",
    "        # Make hermetian symmetric\n",
    "        Nt, Nf = X.shape\n",
    "        padding_zeros = torch.zeros(Nt, num_padding_zeros, device=device)\n",
    "        leading_zeros = torch.zeros(Nt, num_leading_zeros, device=device)\n",
    "        X = torch.cat([leading_zeros, X.to(device), padding_zeros], dim=-1)\n",
    "        DC_Nyquist = torch.zeros((X.shape[0], 1), device=X.device)\n",
    "        X_hermitian = torch.flip(X, dims=[1]).conj()\n",
    "        X_full = torch.hstack([DC_Nyquist, X, DC_Nyquist, X_hermitian])\n",
    "\n",
    "        # Convert to time domain\n",
    "        x_time = torch.fft.ifft(X_full, dim=-1, norm=\"ortho\").real\n",
    "        return x_time.to(device)\n",
    "\n",
    "    if len(received_time) > 0:\n",
    "        N_shortest = min(t.size(-1) for t in received_time)\n",
    "        N_longest = max(t.size(-1) for t in received_time)\n",
    "        good_indices = [i for i, x in enumerate(received_time) if x.size(-1) == N_shortest]\n",
    "        received_frames_time = torch.stack([t for t in received_time if t.size(-1) == N_shortest], dim=0).real.squeeze(1)\n",
    "        sent_frames = sent_frames[good_indices]\n",
    "\n",
    "\n",
    "    sent_frames_time = symbols_to_time(sent_frames, UPSAMPLING_ZEROS, NUM_ZEROS)\n",
    "    # Add cyclic prefix\n",
    "    sent_frames_time = torch.hstack((sent_frames_time[:, -CP_LENGTH:], sent_frames_time))\n",
    "    received_frames_time = received_frames_time - received_frames_time.mean(dim=1, keepdim=True)\n",
    "\n",
    "\n",
    "\n",
    "    # enforce OSA causality\n",
    "    # sent_frames_time = sent_frames_time[:, :-1]\n",
    "    # received_frames_time_resampled = received_frames_time_resampled[:,  1:]\n",
    "    sent_frames_time = sent_frames_time.to(device)\n",
    "    received_frames_time = received_frames_time.to(device)\n",
    "\n",
    "    TRUNCATE_SIZE = slice(CP_LENGTH, CP_LENGTH + 100)\n",
    "    sent_frames_time = sent_frames_time[:, TRUNCATE_SIZE]\n",
    "    received_frames_time = received_frames_time[:, TRUNCATE_SIZE]\n",
    "\n",
    "    # Create a cache path\n",
    "    cache_path = file_path.replace(\".zarr\", \"_cached.pt\").replace(\".h5\", \"_cached.pt\")\n",
    "\n",
    "    torch.save({\n",
    "        \"sent_frames_time\": sent_frames_time.cpu(),\n",
    "        \"received_frames_time\": received_frames_time.cpu(),\n",
    "        \"frequencies\": FREQUENCIES.cpu(),\n",
    "        \"NUM_POINTS_SYMBOL\": NUM_POINTS_SYMBOL,\n",
    "        \"CP_LENGTH\": CP_LENGTH\n",
    "    }, cache_path)\n",
    "\n",
    "class ChannelData(Dataset):\n",
    "        def __init__(self,\n",
    "                    sent_frames,\n",
    "                    received_frames,\n",
    "                    frequencies,\n",
    "                    transform=None,\n",
    "                    target_transform=None):\n",
    "\n",
    "            self.sent_frames = sent_frames\n",
    "            self.received_frames = received_frames\n",
    "            assert len(sent_frames) == len(received_frames)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.sent_frames)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.sent_frames[idx], self.received_frames[idx]\n",
    "\n",
    "if TIME_MODEL:\n",
    "    dataset = ChannelData(sent_frames_time, received_frames_time, FREQUENCIES)\n",
    "else:\n",
    "    dataset = ChannelData(sent_frames, received_frames, FREQUENCIES)\n",
    "\n",
    "# Split sizes\n",
    "train_size = int(0.9 * len(dataset))\n",
    "\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size  # ensures total = 100%\n",
    "\n",
    "# Perform split\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset,\n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator()\n",
    ")\n",
    "print(\"Train Size\", train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sent_frames_time[100].cpu().numpy()\n",
    "r = received_frames_time[100].cpu().numpy()\n",
    "\n",
    "print(s.shape, r.shape)\n",
    "corr = np.correlate(s, r, mode='full')\n",
    "T = len(s)\n",
    "zero_lag_index = T - 1\n",
    "\n",
    "lags = np.arange(-T + 1, T)  # lag axis\n",
    "plt.plot(lags, corr)\n",
    "plt.axvline(0, color='k', linestyle='--')\n",
    "plt.xlabel('Lag (samples)')\n",
    "plt.ylabel('Cross-correlation amplitude')\n",
    "plt.title('Sent vs Received Cross-Correlation (Frame 0)')\n",
    "plt.show()\n",
    "\n",
    "# Find best alignment\n",
    "best_lag = lags[np.argmax(corr)]\n",
    "print(\"Peak lag:\", best_lag)\n",
    "\n",
    "window = 4\n",
    "lags = np.arange(-window, window + 1)\n",
    "plt.plot(lags, corr[zero_lag_index - window:zero_lag_index + window + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8188201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StateSpaceModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 deterministic_num_taps,\n",
    "                 deterministic_state_size,\n",
    "                 deterministic_hidden_size,\n",
    "                 stochastic_state_size,\n",
    "                 stochastic_hidden_size\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.deterministic_state_size = deterministic_state_size\n",
    "        self.stochastic_state_size = stochastic_state_size\n",
    "        self.deterministic_num_taps = deterministic_num_taps\n",
    "        self.deterministic_state_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(deterministic_hidden_size, deterministic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(deterministic_hidden_size, deterministic_state_size)\n",
    "        )\n",
    "        self.deterministic_out_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(deterministic_hidden_size, deterministic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(deterministic_hidden_size, 1) # Predict next scalar ouptut\n",
    "        )\n",
    "        self.stochastic_state_map = nn.Sequential(\n",
    "            nn.Linear(stochastic_state_size + deterministic_num_taps + 1, stochastic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(stochastic_hidden_size, stochastic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(stochastic_hidden_size, stochastic_state_size)\n",
    "        )\n",
    "        self.stochastic_out_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + stochastic_state_size + deterministic_state_size, stochastic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(stochastic_hidden_size, 1)\n",
    "        )\n",
    "\n",
    "        self.n0 = nn.Parameter(torch.zeros(deterministic_state_size))\n",
    "        self.z0 = nn.Parameter(torch.zeros(stochastic_state_size))\n",
    "    def forward(self, x, y):\n",
    "        device = x.device\n",
    "        y_pred = torch.zeros_like(y, device=device)\n",
    "        e_pred = torch.zeros_like(y, device=device)\n",
    "        T = x.size(-1)\n",
    "        B = x.size(0)\n",
    "        # n_t = torch.zeros(B, self.deterministic_state_size, device=device)\n",
    "        # z_t = torch.zeros(B, self.stochastic_state_size, device=device)\n",
    "        # use learned initial states, broadcast to batch\n",
    "        n_t = self.n0.unsqueeze(0).expand(B, -1)  # [B, nx]\n",
    "        z_t = self.z0.unsqueeze(0).expand(B, -1)  # [B, nz]\n",
    "        # add zeros in front equal to num_taps - 1\n",
    "        x = torch.cat([torch.zeros(B, self.deterministic_num_taps - 1, device=device), x], dim=-1)\n",
    "        for t in range(T):\n",
    "            x_t = x[:, t: t + self.deterministic_num_taps]\n",
    "            y_t = y[:, t]\n",
    "            y_t_pred = self.deterministic_out_map(torch.cat([x_t, n_t], dim=-1))\n",
    "            r_t = y_t.unsqueeze(-1) - y_t_pred\n",
    "            nonlinear_noise_t = self.stochastic_out_map(torch.cat([x_t, n_t, z_t], dim=-1))\n",
    "            y_t_next_pred = y_t_pred + nonlinear_noise_t\n",
    "            y_pred[:, t] = y_t_next_pred.squeeze(-1)\n",
    "            e_t = r_t - nonlinear_noise_t\n",
    "            e_pred[:, t] = e_t.squeeze(-1)\n",
    "            # Make state updates\n",
    "            z_t = self.stochastic_state_map(torch.cat([x_t, z_t, r_t], dim=-1))\n",
    "            n_t = self.deterministic_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "        return y_pred, e_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8420b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_std(model, input_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        noisy_sample, mean_pred, std_pred, _ = model(input_tensor)\n",
    "\n",
    "    xin = input_tensor[0].cpu().numpy()\n",
    "    mean = mean_pred[0].cpu().numpy()\n",
    "    std = std_pred[0].cpu().numpy()\n",
    "    sample = noisy_sample[0].cpu().numpy()\n",
    "\n",
    "    time_steps = np.arange(len(xin))\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    plt.plot(time_steps, mean, label='Predicted Mean', color='blue', linewidth=2)\n",
    "\n",
    "    plt.fill_between(\n",
    "        time_steps,\n",
    "        mean - 2 * std,\n",
    "        mean + 2 * std,\n",
    "        color='blue',\n",
    "        alpha=0.2,\n",
    "        label='Uncertainty (±2σ)'\n",
    "    )\n",
    "\n",
    "    plt.plot(time_steps, sample, label='Generated Sample', color='green', alpha=0.7)\n",
    "\n",
    "    plt.title('Model Prediction with Learned Uncertainty')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=':')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a06a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularizer(model, rho_theta, tau, rho_w):\n",
    "    # θ = all parameters of both models\n",
    "    l2_theta = 0.0\n",
    "    l1_theta = 0.0\n",
    "    for p in list(model.parameters()):\n",
    "        l2_theta = l2_theta + torch.sum(p ** 2)\n",
    "        l1_theta = l1_theta + torch.sum(p.abs())\n",
    "\n",
    "    # \\hat w_0 = [n0, z0] from the state-space model\n",
    "    w0_vec = torch.cat([model.n0.view(-1), model.z0.view(-1)])\n",
    "    l2_w0 = torch.sum(w0_vec ** 2)\n",
    "\n",
    "    reg = 0.5 * float(rho_theta) * l2_theta + float(tau) * l1_theta + 0.5 * float(rho_w) * l2_w0\n",
    "    return reg\n",
    "\n",
    "def train(model, optimizer, loop, config):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    batch_count = 0\n",
    "    thetas = []\n",
    "    for batch in loop:\n",
    "        x, y = batch[0], batch[1]\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred, e_pred = model(x, y)\n",
    "        loss = torch.mean((e_pred ** 2)) + regularizer(model, config.rho_theta, config.tau, config.rho_w)\n",
    "        mse_loss = F.mse_loss(y, y_pred)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        wandb.log({\"innovation_train_loss\": loss.item()})\n",
    "        wandb.log({\"mse_train_loss\": mse_loss.item()})\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        wandb.log({\"learning_rate\": lr})\n",
    "        batch_count += 1\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    loop.close()\n",
    "    return model\n",
    "\n",
    "def val(model, val_loader, config):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    batch_count = 0\n",
    "    y_preds = []\n",
    "    val_mse_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            mean_y, e_pred = model(x, y)\n",
    "            y_preds.append(mean_y)\n",
    "            loss = torch.mean((e_pred ** 2))\n",
    "            mse_loss = F.mse_loss(y, mean_y)\n",
    "            val_mse_loss += mse_loss.item()\n",
    "            val_loss += loss.item()\n",
    "            batch_count += 1\n",
    "    avg_val_loss = (val_loss / batch_count)\n",
    "    avg_val_mse_loss = (val_mse_loss / batch_count)\n",
    "    wandb.log({\n",
    "        \"val_innovation_loss\": avg_val_loss,\n",
    "        \"avg_val_mse_loss\": avg_val_mse_loss\n",
    "    })\n",
    "    return avg_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6978226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(x: torch.Tensor, y: torch.Tensor, lag_max: int) -> torch.Tensor:\n",
    "    '''\n",
    "    Computes batched and normalized correlation between x and y [B, N] up to lag_max times\n",
    "    '''\n",
    "    x_centered = x - x.mean(dim=-1, keepdims=True)\n",
    "    y_centered = y - y.mean(dim=-1, keepdims=True)\n",
    "    cross_corrs = []\n",
    "    N = x_centered.shape[1]\n",
    "    assert lag_max <= N, \"Lag max too long\"\n",
    "    x_rms = torch.sqrt((1 / N) * torch.sum(x_centered ** 2, dim=-1, keepdims=True))\n",
    "    y_rms = torch.sqrt((1 / N) * torch.sum(y_centered ** 2, dim=-1, keepdims=True))\n",
    "    for lag in range(-lag_max, lag_max+1):\n",
    "        if lag >= 0:\n",
    "            shifted_x = x_centered[:, lag:]\n",
    "            shifted_y = y_centered[:, :N-lag]\n",
    "        else:\n",
    "            shifted_x = x_centered[:, :N+lag]\n",
    "            shifted_y = y_centered[:, -lag:]\n",
    "\n",
    "        corr = torch.mean(shifted_x * shifted_y, dim=-1, keepdim=True)\n",
    "        corr_norm = torch.mean(corr / (x_rms * y_rms), dim=0) # Average across batches\n",
    "        cross_corrs.append(corr_norm)\n",
    "\n",
    "    return torch.stack(cross_corrs, dim=0)\n",
    "\n",
    "\n",
    "def compute_billings_corrs(batched_residuals: torch.Tensor, batched_inputs: torch.Tensor,\n",
    "                           lag_max: int, log_wandb: bool = False, prefix: str = \"billings_correlation\"):\n",
    "    '''\n",
    "    Computs the Billing's et al correlation parameters to determine whether a model\n",
    "    has captured the system's nonlinearity\n",
    "\n",
    "    Args:\n",
    "        batched_residuals: model errors of shape [B, N]\n",
    "        batched_inputs: model inputs of shape [B, N]\n",
    "    '''\n",
    "\n",
    "\n",
    "    batched_residuals = batched_residuals - batched_residuals.mean(dim=-1, keepdim=True)\n",
    "    batched_inputs = batched_inputs - batched_inputs.mean(dim=-1, keepdim=True) \n",
    "\n",
    "    def _plot_and_log(y_np, title, key):\n",
    "        fig, ax = plt.subplots(figsize=(6, 3.5))\n",
    "        ax.plot(lags, y_np.ravel(), label=key)\n",
    "        ax.hlines(confidence_value, -lag_max, lag_max, colors='r', linestyles='dashed', label=\"95% CI\")\n",
    "        ax.hlines(-confidence_value, -lag_max, lag_max, colors='r', linestyles='dashed')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"Lag\")\n",
    "        ax.set_ylabel(\"Correlation\")\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if log_wandb:\n",
    "            wandb.log({f\"{prefix}/{key}\": wandb.Image(fig)})\n",
    "        else:\n",
    "            plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "    confidence_value = 1.96 / np.sqrt(batched_residuals.shape[1])\n",
    "    lags = lags = np.arange(-lag_max, lag_max + 1)\n",
    "\n",
    "    phi_r_r = correlation(batched_residuals, batched_residuals, lag_max).cpu().numpy()\n",
    "    _plot_and_log(phi_r_r, \"Residual Autocorrelation\", \"residual_autocorr\")\n",
    "    phi_u_r = correlation(batched_inputs, batched_residuals, lag_max).cpu().numpy()\n",
    "    _plot_and_log(phi_u_r, \"Input-Residual Correlation\", \"input_residual_corr\")\n",
    "    # shifted_product = batched_residuals[:, 1:] * batched_inputs[:, 1:]\n",
    "    phi_r_ru = correlation(batched_residuals, batched_inputs * batched_residuals, lag_max).cpu().numpy()\n",
    "    _plot_and_log(phi_r_ru, \"Residual-Residual*Input Correlation\", \"residual_residual_input_corr\")\n",
    "\n",
    "    u_prime_squared = torch.square(batched_inputs) - torch.mean(batched_inputs ** 2, dim=-1, keepdim=True)\n",
    "    phi_u_prime_squared_r = correlation(u_prime_squared, batched_residuals, lag_max).cpu().numpy()\n",
    "    _plot_and_log(phi_u_prime_squared_r, \"(U^2)' Residual Correlation\", \"u_squared_prime_residual_corr\")\n",
    "\n",
    "    phi_u_prime_squared_r_squared = correlation(u_prime_squared, batched_residuals ** 2, lag_max).cpu().numpy()\n",
    "    _plot_and_log(phi_u_prime_squared_r_squared, \"(U^2)' Residual ^2 Correlation\", \"u_squared_prime_residual_squared_corr\")\n",
    "\n",
    "\n",
    "sns.reset_defaults()      # resets seaborn styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d015368",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create dataloader\n",
    "\n",
    "def run_experiment(config):\n",
    "    script_dir = os.getcwd()\n",
    "    config_path = os.path.join(script_dir, \"..\", \"state_space_config.yml\")\n",
    "    with open(config_path, \"r\") as f:\n",
    "        hyperparams = yaml.safe_load(f)\n",
    "\n",
    "    # Start Weights and Biases session\n",
    "    wandb.init(project=\"mldrivenpeled\",\n",
    "            config=hyperparams, tags=['channel_model'])\n",
    "    config = wandb.config\n",
    "\n",
    "    print(f\"WandB run info:\")\n",
    "    print(f\"  Name: {wandb.run.name}\")\n",
    "    print(f\"  ID: {wandb.run.id}\")\n",
    "    print(f\"  URL: {wandb.run.url}\")\n",
    "    print(\"Chosen hyperparameters for this session:\")\n",
    "    print(config)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=config.batch_size, drop_last=False)\n",
    "    test_loader = DataLoader(test_dataset)\n",
    "    val_loader = DataLoader(val_dataset, shuffle=True, batch_size=config.batch_size, drop_last=False)\n",
    "\n",
    "    channel_model = StateSpaceModel(\n",
    "        deterministic_num_taps=config.deterministic_num_taps,\n",
    "        deterministic_hidden_size=config.deterministic_hidden_size,\n",
    "        stochastic_hidden_size=config.stochastic_hidden_size,\n",
    "        stochastic_state_size=config.stochastic_state_size,\n",
    "        deterministic_state_size=config.deterministic_state_size\n",
    "    ).to(device)\n",
    "\n",
    "    def init_xavier_zero_bias(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "    channel_model.apply(init_xavier_zero_bias)\n",
    "\n",
    "    initial_model_state = copy.deepcopy(channel_model.state_dict())\n",
    "\n",
    "    adam = optim.AdamW(list(channel_model.parameters()), lr=config.lr, weight_decay=1e-4)\n",
    "\n",
    "    lbfgs = torch.optim.LBFGS(\n",
    "            channel_model.parameters(),\n",
    "            lr=1.0,\n",
    "            max_iter=20,\n",
    "            history_size=10,\n",
    "            line_search_fn=\"strong_wolfe\"\n",
    "        )\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(adam, mode='min', factor=0.5, patience=1, min_lr=1e-6)\n",
    "\n",
    "    num_adam_epochs = config.num_adam_epochs\n",
    "    num_LBFGS_epochs = config.num_LBFGS_epochs\n",
    "    for epoch in range(num_adam_epochs):\n",
    "        loop = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_adam_epochs}', leave=False)\n",
    "        train(channel_model, adam, loop, config)\n",
    "        avg_val_loss = val(channel_model, val_loader, config)\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "    # X_full = torch.cat([b[0] for b in train_loader], dim=0).to(device)\n",
    "    # Y_full = torch.cat([b[1] for b in train_loader], dim=0).to(device)\n",
    "\n",
    "    # X_val_full = torch.cat([b[0] for b in val_loader], dim=0).to(device)\n",
    "    # Y_val_full = torch.cat([b[1] for b in val_loader], dim=0).to(device)\n",
    "\n",
    "\n",
    "    # for epoch in tqdm(range(num_LBFGS_epochs), desc=\"LBFGS Refinement\", leave=False):\n",
    "    #     def closure():\n",
    "    #         lbfgs.zero_grad()\n",
    "    #         y_pred, e_pred = channel_model(X_full, Y_full)\n",
    "    #         loss = torch.mean(e_pred ** 2)\n",
    "    #         loss.backward()\n",
    "    #         mse_loss = F.mse_loss(Y_full, y_pred)\n",
    "    #         wandb.log({\"mse_train_loss\": mse_loss.item()})\n",
    "    #         return loss\n",
    "\n",
    "    #     loss = lbfgs.step(closure)\n",
    "    #     loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    #     wandb.log({\"innovation_train_loss\": loss.item()})\n",
    "\n",
    "    #     with torch.no_grad():\n",
    "    #         y_val_pred, e_val_pred = channel_model(X_val_full, Y_val_full)\n",
    "    #         mse_loss = F.mse_loss(Y_val_full, y_val_pred)\n",
    "    #         val_loss = torch.mean(e_val_pred ** 2)\n",
    "    #         wandb.log({\"val_innovation_loss\": val_loss.item()})\n",
    "    #         wandb.log({\"mse_train_loss\": mse_loss.item()})\n",
    "\n",
    "    def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(f\"Trainable parameters: {count_parameters(channel_model):,}\")\n",
    "    # Freeze model\n",
    "    for param in channel_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Save model\n",
    "    torch.save({\n",
    "        \"channel_model\": channel_model.state_dict(),\n",
    "    }, \"channel_model_final.pth\")\n",
    "\n",
    "    artifact = wandb.Artifact(\"channel_model\", type=\"model\")\n",
    "    artifact.add_file(\"channel_model_final.pth\")\n",
    "    wandb.log_artifact(artifact)\n",
    "    print(\"Finished!\")\n",
    "    run_name = wandb.run.name\n",
    "    return avg_val_loss, run_name, channel_model, train_loader, val_loader\n",
    "\n",
    "param_grid = {\n",
    "    'lr': [1e-3],\n",
    "    'deterministic_hidden_size': [4, 8, 12, 16],\n",
    "    'stochastic_hidden_size': [4, 8, 12, 16],\n",
    "    'deterministic_num_taps': [2, 4, 6, 8, 10],\n",
    "    'stochastic_state_size': [1, 2, 4, 8],\n",
    "    'deterministic_state_size': [1, 2, 4, 8]\n",
    "}\n",
    "\n",
    "keys, values = zip(*param_grid.items())\n",
    "\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_config = None\n",
    "best_run_id = None\n",
    "for v in itertools.product(*values):\n",
    "    config = dict(zip(keys, v))\n",
    "\n",
    "    # load static config defaults\n",
    "    with open(\"../state_space_config.yml\", \"r\") as f:\n",
    "        base_cfg = yaml.safe_load(f)\n",
    "\n",
    "    # override base config\n",
    "    base_cfg.update(config)\n",
    "\n",
    "    val_loss, run_id, channel_model, train_loader, val_loader = run_experiment(base_cfg)\n",
    "\n",
    "\n",
    "    \n",
    "    innovations = []\n",
    "    all_residuals = []\n",
    "    all_inputs = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(device)\n",
    "            all_inputs.append(x)\n",
    "            y = y.to(device)\n",
    "            y_pred, e_pred = channel_model(x, y)\n",
    "            innovations.append(e_pred)\n",
    "    all_inputs_tensor = torch.cat(all_inputs, dim=0)[:100, :]\n",
    "    all_innovations_tensor = torch.cat(innovations, dim=0)[:100, :]\n",
    "\n",
    "    compute_billings_corrs(all_innovations_tensor, all_inputs_tensor, 20, log_wandb=True, prefix=\"val_billings_correlation\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_config = base_cfg\n",
    "        best_run_id = run_id\n",
    "        print(\"New best found!\")\n",
    "        print(f\"Best Run ID: {best_run_id}\")\n",
    "        print(f\"Best Validation Loss: {best_val_loss}\")\n",
    "        print(f\"Best Configuration: {best_config}\")\n",
    "        print(\"New best found!\")\n",
    "    wandb.finish()\n",
    "print(f\"Best Run ID: {best_run_id}\")\n",
    "print(f\"Best Validation Loss: {best_val_loss}\")\n",
    "print(f\"Best Configuration: {best_config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ecb4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load in chosen model\n",
    "\n",
    "# api = wandb.Api()\n",
    "# run = api.run(\"dylanbackprops-university-of-washington/mldrivenpeled/oibih492\") # Variable\n",
    "# model_name = \"channel_model_final\"\n",
    "# artifact = api.artifact(\"dylanbackprops-university-of-washington/mldrivenpeled/channel_model:v581\") # Variable\n",
    "# artifact_dir = artifact.download()\n",
    "# remote_config = run.config\n",
    "# run_name = run.name\n",
    "# print(\"Channel Run name:\", run_name)\n",
    "\n",
    "# channel_model = StateSpaceModel(\n",
    "#     nlayers=remote_config['nlayers'],\n",
    "#     dilation_base=remote_config['dilation_base'],\n",
    "#     num_taps=remote_config['num_taps'],\n",
    "#     hidden_channels=remote_config['hidden_channels'],\n",
    "#     learn_noise=remote_config['learn_noise'],\n",
    "#     gaussian=remote_config['gaussian']\n",
    "# ).to(device)\n",
    "\n",
    "\n",
    "# channel_model_path = os.path.join(artifact_dir, model_name + \".pth\")\n",
    "# checkpoint = torch.load(channel_model_path)\n",
    "# channel_model.load_state_dict(checkpoint[\"channel_model\"])\n",
    "\n",
    "# # Freeze before moving to device\n",
    "# for param in channel_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# channel_model = channel_model.to(device).float()\n",
    "# channel_model.eval()\n",
    "\n",
    "# print(\"Channel model parameters frozen:\",\n",
    "#       all(not param.requires_grad for param in channel_model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fbd2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b0d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "t = torch.linspace(0, 1, NUM_POINTS_FRAME)\n",
    "\n",
    "\n",
    "freqs = torch.arange(K_MIN, 3000)[::100]\n",
    "\n",
    "# # Downsample frequency sweep\n",
    "# freqs = KS[::200].cpu()\n",
    "\n",
    "\n",
    "# print(freqs)\n",
    "freq_step_hz = 10e3\n",
    "freqs_hz = freqs * freq_step_hz\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Normalize by real frequency values\n",
    "norm = plt.Normalize(vmin=min(freqs_hz), vmax=max(freqs_hz))\n",
    "cmap = cm.get_cmap('viridis')\n",
    "\n",
    "\n",
    "\n",
    "def loop_area(x, y):\n",
    "    # x, y are 1D numpy arrays\n",
    "    return 0.5 * np.trapezoid(y, x)\n",
    "\n",
    "areas = []\n",
    "for f_idx, f_hz in zip(freqs, freqs_hz):\n",
    "    x = 3 * torch.sin(2 * np.pi * f_idx * t).unsqueeze(0).to(device)\n",
    "    _, y, _, _ = channel_model(x)\n",
    "\n",
    "    x = x.squeeze().cpu().numpy()[RECEPTIVE_FIELD:]\n",
    "    y = y.squeeze().cpu().numpy()[RECEPTIVE_FIELD:]\n",
    "\n",
    "    ax.scatter(x, y, color=cmap(norm(f_hz)), s=0.5, alpha=0.5)\n",
    "    areas.append(loop_area(x,y))\n",
    "\n",
    "\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "sm.set_array([])\n",
    "\n",
    "cbar = fig.colorbar(sm, ax=ax)\n",
    "cbar.set_label(\"Frequency (kHz)\")\n",
    "tick_vals = np.linspace(min(freqs_hz), max(freqs_hz), 6)\n",
    "cbar.set_ticks(tick_vals)\n",
    "cbar.set_ticklabels((tick_vals.numpy() / 1e3).astype(int))  # display in kHz\n",
    "\n",
    "ax.set_title(\"Model Prediction for Sinusoidal Inputs at Various Frequencies\")\n",
    "ax.set_xlabel(\"Input\")\n",
    "ax.set_ylabel(\"Output\")\n",
    "ax.grid(True, linestyle=':')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(freqs, areas)\n",
    "plt.xlabel(\"Frequency (10 kHz)\")\n",
    "plt.ylabel(\"Loop Area (Memory Index)\")\n",
    "plt.title(\"Dynamic Nonlinearity vs Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a6526",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.getcwd()\n",
    "config_path = os.path.join(script_dir, \"..\", \"offline_time_channel_config.yml\")\n",
    "with open(config_path, \"r\") as f:\n",
    "    hyperparams = yaml.safe_load(f)\n",
    "\n",
    "    wandb.init(project=\"mldrivenpeled\",\n",
    "            config=hyperparams,\n",
    "            tags=['autoencoder'])\n",
    "    config = wandb.config\n",
    "    if wandb.run.notes is None:\n",
    "        wandb.run.notes = \"\"\n",
    "    print(f\"WandB run info:\")\n",
    "    print(f\"  Name: {wandb.run.name}\")\n",
    "    print(f\"  ID: {wandb.run.id}\")\n",
    "    print(f\"  URL: {wandb.run.url}\")\n",
    "    print(\"Chosen hyperparameters for this session:\")\n",
    "    print(config)\n",
    "\n",
    "def objective(trial, tag):\n",
    "    # Sample hyperparameters\n",
    "    dilation_base = trial.suggest_categorical(\"dilation_base\", [2])\n",
    "    num_taps = trial.suggest_int(\"num_taps\", 10, 256, step=2)\n",
    "    hidden_channels = trial.suggest_int(\"hidden_channels\", 4, 64, step=8)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2)\n",
    "    nlayers = trial.suggest_categorical(\"nlayers\", [2])\n",
    "\n",
    "    local_config = {\n",
    "        \"dilation_base\": dilation_base,\n",
    "        \"num_taps\": num_taps,\n",
    "        \"hidden_channels\": hidden_channels,\n",
    "        \"lr\": lr,\n",
    "        \"epochs\": 50,\n",
    "        \"batch_size\": 16,\n",
    "        \"Nt\": 1,\n",
    "        \"Nf\": 599,\n",
    "        \"save_path\": \"./saved_models\",\n",
    "        \"nlayers\": nlayers,\n",
    "        \"weight_init\": \"default\",\n",
    "        \"scheduler_type\": \"reduce_lr_on_plateu\",\n",
    "        \"learn_noise\": True,\n",
    "        \"gaussian\": True\n",
    "    }\n",
    "\n",
    "    wandb.init(project=\"mldrivenpeled\", config=local_config, reinit=True,\n",
    "               tags=['autoencoder', f'{tag}', f'trial {trial.number}'], mode='online')\n",
    "\n",
    "    channel_model = None\n",
    "    optimizer = None\n",
    "    scheduler = None\n",
    "\n",
    "    try:\n",
    "\n",
    "        channel_model = TCN_channel(\n",
    "            nlayers=local_config['nlayers'],\n",
    "            dilation_base=local_config['dilation_base'],\n",
    "            num_taps=local_config['num_taps'],\n",
    "            hidden_channels=local_config['hidden_channels'],\n",
    "            learn_noise=local_config['learn_noise'],\n",
    "            gaussian=True\n",
    "        ).to(device)\n",
    "\n",
    "        if channel_model.gaussian:\n",
    "            loss_fn = gaussian_nll\n",
    "        else:\n",
    "            loss_fn = students_t_loss\n",
    "\n",
    "        optimizer = torch.optim.Adam(\n",
    "            list(channel_model.parameters()), lr=lr\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "        for epoch in range(local_config['epochs']):\n",
    "            loop = tqdm(train_loader, desc=f'Epoch {epoch+1}/{local_config[\"epochs\"]}', leave=False)\n",
    "            train_loss = train(channel_model, optimizer, loss_fn, loop, scheduler, train_ABC=False)\n",
    "            val_loss = val(channel_model, loss_fn, val_loader, local_config)\n",
    "\n",
    "        return val_loss\n",
    "\n",
    "    finally:\n",
    "        wandb.finish()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        del channel_model, optimizer, scheduler, loop\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "        gc.collect()\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "study_name = f\"optuna_offline_channel_model_{timestamp}\"\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=study_name, storage=\"sqlite:///optuna_results.db\", load_if_exists=True)\n",
    "study.optimize(lambda trial: objective(trial, study_name), n_trials=50)\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27e0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = \"sqlite:///optuna_results.db\"\n",
    "\n",
    "'''\n",
    "\n",
    "{'dilation_base': 2, 'num_taps': 18, 'hidden_channels': 36, 'lr': 0.003526635762093742, 'nlayers': 3}\n",
    "'''\n",
    "summaries = optuna.get_all_study_summaries(storage=storage)\n",
    "for summary in summaries:\n",
    "    print(f\"Study name: {summary.study_name}\")\n",
    "    print(f\"  Trial count: {summary.n_trials}\")\n",
    "    if summary.best_trial is not None:\n",
    "        print(f\"  Best value: {summary.best_trial.value}\")\n",
    "        print(f\"  Best params: {summary.best_trial.params}\")\n",
    "    else:\n",
    "        print(\"  No trials completed yet.\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e4f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    "    plot_slice,\n",
    "    plot_parallel_coordinate\n",
    ")\n",
    "\n",
    "# Step 1: Choose your study name (copy it from the summaries you printed earlier)\n",
    "study_name = \"optuna_offline_channel_model_20251013_142218\"\n",
    "storage = \"sqlite:///optuna_results.db\"\n",
    "\n",
    "# Step 2: Load the study\n",
    "study = optuna.load_study(study_name=study_name, storage=storage)\n",
    "\n",
    "# Step 3: Plot using interactive Plotly charts\n",
    "plot_optimization_history(study).show()\n",
    "plot_param_importances(study).show()\n",
    "plot_slice(study).show()\n",
    "plot_parallel_coordinate(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c0fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf674c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc572e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_sizes = (np.linspace(0.1, 1.0, 5) * len(train_dataset)).astype(int)\n",
    "train_sizes = [int(s) for s in train_sizes]\n",
    "\n",
    "all_val_losses = []\n",
    "print(f\"Testing training sizes: {train_sizes}\")\n",
    "\n",
    "\n",
    "wandb.init()\n",
    "for size in tqdm(train_sizes):\n",
    "    print(f\"--- Training on {size} samples ---\")\n",
    "\n",
    "    subset_indices = train_dataset.indices[:size]\n",
    "    train_subset = Subset(dataset, subset_indices)\n",
    "\n",
    "    train_loader_subset = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "\n",
    "    channel_model.load_state_dict(initial_model_state)\n",
    "    channel_model.to(device)\n",
    "    channel_model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(channel_model.parameters(), lr=1e-3)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "\n",
    "    NUM_EPOCHS = 3\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        loop = tqdm(train_loader_subset, desc=f'Epoch {epoch+1}/{NUM_EPOCHS}', leave=False)\n",
    "        train(channel_model, optimizer, loss_fn, loop, scheduler, train_ABC=False)\n",
    "        avg_val_loss = val(channel_model, loss_fn, val_loader)\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "    final_val_loss = val(channel_model, loss_fn, val_loader)\n",
    "    all_val_losses.append(final_val_loss)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, all_val_losses, 'o-', linewidth=2, markersize=8)\n",
    "plt.xlabel(\"Number of Training Samples\", fontsize=12)\n",
    "plt.ylabel(\"Final Validation Loss (log)\", fontsize=12)\n",
    "plt.title(\"Learning Curve for Channel Model\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve for least squares FIR channel model to get estimate of\n",
    "# channel delay\n",
    "\n",
    "print(sent_frames_time.shape, received_frames_time_resampled.shape)\n",
    "\n",
    "def make_toeplitz(x: torch.tensor, L):\n",
    "    N = len(x)\n",
    "    toeplitz = torch.zeros(N, L, device=x.device)\n",
    "    for i in range(N):\n",
    "        for j in range(L):\n",
    "            if i - j >= 0: # Grab lower left\n",
    "                toeplitz[i, j] = x[i - j]\n",
    "    return toeplitz\n",
    "\n",
    "def construct_A_and_b(x_sent, y_received, L):\n",
    "    N = x_sent.size(1)\n",
    "    A = torch.zeros(L, L, device=x_sent.device)\n",
    "    b = torch.zeros(L, device=x_sent.device)\n",
    "    for xi, yi in zip(x_sent, y_received):\n",
    "        X = make_toeplitz(xi, L)\n",
    "        A += X.T @ X\n",
    "        b += X.T @ yi\n",
    "    return A, b\n",
    "\n",
    "A, b = construct_A_and_b(sent_frames_time, received_frames_time_resampled, 20)\n",
    "h_best = torch.linalg.lstsq(A.cpu(), b.cpu()).solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4111a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(x_sent, y_received, h, L):\n",
    "    \"\"\"\n",
    "    Calculates the Mean Squared Error for the given filter h.\n",
    "    \"\"\"\n",
    "    B, N = x_sent.shape\n",
    "    device = x_sent.device\n",
    "    h = h.to(device)\n",
    "\n",
    "    # 1. Pad the input on the left with L-1 zeros.\n",
    "    x_padded = F.pad(x_sent, (L - 1, 0))\n",
    "\n",
    "    # 2. Create the indices for the Toeplitz matrices.\n",
    "    i = torch.arange(N, device=device).view(N, 1)\n",
    "    j = torch.arange(L, device=device).view(1, L)\n",
    "\n",
    "    # Fixed indexing - this ensures we get the right Toeplitz structure\n",
    "    indices = i + j  # Shape (N, L)\n",
    "\n",
    "    # Clamp indices to avoid any potential out-of-bounds access\n",
    "    indices = torch.clamp(indices, 0, x_padded.shape[1] - 1)\n",
    "\n",
    "    # 3. Create the batched Toeplitz matrix X\n",
    "    X = x_padded[:, indices]  # Shape (B, N, L)\n",
    "\n",
    "\n",
    "    # 5. Predict y for the entire batch using the filter h\n",
    "    y_pred = X @ h\n",
    "\n",
    "    # 6. Calculate the MSE\n",
    "    mse = F.mse_loss(y_pred, y_received)\n",
    "\n",
    "    return mse\n",
    "\n",
    "\n",
    "L = 20\n",
    "\n",
    "mse_value = calculate_mse(sent_frames_time, received_frames_time_resampled, h_best, L)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse_value.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06166ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h_best.abs().numpy())\n",
    "plt.xlabel(\"Taps\")\n",
    "plt.ylabel(\"H Mag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a63691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def effective_length(h, alpha=0.98):\n",
    "    h = np.asarray(h)\n",
    "    energy = np.square(h)\n",
    "    cumu = np.cumsum(energy)\n",
    "    total = cumu[-1]\n",
    "    L_eff = int(np.searchsorted(cumu, alpha * total)) + 1\n",
    "    return L_eff\n",
    "effective_length(h_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldrivenpeled2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
