{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dbdd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import copy\n",
    "import math\n",
    "import wandb\n",
    "import yaml\n",
    "import zarr\n",
    "from scipy.fft import rfft\n",
    "import seaborn as sns\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from lab_scripts.constellation_diagram import RingShapedConstellation, get_constellation, QPSK_Constellation\n",
    "from modules.models import TCN_channel, TCN, memory_polynomial_channel\n",
    "from modules.utils import *\n",
    "\n",
    "if wandb.run is not None:\n",
    "    wandb.run.tags = list(wandb.run.tags) + [\"junk\"]\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78649825",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Import and cache dataset for fast loading in future\n",
    "'''\n",
    "\n",
    "# file_path = \"../data/channel_measurements/zarr_files/channel_3e5-15MHz_3.5V_scale2.zarr\"\n",
    "file_path = \"../data/channel_measurements/zarr_files/channel_3e5-8.6MHz_2.7V_scale2_dynamic_power_0.5-3.zarr\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\") # for M chip Macs\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "print(\"DEVICE\", DEVICE)\n",
    "\n",
    "ofdm_info = extract_zarr_data(file_path, DEVICE)\n",
    "sent_frames_time = ofdm_info.sent_frames_time\n",
    "received_frames_time = ofdm_info.received_frames_time\n",
    "dataset = ChannelData(sent_frames_time, received_frames_time, ofdm_info.FREQUENCIES)\n",
    "\n",
    "# Split sizes\n",
    "train_size = int(0.9 * len(dataset))\n",
    "\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size  # ensures total = 100%\n",
    "\n",
    "# Perform split\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset,\n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator()\n",
    ")\n",
    "print(\"Train Size\", train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.fft.fft(received_frames_time[0, ofdm_info.CP_LENGTH:].cpu()).abs()\n",
    "plt.plot(t[:len(t)//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa6d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.fft.fft(sent_frames_time[0, ofdm_info.CP_LENGTH:].cpu()).abs()\n",
    "plt.plot(t[:len(t)//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse_pct_loss(y, y_pred):\n",
    "    r = y - y_pred\n",
    "    return (torch.sqrt(torch.mean(r ** 2) / torch.mean(y ** 2)) * 100).item()\n",
    "\n",
    "def train(model, optimizer, loss_fn, loop, log_to_wandb=True):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    batch_count = 0\n",
    "    for batch in loop:\n",
    "        x, y = batch[0], batch[1]\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        noisy_y_pred, y_pred, y_pred_std, y_pred_nu = model(x)\n",
    "        # calculate residual\n",
    "        r = y - y_pred\n",
    "        if model.learn_noise:\n",
    "            if model.gaussian:\n",
    "                loss = loss_fn(r, y_pred_std)\n",
    "            else:\n",
    "                loss = loss_fn(r, y_pred_std, y_pred_nu)\n",
    "        else:\n",
    "            loss = loss_fn(y, y_pred)\n",
    "\n",
    "        mse_loss = F.mse_loss(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        if log_to_wandb:\n",
    "            wandb.log({\"nnl_train_loss\": loss.item()})\n",
    "            wandb.log({\"mse_train_loss\": mse_loss.item()})\n",
    "            wandb.log({\"learning_rate\": lr})\n",
    "        batch_count += 1\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    loop.close()\n",
    "\n",
    "def val(model,\n",
    "        loss_fn,\n",
    "        val_loader,\n",
    "        ofdm_info: OFDM_channel,\n",
    "        memory_polynomial=None,\n",
    "        log_to_wandb=True):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    batch_count = 0\n",
    "    y_preds = []\n",
    "    std_preds = []\n",
    "    nu_preds = []\n",
    "    true_ys = []\n",
    "    noisy_ys = []\n",
    "    val_mse_loss = 0\n",
    "    nrmse_pct_loss = 0.0\n",
    "    mse_mem_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            noisy_y, mean_y, std_y, nu_y = model(x)\n",
    "            y_preds.append(mean_y)\n",
    "            std_preds.append(std_y)\n",
    "            nu_preds.append(nu_y)\n",
    "            true_ys.append(y)\n",
    "            noisy_ys.append(noisy_y)\n",
    "            if model.learn_noise:\n",
    "                if model.gaussian:\n",
    "                    loss = loss_fn(y - mean_y, std_y) # Use mean for validation\n",
    "                else:\n",
    "                    loss = loss_fn(y - mean_y, std_y, nu_y) # Use mean for validation\n",
    "            else:\n",
    "                loss = loss_fn(y, mean_y)\n",
    "            mse_loss = F.mse_loss(y, mean_y)\n",
    "            nrmse_pct_loss += calculate_rmse_pct_loss(y, mean_y)\n",
    "            val_mse_loss += mse_loss.item()\n",
    "            val_loss += loss.item()\n",
    "            if memory_polynomial:\n",
    "                y_pred_mp = memory_polynomial(x)\n",
    "                mse_mem_loss += calculate_rmse_pct_loss(y, y_pred_mp)\n",
    "            batch_count += 1\n",
    "\n",
    "    avg_val_loss = (val_loss / batch_count)\n",
    "    avg_val_mse_loss = (val_mse_loss / batch_count)\n",
    "    avg_val_mem_loss = (mse_mem_loss / batch_count)\n",
    "    avg_nrmse_pct_loss = (nrmse_pct_loss / batch_count)\n",
    "\n",
    "    y_preds = torch.vstack(y_preds)\n",
    "    std_preds = torch.vstack(std_preds)\n",
    "    nu_preds = torch.vstack(nu_preds)\n",
    "    true_ys = torch.vstack(true_ys)\n",
    "    noisy_ys = torch.vstack(noisy_ys)\n",
    "\n",
    "    if log_to_wandb:\n",
    "        # Log both scalar and histogram\n",
    "        wandb.log({\n",
    "            'val_nll_loss': avg_val_loss,\n",
    "            \"avg_val_mse_loss\": avg_val_mse_loss,\n",
    "            \"avg_nrmse_pct_loss\": avg_nrmse_pct_loss\n",
    "        })\n",
    "        if memory_polynomial:\n",
    "            wandb.log({\n",
    "                'val_mem_poly_nrmse_pct_loss': avg_val_mem_loss\n",
    "            })\n",
    "        if model.learn_noise:\n",
    "            log_snr_plots(y_preds, noisy_ys, ofdm_info)\n",
    "\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d961ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def students_t_loss(difference, y_pred_std, y_pred_nu):\n",
    "    # nu = y_pred_nu.clamp_min(2.0)\n",
    "    nu = y_pred_nu\n",
    "    z_resid = (difference) / (y_pred_std)\n",
    "    term1 = -1 * torch.lgamma((nu + 1) / 2) + 0.5 * torch.log(torch.pi * nu) + torch.lgamma(nu / 2) + torch.log(y_pred_std + 1e-8)\n",
    "    term2 = ((nu + 1) / 2) * torch.log(1 + (1 / nu) * torch.square(z_resid) + 1e-8)\n",
    "    loss = torch.mean(term1 + term2)\n",
    "    if torch.isnan(loss):\n",
    "        raise ValueError(\"NaN in loss\")\n",
    "    return loss\n",
    "\n",
    "def gaussian_nll(difference, y_pred_std):\n",
    "    term1 = 0.5 * torch.log(2 * torch.pi * (y_pred_std ** 2))\n",
    "    term2 = 0.5 * torch.square((difference) / y_pred_std)\n",
    "    loss = torch.mean(term1 + term2)\n",
    "    if torch.isnan(loss):\n",
    "        raise ValueError(\"NaN in loss\")\n",
    "    return loss\n",
    "\n",
    "def get_hyperparam_dict(name):\n",
    "    script_dir = os.getcwd()\n",
    "    config_path = os.path.join(script_dir, \"..\", f\"configs/{name}\")\n",
    "    with open(config_path, \"r\") as f:\n",
    "        hyper_dict = yaml.safe_load(f)\n",
    "        return hyper_dict\n",
    "\n",
    "hyper_dict = get_hyperparam_dict(\"offline_time_channel_config.yml\")\n",
    "\n",
    "# Start Weights and Biases session\n",
    "wandb.init(project=\"mldrivenpeled\",\n",
    "           config=hyper_dict,\n",
    "           tags=['channel_model'])\n",
    "config = wandb.config\n",
    "\n",
    "print(\"WandB run info:\")\n",
    "print(f\"  Name: {wandb.run.name}\")\n",
    "print(f\"  ID: {wandb.run.id}\")\n",
    "print(f\"  URL: {wandb.run.url}\")\n",
    "print(\"Chosen hyperparameters for this session:\")\n",
    "print(config)\n",
    "\n",
    "# Create dataloader\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=config.batch_size, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=config.batch_size, drop_last=False)\n",
    "\n",
    "channel_model = TCN_channel(\n",
    "    nlayers=config.nlayers,\n",
    "    dilation_base=config.dilation_base,\n",
    "    num_taps=config.num_taps,\n",
    "    hidden_channels=config.hidden_channels,\n",
    "    learn_noise=config.learn_noise,\n",
    "    gaussian=config.gaussian\n",
    ").to(DEVICE)\n",
    "\n",
    "# Fit memory polynomial for reference\n",
    "memory_polynomial = memory_polynomial_channel(weights=None, memory_linear=10, memory_nonlinear=10, nonlinearity_order=2, device=DEVICE)\n",
    "memory_polynomial.fit(sent_frames_time, received_frames_time)\n",
    "initial_model_state = copy.deepcopy(channel_model.state_dict())\n",
    "\n",
    "if channel_model.gaussian:\n",
    "    loss_fn = gaussian_nll\n",
    "else:\n",
    "    loss_fn = students_t_loss\n",
    "\n",
    "optimizer = optim.AdamW(\n",
    "        channel_model.parameters(),\n",
    "        lr=float(config.lr),\n",
    "        weight_decay=float(config.wd)\n",
    "    )\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1, min_lr=1e-6)\n",
    "\n",
    "epoch_counter = 0\n",
    "for epoch in range(config.epochs):\n",
    "    epoch_counter += 1\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f'Epoch {epoch_counter}')\n",
    "    train(channel_model,\n",
    "            optimizer,\n",
    "            loss_fn,\n",
    "            loop)\n",
    "\n",
    "    avg_val_loss = val(channel_model,\n",
    "                        loss_fn,\n",
    "                        val_loader,\n",
    "                        memory_polynomial=memory_polynomial,\n",
    "                        ofdm_info=ofdm_info)\n",
    "\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Trainable parameters: {count_parameters(channel_model)}\")\n",
    "# Freeze model\n",
    "for param in channel_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Save model\n",
    "torch.save({\n",
    "    \"channel_model\": channel_model.state_dict(),\n",
    "}, \"../models/channel_models/channel_model_final.pth\")\n",
    "\n",
    "artifact = wandb.Artifact(\"channel_model\", type=\"model\")\n",
    "artifact.add_file(\"../models/channel_models/channel_model_final.pth\")\n",
    "logged_artifact = wandb.log_artifact(artifact)\n",
    "\n",
    "# Get version from server for next stage\n",
    "logged_artifact.wait()\n",
    "\n",
    "channel_model_version = logged_artifact.version\n",
    "print(\"Finished!\")\n",
    "channel_run_name = wandb.run.name\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc6339c",
   "metadata": {},
   "source": [
    "### Memory Polynomial for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99aa837",
   "metadata": {},
   "outputs": [],
   "source": [
    "TCN_CHANNEL = True\n",
    "if TCN_CHANNEL:\n",
    "    api = wandb.Api()\n",
    "    # run = api.run(\"dylanbackprops-university-of-washington/mldrivenpeled/oibih492\") # Variable\n",
    "    model_name = \"channel_model_final\"\n",
    "    # artifact = api.artifact(\"dylanbackprops-university-of-washington/mldrivenpeled/channel_model:v581\") # Variable\n",
    "\n",
    "    entity = \"dylanbackprops-university-of-washington\"\n",
    "    project = \"mldrivenpeled\"\n",
    "    artifact_name = \"channel_model\"\n",
    "    version = channel_model_version\n",
    "\n",
    "    # Construct the full path string\n",
    "    channel_model_artifact_path = f\"{entity}/{project}/{artifact_name}:{version}\"\n",
    "    artifact = api.artifact(channel_model_artifact_path)\n",
    "    artifact_dir = artifact.download() # downloads to CWD\n",
    "\n",
    "    logging_run = artifact.logged_by()\n",
    "\n",
    "    remote_config = logging_run.config\n",
    "\n",
    "    run_name = logging_run.name\n",
    "    print(\"Channel Run name:\", run_name)\n",
    "\n",
    "    channel_model = TCN_channel(\n",
    "        nlayers=remote_config['nlayers'],\n",
    "        dilation_base=remote_config['dilation_base'],\n",
    "        num_taps=remote_config['num_taps'],\n",
    "        hidden_channels=remote_config['hidden_channels'],\n",
    "        learn_noise=remote_config['learn_noise'],\n",
    "        gaussian=remote_config['gaussian']\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    channel_model_path = os.path.join(artifact_dir, model_name + \".pth\")\n",
    "    checkpoint = torch.load(channel_model_path)\n",
    "    channel_model.load_state_dict(checkpoint[\"channel_model\"])\n",
    "else:\n",
    "    run_name = \"Trained on MP channel model\"\n",
    "    channel_model = memory_polynomial_channel(weights=None, memory_linear=10, memory_nonlinear=10, nonlinearity_order=2, device=DEVICE)\n",
    "    weights, A, residuals = channel_model.fit(sent_frames_time, received_frames_time)\n",
    "    terms, weights = channel_model.show_terms()\n",
    "\n",
    "\n",
    "# Freeze before moving to DEVICE\n",
    "for param in channel_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "channel_model = channel_model.to(DEVICE).float()\n",
    "channel_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f04a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = memory_polynomial.show_terms(plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a2a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = memory_polynomial.calculate_err(sent_frames_time, received_frames_time, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fb341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Channel model parameters frozen:\",\n",
    "      all(not param.requires_grad for param in channel_model.parameters()))\n",
    "\n",
    "constellation_mode = \"m7_apsk_constellation\"\n",
    "\n",
    "constellation = get_constellation(constellation_mode)\n",
    "\n",
    "script_dir = os.getcwd()\n",
    "config_path = os.path.join(script_dir, \"..\", \"configs/offline_time_ae_config.yml\")\n",
    "with open(config_path, \"r\") as f:\n",
    "    hyperparams = yaml.safe_load(f)\n",
    "\n",
    "    wandb.init(project=\"mldrivenpeled\",\n",
    "            config=hyperparams,\n",
    "            tags=['autoencoder'])\n",
    "    config = wandb.config\n",
    "    if wandb.run.notes is None:\n",
    "        wandb.run.notes = \"\"\n",
    "    config.modulator = constellation_mode\n",
    "    wandb.run.notes += wandb.run.notes + f\"\\n | trained on channel model {run_name} \\n | {constellation_mode}\"\n",
    "    print(\"WandB run info:\")\n",
    "    print(f\"  Name: {wandb.run.name}\")\n",
    "    print(f\"  ID: {wandb.run.id}\")\n",
    "    print(f\"  URL: {wandb.run.url}\")\n",
    "    print(\"Chosen hyperparameters for this session:\")\n",
    "    print(config)\n",
    "\n",
    "encoder = TCN(\n",
    "    nlayers=config.nlayers,\n",
    "    dilation_base=config.dilation_base,\n",
    "    num_taps=config.num_taps,\n",
    "    hidden_channels=config.hidden_channels,\n",
    ").to(DEVICE)\n",
    "\n",
    "decoder = TCN(\n",
    "    nlayers=config.nlayers,\n",
    "    dilation_base=config.dilation_base,\n",
    "    num_taps=config.num_taps,\n",
    "    hidden_channels=config.hidden_channels\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=config.lr, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20, min_lr=1e-6)\n",
    "\n",
    "\n",
    "val_ofdm_settings = OFDM_channel()\n",
    "\n",
    "NUM_BITS = config.Nt * config.Nf * constellation.modulation_order\n",
    "\n",
    "FREQUENCIES = torch.arange(\n",
    "    float(config.flow),\n",
    "    float(config.fhigh),\n",
    "    float(config.subcarrier_spacing)\n",
    ")\n",
    "\n",
    "delta_f = FREQUENCIES[1] - FREQUENCIES[0]\n",
    "KS = (FREQUENCIES / delta_f).to(torch.int)\n",
    "\n",
    "K_MIN = int(KS[0].item())\n",
    "K_MAX = int(KS[-1].item())\n",
    "NUM_POS_FREQS = K_MAX + 1\n",
    "RIGHT_PADDING_ZEROS = (ofdm_info.NUM_POINTS_FRAME - 2 *  NUM_POS_FREQS) // 2\n",
    "LEFT_PADDING_ZEROS = K_MIN - 1\n",
    "PREAMBLE_MAX = config.preamble_amplitude\n",
    "\n",
    "val_ofdm_settings = OFDM_channel(\n",
    "    FREQUENCIES=FREQUENCIES,\n",
    "    NUM_POINTS_SYMBOL=config.Nf,\n",
    "    CP_LENGTH=ofdm_info.CP_LENGTH,\n",
    "    DELTA_K=int(delta_f.item()),\n",
    "    KS=KS,\n",
    "    K_MIN=K_MIN,\n",
    "    K_MAX=K_MAX,\n",
    "    LEFT_PADDING_ZEROS=LEFT_PADDING_ZEROS,\n",
    "    CP_RATIO=ofdm_info.CP_RATIO,\n",
    "    NUM_POINTS_FRAME=ofdm_info.NUM_POINTS_FRAME,\n",
    "    NUM_POS_FREQS=len(KS),\n",
    "    RIGHT_PADDING_ZEROS=RIGHT_PADDING_ZEROS\n",
    ")\n",
    "\n",
    "def train(channel_model, encoder, decoder, optimizer, scheduler, config, DEVICE, mask=None):\n",
    "\n",
    "    encoder = encoder.to(DEVICE)\n",
    "    decoder = decoder.to(DEVICE)\n",
    "\n",
    "    average_encoded_power = 0.0\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_freq_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        batch_entries = []\n",
    "        true_bits_list = []\n",
    "        for batch in range(config[\"batch_size\"]):\n",
    "            # Generate frame data\n",
    "            true_bits = np.random.randint(0, 2, size=NUM_BITS)\n",
    "            true_bits_list.append(torch.tensor(true_bits))\n",
    "            true_bits_str = ''.join(map(str, true_bits))\n",
    "            true_symbols = torch.tensor(\n",
    "                constellation.bits_to_symbols(true_bits_str),\n",
    "                dtype=torch.complex64, device=DEVICE\n",
    "            )\n",
    "            true_frame = true_symbols.reshape(config[\"Nt\"], config[\"Nf\"])\n",
    "\n",
    "\n",
    "            batch_entries.append(true_frame)\n",
    "\n",
    "        true_bits = torch.stack(true_bits_list)\n",
    "\n",
    "        # Batch along time domain\n",
    "        true_frame = torch.cat(batch_entries)\n",
    "\n",
    "        # print(\"Inband symbol power\", true_frame.abs().square().mean())\n",
    "        # Convert to time domain\n",
    "        sent_frames_time = symbols_to_time(true_frame, val_ofdm_settings.LEFT_PADDING_ZEROS, val_ofdm_settings.RIGHT_PADDING_ZEROS)\n",
    "        sent_frames_time = torch.hstack((sent_frames_time[:, -val_ofdm_settings.CP_LENGTH:], sent_frames_time))\n",
    "\n",
    "        # print(f\"Encoder Ave Pwr In {sent_frames_time.square().mean().item(): .3f}\")\n",
    "        encoded_frames_time = encoder(sent_frames_time)\n",
    "        average_encoded_power += encoded_frames_time.square().mean().item()\n",
    "\n",
    "        # print(f\"Encoder Ave Pwr Out {encoded_frames_time.square().mean().item(): .3f}\")\n",
    "\n",
    "        # encoded_frames_time = in_band_filter(encoded_frames_time, KS, NUM_POINTS_FRAME)\n",
    "\n",
    "        # Clip to preamble make\n",
    "        encoded_frames_time = torch.clip(encoded_frames_time, -PREAMBLE_MAX, PREAMBLE_MAX)\n",
    "\n",
    "        if TCN_CHANNEL:\n",
    "            received_frames_time, mean, std, nu = channel_model(encoded_frames_time)\n",
    "            if torch.isnan(received_frames_time).any():\n",
    "                raise ValueError(\"NaN in Loss!\")\n",
    "        else:\n",
    "            received_frames_time = channel_model(encoded_frames_time)\n",
    "            mean = received_frames_time\n",
    "            std = 0\n",
    "            nu = 0\n",
    "\n",
    "\n",
    "        decoded_frames_time = decoder(received_frames_time)\n",
    "\n",
    "        # Convert to frequency domain for loss\n",
    "        sent_frames_frequency = torch.tensor(rfft(sent_frames_time[:, val_ofdm_settings.CP_LENGTH:].detach().cpu().numpy(), norm='ortho', axis=1)[:, KS])\n",
    "        decoded_frames_frequency = torch.tensor(rfft(decoded_frames_time[:, val_ofdm_settings.CP_LENGTH:].detach().cpu().numpy(), norm='ortho', axis=1)[:, KS])\n",
    "\n",
    "        loss = in_band_time_loss(sent_frames_time, decoded_frames_time, ks_indices=KS, n_fft=val_ofdm_settings.NUM_POINTS_FRAME, num_taps=config['num_taps'])\n",
    "\n",
    "\n",
    "        diff_complex = sent_frames_frequency.detach() - decoded_frames_frequency.detach()\n",
    "        freq_loss = torch.mean(diff_complex.abs().pow(2))\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_freq_loss += freq_loss.item()\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step(epoch_loss)\n",
    "\n",
    "        wandb.log({\"loss\": epoch_loss}, step=epoch)\n",
    "        wandb.log({\"freq_loss\": epoch_freq_loss}, step=epoch)\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        wandb.log({\"learning_rate\": lr}, step=epoch)\n",
    "\n",
    "        # Get BER\n",
    "        ber = calculate_BER(decoded_frames_frequency.detach().flatten(), true_bits.flatten(), constellation=constellation)\n",
    "        wandb.log({\"BER\": ber}, step=epoch)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            make_time_validate_plots(\n",
    "            sent_frames_time[0],\n",
    "            encoded_frames_time[0],\n",
    "            received_frames_time[0],\n",
    "            decoded_frames_time[0],\n",
    "            frame_BER=ber,\n",
    "            run_model=True,\n",
    "            step=epoch\n",
    "            )\n",
    "\n",
    "            # Plot first example of sent and reconstructed time\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(sent_frames_time[0][:100].detach().cpu().numpy(), label=\"Sent (time)\")\n",
    "            ax.plot(decoded_frames_time[0][:100].detach().cpu().numpy(), label=\"Decoded (time)\")\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"Sent vs Decoded (Time Domain) EVM: {loss: 0.3e}\")\n",
    "            wandb.log({\"time_domain_plot\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "            sent_symbols = sent_frames_frequency[0].detach().cpu().numpy()\n",
    "            decoded_symbols = decoded_frames_frequency[0].detach().cpu().numpy()\n",
    "\n",
    "            # Compute EVM for logging (per frame)\n",
    "            evm_val = evm_loss(torch.tensor(sent_symbols), torch.tensor(decoded_symbols)).item()\n",
    "\n",
    "            # Create constellation plot\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.scatter(sent_symbols.real, sent_symbols.imag, color='blue', alpha=0.6, label='Sent')\n",
    "            ax.scatter(decoded_symbols.real, decoded_symbols.imag, color='red', alpha=0.6, label='Decoded')\n",
    "            ax.set_xlabel('In-phase')\n",
    "            ax.set_ylabel('Quadrature')\n",
    "            ax.set_title(f'Constellation Diagram EVM: {evm_val:0.3e}')\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "\n",
    "            # Log to wandb\n",
    "            wandb.log({\"constellation\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "            evm_per_freq = ((sent_frames_frequency[0] - decoded_frames_frequency[0]).abs()**2).detach().cpu().numpy()\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(evm_per_freq)\n",
    "            ax.set_title(\"EVM vs Frequency\")\n",
    "            wandb.log({\"evm_vs_freq\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "\n",
    "            # Plot Model SNRs\n",
    "            sent_k = torch.fft.fft(encoded_frames_time[:, val_ofdm_settings.CP_LENGTH:], norm=\"ortho\", dim=-1)\n",
    "            received_k = torch.fft.fft(mean[:, val_ofdm_settings.CP_LENGTH:], norm=\"ortho\", dim=-1)\n",
    "\n",
    "            residual = received_frames_time - mean\n",
    "            received_noise_k = torch.fft.fft(residual[:, val_ofdm_settings.CP_LENGTH:] ** 2, norm=\"ortho\", dim=-1)\n",
    "\n",
    "\n",
    "            signal_power = torch.mean(torch.abs(sent_k) ** 2, dim=0).detach().cpu().numpy()\n",
    "            received_power = torch.mean(torch.abs(received_k) ** 2, dim=0).detach().cpu().numpy()\n",
    "            received_noise_power = torch.mean(torch.abs(received_noise_k), dim=0).detach().cpu().numpy()\n",
    "            snr_vs_freq = (received_power / received_noise_power + 1e-12)\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(10 * np.log10(signal_power[:len(signal_power)//2]))\n",
    "            ax.axvline(30, c='r', linestyle='--')\n",
    "            ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            ax.set_title(\"Encoded Signal Frequency Power Spectrum\")\n",
    "            ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            ax.set_ylabel(\"Power (dB)\")\n",
    "            wandb.log({\"encoded_signal_power_spectrum\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(10 * np.log10(received_power[:len(received_power)//2]))\n",
    "            ax.axvline(30, c='r', linestyle='--')\n",
    "            ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            ax.set_title(\"Received Signal Frequency Power Spectrum\")\n",
    "            ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            ax.set_ylabel(\"Power (dB)\")\n",
    "            wandb.log({\"received_signal_power_spectrum\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(10 * np.log10(snr_vs_freq[:len(snr_vs_freq)//2]))\n",
    "            ax.set_title(\"SNR vs Freq Estimate\")\n",
    "            ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            ax.set_ylabel(\"SNR (dB)\")\n",
    "            ax.axvline(30, c='r', linestyle='--')\n",
    "            ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            wandb.log({\"snr_vs_freq\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(10 * np.log10(received_noise_power[:len(snr_vs_freq)//2]))\n",
    "            ax.set_title(\"Noise power vs Freq Estimate\")\n",
    "            ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            ax.set_ylabel(\"Power (dB)\")\n",
    "            ax.axvline(30, c='r', linestyle='--')\n",
    "            ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            wandb.log({\"noise_power_vs_freq\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "    average_encoded_power /= config['epochs']\n",
    "\n",
    "\n",
    "    # Save model\n",
    "    torch.save({\n",
    "        \"time_encoder\": encoder.state_dict(),\n",
    "        \"time_decoder\": decoder.state_dict()\n",
    "    }, \"time_autoencoder.pth\")\n",
    "\n",
    "    artifact = wandb.Artifact(\"time_autoencoder\", type=\"model\")\n",
    "    artifact.add_file(\"time_autoencoder.pth\")\n",
    "    wandb.log_artifact(artifact)\n",
    "\n",
    "    return epoch_loss, average_encoded_power\n",
    "\n",
    "_, average_enc_power = train(channel_model, encoder, decoder, optimizer, scheduler, config, DEVICE)\n",
    "wandb.finish()\n",
    "print(average_enc_power)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldrivenpeled2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
