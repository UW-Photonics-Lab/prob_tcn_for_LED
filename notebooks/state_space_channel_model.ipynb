{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ebde2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import h5py\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.special import beta\n",
    "from torch.special import psi\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Subset\n",
    "import copy\n",
    "import math\n",
    "import wandb\n",
    "import itertools\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import gc\n",
    "import datetime\n",
    "import optuna\n",
    "import zarr\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "if wandb.run is not None:\n",
    "    wandb.run.tags = list(wandb.run.tags) + [\"junk\"]\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be64339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/wideband_twocarrier_3.1V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/wideband_single_carrier_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/wideband_2.83V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/time_channel_2.83V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_channel_2.83V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_channel_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/normalized_channel_2.83V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/single_X_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_wide_channel_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_wide_channel_3.5V_scale2.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_wide_channel_test_3.5V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/unnormalized_wide_channel_3.13V.h5\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_25MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_15MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_15MHz_3.5V_scale4.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_7.5MHz_3.5V_scale8.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_4MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_3e5-4MHz_3.5V_scale4.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/channel_3e5-4MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"C:/Users/maild/mldrivenpeled/data/channel_measurements/zarr_files/test/channel_3e5-15MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/channel_3e5-15MHz_3.5V_scale2.zarr\"\n",
    "file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/channel_3e5-30MHz_3.5V_scale2.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_7.5MHz_3.5V_scale4.zarr\"\n",
    "# file_path = \"/Users/dylanjones/Desktop/mldrivenpeled/data/channel_measurements/zarr_files/wide_channel_1e4-15MHz_3.5V_scale4.zarr\"\n",
    "\n",
    "# Set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\") # for M chip Macs\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "WIDE_BAND = False\n",
    "TIME_MODEL = True\n",
    "\n",
    "cache_path = file_path.replace(\".zarr\", \"_cached.pt\").replace(\".h5\", \"_cached.pt\")\n",
    "\n",
    "if os.path.exists(cache_path):\n",
    "    data = torch.load(cache_path, map_location=device)\n",
    "    sent_frames_time = data[\"sent_frames_time\"].to(device)\n",
    "    received_frames_time = data[\"received_frames_time\"].to(device)\n",
    "    FREQUENCIES = data[\"frequencies\"].to(device)\n",
    "    NUM_POINTS_SYMBOL = data[\"NUM_POINTS_SYMBOL\"]\n",
    "    CP_LENGTH = data[\"CP_LENGTH\"]\n",
    "    delta_f = FREQUENCIES[1] - FREQUENCIES[0]\n",
    "    KS = (FREQUENCIES / delta_f).to(torch.int)\n",
    "    K_MIN = int(KS[0].item())\n",
    "    K_MAX = int(KS[-1].item())\n",
    "    NUM_ZEROS = K_MIN - 1\n",
    "    CP_RATIO = 0.25\n",
    "    NUM_POINTS_FRAME = NUM_POINTS_SYMBOL - CP_LENGTH\n",
    "    NUM_POS_FREQS_LOW_BAND = K_MAX + 1\n",
    "    print(NUM_POINTS_FRAME  - 2 * NUM_POS_FREQS_LOW_BAND)\n",
    "    UPSAMPLING_ZEROS = (NUM_POINTS_FRAME  - 2 * NUM_POS_FREQS_LOW_BAND) // 2\n",
    "\n",
    "    print(\"Loaded from cache!\")\n",
    "else:\n",
    "    print(\"No cache found — loading original dataset...\")\n",
    "\n",
    "    H5 = False\n",
    "    FREQUENCIES = None\n",
    "    if H5:\n",
    "        # Extract all frame data\n",
    "        DTYPE = torch.complex64\n",
    "        sent = []\n",
    "        received = []\n",
    "        received_time = []\n",
    "        FREQUENCIES = None\n",
    "        with h5py.File(file_path, \"r\") as f:\n",
    "            # Get frequency\n",
    "            first_frame = list(f.keys())[-1]\n",
    "            FREQUENCIES = torch.tensor(f[first_frame]['freqs'][:], dtype=DTYPE).to(device).real\n",
    "            NUM_POINTS_SYMBOL = int(f[first_frame]['num_points_symbol'][()])\n",
    "            CP_LENGTH = int(f[first_frame]['cp_length'][()])\n",
    "            for frame in f:\n",
    "                group = f[frame]\n",
    "                sent.append(torch.tensor(group['sent'][:], dtype=DTYPE))\n",
    "                received.append(torch.tensor(group['received'][:], dtype=DTYPE))\n",
    "                received_time.append(torch.tensor(group['received_time'][:], dtype=DTYPE))\n",
    "    else:\n",
    "        # Open the Zarr root\n",
    "        root = zarr.open(file_path, mode=\"r\")\n",
    "\n",
    "        # Get first frame\n",
    "\n",
    "        # Load metadata (attributes live under .attrs)\n",
    "        sent, received, received_time = [], [], []\n",
    "\n",
    "        # Loop through frames\n",
    "        num_skipped = 0\n",
    "        for frame_key in root.group_keys():\n",
    "            try:\n",
    "                frame = root[frame_key]\n",
    "                if FREQUENCIES is None:\n",
    "                    FREQUENCIES = torch.tensor(frame[\"freqs\"][:], dtype=torch.int).real\n",
    "                    NUM_POINTS_SYMBOL = int(frame.attrs[\"num_points_symbol\"])\n",
    "                    CP_LENGTH = int(frame.attrs[\"cp_length\"])\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                sent.append(torch.tensor(frame[\"sent\"][:], dtype=torch.complex64))\n",
    "                received.append(torch.tensor(frame[\"received\"][:], dtype=torch.complex64))\n",
    "                if \"received_time\" in frame:\n",
    "                    received_time.append(torch.tensor(frame[\"received_time\"][:], dtype=torch.float32))\n",
    "            except:\n",
    "                num_skipped += 1\n",
    "                pass # skip corrupted frames\n",
    "    print(f\"Skipped {num_skipped} corrupted frames\")\n",
    "\n",
    "    sent_frames = torch.stack(sent).squeeze(1)\n",
    "    sent_frames_active = sent_frames\n",
    "    received_frames = torch.stack(received).squeeze(1)\n",
    "\n",
    "\n",
    "    delta_f = FREQUENCIES[1] - FREQUENCIES[0]\n",
    "    KS = (FREQUENCIES / delta_f).to(torch.int)\n",
    "    K_MIN = int(KS[0].item())\n",
    "    K_MAX = int(KS[-1].item())\n",
    "    NUM_ZEROS = K_MIN - 1\n",
    "    CP_RATIO = 0.25\n",
    "    NUM_POINTS_FRAME = NUM_POINTS_SYMBOL - CP_LENGTH\n",
    "    NUM_POS_FREQS_LOW_BAND = K_MAX + 1\n",
    "    UPSAMPLING_ZEROS = (NUM_POINTS_FRAME  - 2 * NUM_POS_FREQS_LOW_BAND) // 2\n",
    "\n",
    "\n",
    "    def symbols_to_time(X, num_padding_zeros: int, num_leading_zeros=0):\n",
    "        # Make hermetian symmetric\n",
    "        Nt, Nf = X.shape\n",
    "        padding_zeros = torch.zeros(Nt, num_padding_zeros, device=device)\n",
    "        leading_zeros = torch.zeros(Nt, num_leading_zeros, device=device)\n",
    "        X = torch.cat([leading_zeros, X.to(device), padding_zeros], dim=-1)\n",
    "        DC_Nyquist = torch.zeros((X.shape[0], 1), device=X.device)\n",
    "        X_hermitian = torch.flip(X, dims=[1]).conj()\n",
    "        X_full = torch.hstack([DC_Nyquist, X, DC_Nyquist, X_hermitian])\n",
    "\n",
    "        # Convert to time domain\n",
    "        x_time = torch.fft.ifft(X_full, dim=-1, norm=\"ortho\").real\n",
    "        return x_time.to(device)\n",
    "\n",
    "    if len(received_time) > 0:\n",
    "        N_shortest = min(t.size(-1) for t in received_time)\n",
    "        N_longest = max(t.size(-1) for t in received_time)\n",
    "        good_indices = [i for i, x in enumerate(received_time) if x.size(-1) == N_shortest]\n",
    "        received_frames_time = torch.stack([t for t in received_time if t.size(-1) == N_shortest], dim=0).real.squeeze(1)\n",
    "        sent_frames = sent_frames[good_indices]\n",
    "\n",
    "\n",
    "    sent_frames_time = symbols_to_time(sent_frames, UPSAMPLING_ZEROS, NUM_ZEROS)\n",
    "    # Add cyclic prefix\n",
    "    sent_frames_time = torch.hstack((sent_frames_time[:, -CP_LENGTH:], sent_frames_time))\n",
    "    received_frames_time = received_frames_time - received_frames_time.mean(dim=1, keepdim=True)\n",
    "\n",
    "\n",
    "\n",
    "    # enforce OSA causality\n",
    "    # sent_frames_time = sent_frames_time[:, :-1]\n",
    "    # received_frames_time_resampled = received_frames_time_resampled[:,  1:]\n",
    "    sent_frames_time = sent_frames_time.to(device)\n",
    "    received_frames_time = received_frames_time.to(device)\n",
    "\n",
    "    TRUNCATE_SIZE = slice(CP_LENGTH, CP_LENGTH + 300)\n",
    "    sent_frames_time = sent_frames_time[:, TRUNCATE_SIZE]\n",
    "    received_frames_time = received_frames_time[:, TRUNCATE_SIZE]\n",
    "\n",
    "    # Create a cache path\n",
    "    cache_path = file_path.replace(\".zarr\", \"_cached.pt\").replace(\".h5\", \"_cached.pt\")\n",
    "\n",
    "    torch.save({\n",
    "        \"sent_frames_time\": sent_frames_time.cpu(),\n",
    "        \"received_frames_time\": received_frames_time.cpu(),\n",
    "        \"frequencies\": FREQUENCIES.cpu(),\n",
    "        \"NUM_POINTS_SYMBOL\": NUM_POINTS_SYMBOL,\n",
    "        \"CP_LENGTH\": CP_LENGTH\n",
    "    }, cache_path)\n",
    "\n",
    "class ChannelData(Dataset):\n",
    "        def __init__(self,\n",
    "                    sent_frames,\n",
    "                    received_frames,\n",
    "                    frequencies,\n",
    "                    transform=None,\n",
    "                    target_transform=None):\n",
    "\n",
    "            self.sent_frames = sent_frames\n",
    "            self.received_frames = received_frames\n",
    "            assert len(sent_frames) == len(received_frames)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.sent_frames)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.sent_frames[idx], self.received_frames[idx]\n",
    "\n",
    "if TIME_MODEL:\n",
    "    dataset = ChannelData(sent_frames_time, received_frames_time, FREQUENCIES)\n",
    "else:\n",
    "    dataset = ChannelData(sent_frames, received_frames, FREQUENCIES)\n",
    "\n",
    "# Split sizes\n",
    "train_size = int(0.9 * len(dataset))\n",
    "\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size  # ensures total = 100%\n",
    "\n",
    "# Perform split\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset,\n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator()\n",
    ")\n",
    "print(\"Train Size\", train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sent_frames_time[100].cpu().numpy()\n",
    "r = received_frames_time[100].cpu().numpy()\n",
    "\n",
    "print(s.shape, r.shape)\n",
    "corr = np.correlate(s, r, mode='full')\n",
    "T = len(s)\n",
    "zero_lag_index = T - 1\n",
    "\n",
    "lags = np.arange(-T + 1, T)  # lag axis\n",
    "plt.plot(lags, corr)\n",
    "plt.axvline(0, color='k', linestyle='--')\n",
    "plt.xlabel('Lag (samples)')\n",
    "plt.ylabel('Cross-correlation amplitude')\n",
    "plt.title('Sent vs Received Cross-Correlation (Frame 0)')\n",
    "plt.show()\n",
    "\n",
    "# Find best alignment\n",
    "best_lag = lags[np.argmax(corr)]\n",
    "print(\"Peak lag:\", best_lag)\n",
    "\n",
    "window = 4\n",
    "lags = np.arange(-window, window + 1)\n",
    "plt.plot(lags, corr[zero_lag_index - window:zero_lag_index + window + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8188201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_last_layer(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.zeros_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "class StateSpaceModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 deterministic_num_taps,\n",
    "                 deterministic_state_size,\n",
    "                 deterministic_hidden_size,\n",
    "                 stochastic_state_size,\n",
    "                 stochastic_hidden_size\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.deterministic_state_size = deterministic_state_size\n",
    "        self.stochastic_state_size = stochastic_state_size\n",
    "        self.deterministic_num_taps = deterministic_num_taps\n",
    "        self.deterministic_state_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(deterministic_hidden_size, deterministic_state_size)\n",
    "        )\n",
    "        self.deterministic_out_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(deterministic_hidden_size, 1) # Predict next scalar ouptut\n",
    "        )\n",
    "        self.stochastic_state_map = nn.Sequential(\n",
    "            nn.Linear(stochastic_state_size + deterministic_num_taps + 1, stochastic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(stochastic_hidden_size, stochastic_state_size)\n",
    "        )\n",
    "        self.stochastic_out_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + stochastic_state_size + deterministic_state_size, stochastic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(stochastic_hidden_size, 1)\n",
    "        )\n",
    "        self.linear_det_out_map = nn.Linear(deterministic_num_taps + deterministic_state_size, 1)\n",
    "        self.linear_det_state_map = nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_state_size)\n",
    "        self.linear_stoch_state_map = nn.Linear(stochastic_state_size + deterministic_num_taps + 1, stochastic_state_size)\n",
    "        self.linear_stoch_out_map = nn.Linear(deterministic_num_taps + stochastic_state_size + deterministic_state_size, 1)\n",
    "\n",
    "        self.n0 = nn.Parameter(torch.zeros(deterministic_state_size))\n",
    "        self.z0 = nn.Parameter(torch.zeros(stochastic_state_size))\n",
    "\n",
    "        # Make it so that the stochastic output starts at zero\n",
    "        self.deterministic_state_map[-1].apply(zero_last_layer)\n",
    "        self.deterministic_out_map[-1].apply(zero_last_layer)\n",
    "        self.stochastic_state_map[-1].apply(zero_last_layer)\n",
    "        self.stochastic_out_map[-1].apply(zero_last_layer)\n",
    "        self.mode = \"nonlinear\"\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        mode = self.mode\n",
    "        device = x.device\n",
    "        y_pred = torch.zeros_like(y, device=device)\n",
    "        e_pred = torch.zeros_like(y, device=device)\n",
    "        T = x.size(-1)\n",
    "        B = x.size(0)\n",
    "        # n_t = torch.zeros(B, self.deterministic_state_size, device=device)\n",
    "        # z_t = torch.zeros(B, self.stochastic_state_size, device=device)\n",
    "        n_t = self.n0.unsqueeze(0).expand(B, -1)  # [B, nx]\n",
    "        z_t = self.z0.unsqueeze(0).expand(B, -1)  # [B, nz]\n",
    "        # add zeros in front equal to num_taps - 1\n",
    "        x = torch.cat([torch.zeros(B, self.deterministic_num_taps - 1, device=device), x], dim=-1)\n",
    "        for t in range(T):\n",
    "            x_t = x[:, t: t + self.deterministic_num_taps]\n",
    "            y_t = y[:, t]\n",
    "            if mode == \"linear\":\n",
    "                y_t_pred = self.linear_det_out_map(torch.cat([x_t, n_t], dim=-1))\n",
    "            else:\n",
    "                y_t_pred = self.deterministic_out_map(torch.cat([x_t, n_t], dim=-1)) + self.linear_det_out_map(torch.cat([x_t, n_t], dim=-1))\n",
    "            r_t = y_t.unsqueeze(-1) - y_t_pred\n",
    "\n",
    "            if mode == \"linear\":\n",
    "                nonlinear_noise_t = self.linear_stoch_out_map(torch.cat([x_t, n_t, z_t], dim=-1))\n",
    "            else:\n",
    "                nonlinear_noise_t = self.stochastic_out_map(torch.cat([x_t, n_t, z_t], dim=-1)) + self.linear_stoch_out_map(torch.cat([x_t, n_t, z_t], dim=-1))\n",
    "            y_t_next_pred = y_t_pred + nonlinear_noise_t\n",
    "            y_pred[:, t] = y_t_next_pred.squeeze(-1)\n",
    "            e_t = r_t - nonlinear_noise_t\n",
    "            e_pred[:, t] = e_t.squeeze(-1)\n",
    "            # Make state updates\n",
    "\n",
    "            if mode == \"linear\":\n",
    "                z_t = self.linear_stoch_state_map(torch.cat([x_t, z_t, r_t], dim=-1))\n",
    "                n_t = self.linear_det_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "            else:\n",
    "                z_t = self.stochastic_state_map(torch.cat([x_t, z_t, r_t], dim=-1)) + self.linear_stoch_state_map(torch.cat([x_t, z_t, r_t], dim=-1))\n",
    "                n_t = self.deterministic_state_map(torch.cat([x_t, n_t], dim=-1)) + self.linear_det_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "        return y_pred, e_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8420b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_std(model, input_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        noisy_sample, mean_pred, std_pred, _ = model(input_tensor)\n",
    "\n",
    "    xin = input_tensor[0].cpu().numpy()\n",
    "    mean = mean_pred[0].cpu().numpy()\n",
    "    std = std_pred[0].cpu().numpy()\n",
    "    sample = noisy_sample[0].cpu().numpy()\n",
    "\n",
    "    time_steps = np.arange(len(xin))\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    plt.plot(time_steps, mean, label='Predicted Mean', color='blue', linewidth=2)\n",
    "\n",
    "    plt.fill_between(\n",
    "        time_steps,\n",
    "        mean - 2 * std,\n",
    "        mean + 2 * std,\n",
    "        color='blue',\n",
    "        alpha=0.2,\n",
    "        label='Uncertainty (±2σ)'\n",
    "    )\n",
    "\n",
    "    plt.plot(time_steps, sample, label='Generated Sample', color='green', alpha=0.7)\n",
    "\n",
    "    plt.title('Model Prediction with Learned Uncertainty')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=':')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a06a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularizer(model, rho_theta, tau, rho_w):\n",
    "    # θ = all parameters of both models\n",
    "    l2_theta = 0.0\n",
    "    l1_theta = 0.0\n",
    "    for p in list(model.parameters()):\n",
    "        l2_theta = l2_theta + torch.sum(p ** 2)\n",
    "        l1_theta = l1_theta + torch.sum(p.abs())\n",
    "\n",
    "    # \\hat w_0 = [n0, z0] from the state-space model\n",
    "    w0_vec = torch.cat([model.n0.view(-1), model.z0.view(-1)])\n",
    "    l2_w0 = torch.sum(w0_vec ** 2)\n",
    "\n",
    "    reg = 0.5 * float(rho_theta) * l2_theta + float(tau) * l1_theta + 0.5 * float(rho_w) * l2_w0\n",
    "    return reg\n",
    "\n",
    "def train(model, optimizer, loop, config):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    batch_count = 0\n",
    "    thetas = []\n",
    "    for batch in loop:\n",
    "        x, y = batch[0], batch[1]\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred, e_pred = model(x, y)\n",
    "        loss = torch.mean((e_pred ** 2)) + regularizer(model, config.rho_theta, config.tau, config.rho_w)\n",
    "        mse_loss = F.mse_loss(y, y_pred)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        wandb.log({\"innovation_train_loss\": loss.item()})\n",
    "        wandb.log({\"mse_train_loss\": mse_loss.item()})\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        wandb.log({\"learning_rate\": lr})\n",
    "        batch_count += 1\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    loop.close()\n",
    "    return model\n",
    "\n",
    "def val(model, val_loader, config):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    batch_count = 0\n",
    "    y_preds = []\n",
    "    val_mse_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            mean_y, e_pred = model(x, y)\n",
    "            y_preds.append(mean_y)\n",
    "            loss = torch.mean((e_pred ** 2))\n",
    "            mse_loss = F.mse_loss(y, mean_y)\n",
    "            val_mse_loss += mse_loss.item()\n",
    "            val_loss += loss.item()\n",
    "            batch_count += 1\n",
    "    avg_val_loss = (val_loss / batch_count)\n",
    "    avg_val_mse_loss = (val_mse_loss / batch_count)\n",
    "    wandb.log({\n",
    "        \"val_innovation_loss\": avg_val_loss,\n",
    "        \"avg_val_mse_loss\": avg_val_mse_loss\n",
    "    })\n",
    "    return avg_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6978226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(x: torch.Tensor, y: torch.Tensor, lag_max: int) -> torch.Tensor:\n",
    "    '''\n",
    "    Computes batched and normalized correlation between x and y [B, N] up to lag_max times\n",
    "    '''\n",
    "    x_centered = x - x.mean(dim=-1, keepdims=True)\n",
    "    y_centered = y - y.mean(dim=-1, keepdims=True)\n",
    "    cross_corrs = []\n",
    "    N = x_centered.shape[1]\n",
    "    assert lag_max <= N, \"Lag max too long\"\n",
    "    x_rms = torch.sqrt((1 / N) * torch.sum(x_centered ** 2, dim=-1, keepdims=True))\n",
    "    y_rms = torch.sqrt((1 / N) * torch.sum(y_centered ** 2, dim=-1, keepdims=True))\n",
    "    for lag in range(-lag_max, lag_max+1):\n",
    "        if lag >= 0:\n",
    "            shifted_x = x_centered[:, lag:]\n",
    "            shifted_y = y_centered[:, :N-lag]\n",
    "        else:\n",
    "            shifted_x = x_centered[:, :N+lag]\n",
    "            shifted_y = y_centered[:, -lag:]\n",
    "\n",
    "        corr = torch.mean(shifted_x * shifted_y, dim=-1, keepdim=True)\n",
    "        corr_norm = torch.mean(corr / (x_rms * y_rms), dim=0) # Average across batches\n",
    "        cross_corrs.append(corr_norm)\n",
    "\n",
    "    return torch.stack(cross_corrs, dim=0)\n",
    "\n",
    "\n",
    "def compute_billings_corrs(batched_residuals: torch.Tensor, batched_inputs: torch.Tensor,\n",
    "                           lag_max: int, log_wandb: bool = False, prefix: str = \"billings_correlation\"):\n",
    "    '''\n",
    "    Computs the Billing's et al correlation parameters to determine whether a model\n",
    "    has captured the system's nonlinearity\n",
    "\n",
    "    Args:\n",
    "        batched_residuals: model errors of shape [B, N]\n",
    "        batched_inputs: model inputs of shape [B, N]\n",
    "    '''\n",
    "\n",
    "\n",
    "    batched_residuals = batched_residuals - batched_residuals.mean(dim=-1, keepdim=True)\n",
    "    batched_inputs = batched_inputs - batched_inputs.mean(dim=-1, keepdim=True)\n",
    "\n",
    "    def _plot_and_log(y_np, title, key):\n",
    "        fig, ax = plt.subplots(figsize=(6, 3.5))\n",
    "        ax.plot(lags, y_np.ravel(), label=key)\n",
    "        ax.hlines(confidence_value, -lag_max, lag_max, colors='r', linestyles='dashed', label=\"95% CI\")\n",
    "        ax.hlines(-confidence_value, -lag_max, lag_max, colors='r', linestyles='dashed')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"Lag\")\n",
    "        ax.set_ylabel(\"Correlation\")\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if log_wandb:\n",
    "            wandb.log({f\"{prefix}/{key}\": wandb.Image(fig)})\n",
    "        else:\n",
    "            plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "    confidence_value = 1.96 / np.sqrt(batched_residuals.shape[1])\n",
    "    lags = lags = np.arange(-lag_max, lag_max + 1)\n",
    "\n",
    "    phi_r_r = correlation(batched_residuals, batched_residuals, lag_max).cpu().numpy()\n",
    "    _plot_and_log(phi_r_r, \"Residual Autocorrelation\", \"residual_autocorr\")\n",
    "    phi_u_r = correlation(batched_inputs, batched_residuals, lag_max).cpu().numpy()\n",
    "    _plot_and_log(phi_u_r, \"Input-Residual Correlation\", \"input_residual_corr\")\n",
    "    # shifted_product = batched_residuals[:, 1:] * batched_inputs[:, 1:]\n",
    "    phi_r_ru = correlation(batched_residuals, batched_inputs * batched_residuals, lag_max).cpu().numpy()\n",
    "    _plot_and_log(phi_r_ru, \"Residual-Residual*Input Correlation\", \"residual_residual_input_corr\")\n",
    "\n",
    "    u_prime_squared = torch.square(batched_inputs) - torch.mean(batched_inputs ** 2, dim=-1, keepdim=True)\n",
    "    phi_u_prime_squared_r = correlation(u_prime_squared, batched_residuals, lag_max).cpu().numpy()\n",
    "    _plot_and_log(phi_u_prime_squared_r, \"(U^2)' Residual Correlation\", \"u_squared_prime_residual_corr\")\n",
    "\n",
    "    phi_u_prime_squared_r_squared = correlation(u_prime_squared, batched_residuals ** 2, lag_max).cpu().numpy()\n",
    "    _plot_and_log(phi_u_prime_squared_r_squared, \"(U^2)' Residual ^2 Correlation\", \"u_squared_prime_residual_squared_corr\")\n",
    "\n",
    "\n",
    "sns.reset_defaults()      # resets seaborn styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d015368",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_optimizer(mode, channel_model, noise_model, channel_model_linear, config):\n",
    "    if mode == \"linear_only\":\n",
    "        return optim.AdamW(\n",
    "            list(channel_model_linear),\n",
    "            lr=float(config.lr_linear),\n",
    "            weight_decay=float(config.wd_linear)\n",
    "        )\n",
    "    if mode == \"channel_only\":\n",
    "        return optim.AdamW(\n",
    "            list(channel_model),\n",
    "            lr=float(config.lr_channel),\n",
    "            weight_decay=float(config.wd_channel)\n",
    "        )\n",
    "\n",
    "    elif mode == \"noise_only\":\n",
    "        return optim.AdamW(\n",
    "            list(noise_model),\n",
    "            lr=float(config.lr_noise),\n",
    "            weight_decay=float(config.wd_noise)\n",
    "        )\n",
    "\n",
    "    elif mode == \"joint\":\n",
    "        return optim.AdamW(\n",
    "            list(channel_model) +\n",
    "            list(noise_model),\n",
    "            lr=float(config.lr_joint),\n",
    "            weight_decay=float(config.wd_joint)\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown mode\")\n",
    "\n",
    "def run_experiment(config):\n",
    "    script_dir = os.getcwd()\n",
    "    config_path = os.path.join(script_dir, \"..\", \"state_space_config.yml\")\n",
    "    with open(config_path, \"r\") as f:\n",
    "        hyperparams = yaml.safe_load(f)\n",
    "\n",
    "    # Start Weights and Biases session\n",
    "    wandb.init(project=\"mldrivenpeled\",\n",
    "            config=hyperparams, tags=['channel_model'])\n",
    "    config = wandb.config\n",
    "\n",
    "    print(f\"WandB run info:\")\n",
    "    print(f\"  Name: {wandb.run.name}\")\n",
    "    print(f\"  ID: {wandb.run.id}\")\n",
    "    print(f\"  URL: {wandb.run.url}\")\n",
    "    print(\"Chosen hyperparameters for this session:\")\n",
    "    print(config)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=config.batch_size, drop_last=False)\n",
    "    test_loader = DataLoader(test_dataset)\n",
    "    val_loader = DataLoader(val_dataset, shuffle=True, batch_size=config.batch_size, drop_last=False)\n",
    "\n",
    "    channel_model = StateSpaceModel(\n",
    "        deterministic_num_taps=config.deterministic_num_taps,\n",
    "        deterministic_hidden_size=config.deterministic_hidden_size,\n",
    "        stochastic_hidden_size=config.stochastic_hidden_size,\n",
    "        stochastic_state_size=config.stochastic_state_size,\n",
    "        deterministic_state_size=config.deterministic_state_size\n",
    "    ).to(device)\n",
    "\n",
    "    def init_xavier_zero_bias(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "    channel_model.apply(init_xavier_zero_bias)\n",
    "\n",
    "\n",
    "\n",
    "    channel_model_params = (\n",
    "        list(channel_model.deterministic_out_map.parameters()) +\n",
    "        list(channel_model.deterministic_state_map.parameters()) +\n",
    "        [channel_model.n0]\n",
    "    )\n",
    "\n",
    "    channel_model_linear_params = (\n",
    "        list(channel_model.linear_det_out_map.parameters()) +\n",
    "        list(channel_model.linear_det_state_map.parameters()) +\n",
    "        list(channel_model.linear_stoch_state_map.parameters()) +\n",
    "        list(channel_model.linear_stoch_out_map.parameters())\n",
    "    )\n",
    "\n",
    "    noise_model_params = (\n",
    "        list(channel_model.stochastic_out_map.parameters()) +\n",
    "        list(channel_model.stochastic_state_map.parameters()) +\n",
    "        [channel_model.z0]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # lbfgs = torch.optim.LBFGS(\n",
    "    #         channel_model.parameters(),\n",
    "    #         lr=1.0,\n",
    "    #         max_iter=20,\n",
    "    #         history_size=10,\n",
    "    #         line_search_fn=\"strong_wolfe\"\n",
    "    #     )\n",
    "\n",
    "    # num_adam_epochs = config.num_adam_epochs\n",
    "    # num_LBFGS_epochs = config.num_LBFGS_epochs\n",
    "    # for epoch in range(num_adam_epochs):\n",
    "    #     loop = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_adam_epochs}', leave=False)\n",
    "    #     train(channel_model, adam, loop, config)\n",
    "    #     avg_val_loss = val(channel_model, val_loader, config)\n",
    "    #     scheduler.step(avg_val_loss)\n",
    "\n",
    "\n",
    "    schedule = config.training_schedule\n",
    "    epoch_counter = 0\n",
    "    for phase in schedule:\n",
    "        mode = phase[\"mode\"]\n",
    "        num_phase_epochs = phase[\"epochs\"]\n",
    "\n",
    "        optimizer = make_optimizer(mode, channel_model_params, noise_model_params, channel_model_linear_params, config)\n",
    "\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1, min_lr=1e-6)\n",
    "        channel_model.mode = mode\n",
    "        for local_epoch in range(num_phase_epochs):\n",
    "            epoch_counter += 1\n",
    "            loop = tqdm(train_loader, desc=f'Epoch {epoch_counter} [{mode}]')\n",
    "            train(channel_model, optimizer, loop, config)\n",
    "            avg_val_loss = val(channel_model, val_loader, config)\n",
    "            scheduler.step(avg_val_loss)\n",
    "\n",
    "    def count_parameters(model):\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(f\"Trainable parameters: {count_parameters(channel_model):,}\")\n",
    "    # Freeze modelj\n",
    "    for param in channel_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Save model\n",
    "    torch.save({\n",
    "        \"channel_model\": channel_model.state_dict(),\n",
    "    }, \"channel_model_final.pth\")\n",
    "\n",
    "    artifact = wandb.Artifact(\"channel_model\", type=\"model\")\n",
    "    artifact.add_file(\"channel_model_final.pth\")\n",
    "    wandb.log_artifact(artifact)\n",
    "    print(\"Finished!\")\n",
    "    run_name = wandb.run.name\n",
    "    return avg_val_loss, run_name, channel_model, train_loader, val_loader\n",
    "\n",
    "param_grid = {\n",
    "    'lr': [1e-3],\n",
    "    'deterministic_hidden_size': [8],\n",
    "    'stochastic_hidden_size': [8],\n",
    "    'deterministic_num_taps': [4],\n",
    "    'stochastic_state_size': [2],\n",
    "    'deterministic_state_size': [1]\n",
    "}\n",
    "\n",
    "keys, values = zip(*param_grid.items())\n",
    "\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_config = None\n",
    "best_run_id = None\n",
    "for v in itertools.product(*values):\n",
    "    config = dict(zip(keys, v))\n",
    "\n",
    "    # load static config defaults\n",
    "    with open(\"../state_space_config.yml\", \"r\") as f:\n",
    "        base_cfg = yaml.safe_load(f)\n",
    "\n",
    "    # override base config\n",
    "    base_cfg.update(config)\n",
    "\n",
    "    val_loss, run_id, channel_model, train_loader, val_loader = run_experiment(base_cfg)\n",
    "\n",
    "\n",
    "\n",
    "    innovations = []\n",
    "    all_residuals = []\n",
    "    all_inputs = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(device)\n",
    "            all_inputs.append(x)\n",
    "            y = y.to(device)\n",
    "            y_pred, e_pred = channel_model(x, y)\n",
    "            innovations.append(e_pred)\n",
    "    all_inputs_tensor = torch.cat(all_inputs, dim=0)[:100, :]\n",
    "    all_innovations_tensor = torch.cat(innovations, dim=0)[:100, :]\n",
    "\n",
    "    compute_billings_corrs(all_innovations_tensor, all_inputs_tensor, 20, log_wandb=True, prefix=\"val_billings_correlation\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_config = base_cfg\n",
    "        best_run_id = run_id\n",
    "        print(\"New best found!\")\n",
    "        print(f\"Best Run ID: {best_run_id}\")\n",
    "        print(f\"Best Validation Loss: {best_val_loss}\")\n",
    "        print(f\"Best Configuration: {best_config}\")\n",
    "        print(\"New best found!\")\n",
    "    wandb.finish()\n",
    "print(f\"Best Run ID: {best_run_id}\")\n",
    "print(f\"Best Validation Loss: {best_val_loss}\")\n",
    "print(f\"Best Configuration: {best_config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ecb4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load in chosen model\n",
    "\n",
    "# api = wandb.Api()\n",
    "# run = api.run(\"dylanbackprops-university-of-washington/mldrivenpeled/oibih492\") # Variable\n",
    "# model_name = \"channel_model_final\"\n",
    "# artifact = api.artifact(\"dylanbackprops-university-of-washington/mldrivenpeled/channel_model:v581\") # Variable\n",
    "# artifact_dir = artifact.download()\n",
    "# remote_config = run.config\n",
    "# run_name = run.name\n",
    "# print(\"Channel Run name:\", run_name)\n",
    "\n",
    "# channel_model = StateSpaceModel(\n",
    "#     nlayers=remote_config['nlayers'],\n",
    "#     dilation_base=remote_config['dilation_base'],\n",
    "#     num_taps=remote_config['num_taps'],\n",
    "#     hidden_channels=remote_config['hidden_channels'],\n",
    "#     learn_noise=remote_config['learn_noise'],\n",
    "#     gaussian=remote_config['gaussian']\n",
    "# ).to(device)\n",
    "\n",
    "\n",
    "# channel_model_path = os.path.join(artifact_dir, model_name + \".pth\")\n",
    "# checkpoint = torch.load(channel_model_path)\n",
    "# channel_model.load_state_dict(checkpoint[\"channel_model\"])\n",
    "\n",
    "# # Freeze before moving to device\n",
    "# for param in channel_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# channel_model = channel_model.to(device).float()\n",
    "# channel_model.eval()\n",
    "\n",
    "# print(\"Channel model parameters frozen:\",\n",
    "#       all(not param.requires_grad for param in channel_model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fbd2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b0d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "t = torch.linspace(0, 1, NUM_POINTS_FRAME)\n",
    "\n",
    "\n",
    "freqs = torch.arange(K_MIN, 3000)[::100]\n",
    "\n",
    "# # Downsample frequency sweep\n",
    "# freqs = KS[::200].cpu()\n",
    "\n",
    "\n",
    "# print(freqs)\n",
    "freq_step_hz = 10e3\n",
    "freqs_hz = freqs * freq_step_hz\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Normalize by real frequency values\n",
    "norm = plt.Normalize(vmin=min(freqs_hz), vmax=max(freqs_hz))\n",
    "cmap = cm.get_cmap('viridis')\n",
    "\n",
    "\n",
    "\n",
    "def loop_area(x, y):\n",
    "    # x, y are 1D numpy arrays\n",
    "    return 0.5 * np.trapezoid(y, x)\n",
    "\n",
    "areas = []\n",
    "for f_idx, f_hz in zip(freqs, freqs_hz):\n",
    "    x = 3 * torch.sin(2 * np.pi * f_idx * t).unsqueeze(0).to(device)\n",
    "    _, y, _, _ = channel_model(x)\n",
    "\n",
    "    x = x.squeeze().cpu().numpy()\n",
    "    y = y.squeeze().cpu().numpy()\n",
    "\n",
    "    ax.scatter(x, y, color=cmap(norm(f_hz)), s=0.5, alpha=0.5)\n",
    "    areas.append(loop_area(x,y))\n",
    "\n",
    "\n",
    "sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "sm.set_array([])\n",
    "\n",
    "cbar = fig.colorbar(sm, ax=ax)\n",
    "cbar.set_label(\"Frequency (kHz)\")\n",
    "tick_vals = np.linspace(min(freqs_hz), max(freqs_hz), 6)\n",
    "cbar.set_ticks(tick_vals)\n",
    "cbar.set_ticklabels((tick_vals.numpy() / 1e3).astype(int))  # display in kHz\n",
    "\n",
    "ax.set_title(\"Model Prediction for Sinusoidal Inputs at Various Frequencies\")\n",
    "ax.set_xlabel(\"Input\")\n",
    "ax.set_ylabel(\"Output\")\n",
    "ax.grid(True, linestyle=':')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldrivenpeled2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
