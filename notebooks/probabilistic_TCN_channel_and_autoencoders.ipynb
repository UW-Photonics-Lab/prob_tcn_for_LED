{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dbdd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import copy\n",
    "import math\n",
    "import wandb\n",
    "import yaml\n",
    "import zarr\n",
    "from scipy.fft import rfft\n",
    "import seaborn as sns\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from lab_scripts.constellation_diagram import QPSK_Constellation\n",
    "from lab_scripts.constellation_diagram import RingShapedConstellation\n",
    "from modules.models import TCN_channel, TCN, memory_polynomial_channel\n",
    "\n",
    "if wandb.run is not None:\n",
    "    wandb.run.tags = list(wandb.run.tags) + [\"junk\"]\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78649825",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Import and cache dataset for fast loading in future\n",
    "'''\n",
    "\n",
    "# file_path = \"C:/Users/maild/mldrivenpeled/data/channel_measurements/zarr_files/channel_3e5-15MHz_3.5V_scale2.zarr\"\n",
    "# file_path = r\"C:\\Users\\maild\\mldrivenpeled\\data\\channel_measurements\\zarr_files\\channel_3e5-15MHz_2.9V_scale2_dynamic_power_0.5-3.zarr\"\n",
    "file_path = r\"C:\\Users\\maild\\mldrivenpeled\\data\\channel_measurements\\zarr_files\\channel_3e5-8.6MHz_2.7V_scale2_dynamic_power_0.5-3.zarr\"\n",
    "# file_path = \"C:/Users/maild/mldrivenpeled/data/channel_measurements/zarr_files/channel_3e5-15MHz_2.8V_scale2_v2.zarr\"\n",
    "# file_path = \"C:/Users/maild/mldrivenpeled/data/channel_measurements/zarr_files/test/channel_3e5-8MHz_2.6V_scale2_v2.zarr\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\") # for M chip Macs\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Device\", device)\n",
    "FREQUENCIES = None\n",
    "\n",
    "cache_path = file_path.replace(\".zarr\", \"_cached.pt\").replace(\".h5\", \"_cached.pt\")\n",
    "if os.path.exists(cache_path):\n",
    "    data = torch.load(cache_path, map_location=device)\n",
    "    sent_frames_time = data[\"sent_frames_time\"].to(device)\n",
    "    received_frames_time = data[\"received_frames_time\"].to(device)\n",
    "    FREQUENCIES = data[\"frequencies\"].to(device)\n",
    "    NUM_POINTS_SYMBOL = data[\"NUM_POINTS_SYMBOL\"]\n",
    "    CP_LENGTH = data[\"CP_LENGTH\"]\n",
    "    delta_f = FREQUENCIES[1] - FREQUENCIES[0]\n",
    "    KS = (FREQUENCIES / delta_f).to(torch.int)\n",
    "    K_MIN = int(KS[0].item())\n",
    "    K_MAX = int(KS[-1].item())\n",
    "    NUM_ZEROS = K_MIN - 1\n",
    "    CP_RATIO = 0.25 # Known from experiment\n",
    "    NUM_POINTS_FRAME = NUM_POINTS_SYMBOL - CP_LENGTH\n",
    "    NUM_POS_FREQS_LOW_BAND = K_MAX + 1\n",
    "    UPSAMPLING_ZEROS = (NUM_POINTS_FRAME  - 2 * NUM_POS_FREQS_LOW_BAND) // 2\n",
    "    print(\"Loaded from cache!\")\n",
    "\n",
    "else:\n",
    "    print(\"No cache found â€” loading original dataset...\")\n",
    "\n",
    "\n",
    "        # Open the Zarr root\n",
    "    root = zarr.open(file_path, mode=\"r\")\n",
    "\n",
    "    # Load metadata (attributes live under .attrs)\n",
    "    sent, received, received_time = [], [], []\n",
    "    # Loop through frames\n",
    "    num_skipped = 0\n",
    "    for frame_key in root.group_keys():\n",
    "        try:\n",
    "            frame = root[frame_key]\n",
    "            if FREQUENCIES is None:\n",
    "                FREQUENCIES = torch.tensor(frame[\"freqs\"][:], dtype=torch.int).real\n",
    "                NUM_POINTS_SYMBOL = int(frame.attrs[\"num_points_symbol\"])\n",
    "                CP_LENGTH = int(frame.attrs[\"cp_length\"])\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            sent.append(torch.tensor(frame[\"sent\"][:], dtype=torch.complex64))\n",
    "            received.append(torch.tensor(frame[\"received\"][:], dtype=torch.complex64))\n",
    "            if \"received_time\" in frame:\n",
    "                received_time.append(torch.tensor(frame[\"received_time\"][:], dtype=torch.float32))\n",
    "        except:\n",
    "            num_skipped += 1\n",
    "            pass # skip corrupted frames\n",
    "    print(f\"Skipped {num_skipped} corrupted frames\")\n",
    "\n",
    "\n",
    "    sent_frames = torch.stack(sent).squeeze(1)\n",
    "    received_frames = torch.stack(received).squeeze(1)\n",
    "\n",
    "    # Establish globals\n",
    "    delta_f = FREQUENCIES[1] - FREQUENCIES[0]\n",
    "    KS = (FREQUENCIES / delta_f).to(torch.int)\n",
    "    K_MIN = int(KS[0].item())\n",
    "    K_MAX = int(KS[-1].item())\n",
    "    NUM_ZEROS = K_MIN - 1\n",
    "    CP_RATIO = 0.25\n",
    "    NUM_POINTS_FRAME = NUM_POINTS_SYMBOL - CP_LENGTH\n",
    "    NUM_POS_FREQS_LOW_BAND = K_MAX + 1\n",
    "    UPSAMPLING_ZEROS = (NUM_POINTS_FRAME  - 2 * NUM_POS_FREQS_LOW_BAND) // 2\n",
    "\n",
    "\n",
    "    def symbols_to_time(X, num_padding_zeros: int, num_leading_zeros=0, negative_rail=-3.0, positive_rail=3.0):\n",
    "        'Convert OFDM symbols to real valued signal'\n",
    "        # Make hermetian symmetric\n",
    "        Nt, Nf = X.shape\n",
    "        padding_zeros = torch.zeros(Nt, num_padding_zeros, device=device)\n",
    "        leading_zeros = torch.zeros(Nt, num_leading_zeros, device=device)\n",
    "        X = torch.cat([leading_zeros, X.to(device), padding_zeros], dim=-1)\n",
    "        DC_Nyquist = torch.zeros((X.shape[0], 1), device=X.device)\n",
    "        X_hermitian = torch.flip(X, dims=[1]).conj()\n",
    "        X_full = torch.hstack([DC_Nyquist, X, DC_Nyquist, X_hermitian])\n",
    "\n",
    "        # Convert to time domain\n",
    "        x_time = torch.fft.ifft(X_full, dim=-1, norm=\"ortho\").real\n",
    "        x_time = torch.clip(x_time, min=negative_rail, max=positive_rail)\n",
    "        return x_time.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Handle received time symbols; perform some cleaning if necessary\n",
    "    N_shortest = min(t.size(-1) for t in received_time)\n",
    "    N_longest = max(t.size(-1) for t in received_time)\n",
    "    good_indices = [i for i, x in enumerate(received_time) if x.size(-1) == N_shortest]\n",
    "    received_frames_time = torch.stack([t for t in received_time if t.size(-1) == N_shortest], dim=0).real\n",
    "    sent_frames = sent_frames[good_indices]\n",
    "    received_frames_time = received_frames_time.squeeze(1)\n",
    "\n",
    "\n",
    "    sent_frames_time = symbols_to_time(sent_frames, UPSAMPLING_ZEROS, NUM_ZEROS)\n",
    "    # Add cyclic prefix\n",
    "    sent_frames_time = torch.hstack((sent_frames_time[:, -CP_LENGTH:], sent_frames_time))\n",
    "\n",
    "\n",
    "\n",
    "    DELAY_TIME = 0 # If for some reason there is a global delay with measure data adjust here\n",
    "    if DELAY_TIME > 0:\n",
    "        sent_frames_time = sent_frames_time[:, :-DELAY_TIME]\n",
    "    received_frames_time = received_frames_time[:, DELAY_TIME:]\n",
    "    received_frames_time = received_frames_time - received_frames_time.mean(dim=1, keepdim=True) # Always zero mean\n",
    "    sent_frames_time = sent_frames_time.to(device)\n",
    "    received_frames_time = received_frames_time.to(device)\n",
    "\n",
    "\n",
    "    # Create a cache path\n",
    "    cache_path = file_path.replace(\".zarr\", \"_cached.pt\").replace(\".h5\", \"_cached.pt\")\n",
    "\n",
    "    torch.save({\n",
    "        \"sent_frames_time\": sent_frames_time.cpu(),\n",
    "        \"received_frames_time\": received_frames_time.cpu(),\n",
    "        \"frequencies\": FREQUENCIES.cpu(),\n",
    "        \"NUM_POINTS_SYMBOL\": NUM_POINTS_SYMBOL,\n",
    "        \"CP_LENGTH\": CP_LENGTH\n",
    "    }, cache_path)\n",
    "\n",
    "\n",
    "class ChannelData(Dataset):\n",
    "    def __init__(self,\n",
    "                sent_frames,\n",
    "                received_frames,\n",
    "                frequencies,\n",
    "                transform=None,\n",
    "                target_transform=None):\n",
    "\n",
    "        self.sent_frames = sent_frames\n",
    "        self.received_frames = received_frames\n",
    "        assert len(sent_frames) == len(received_frames)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sent_frames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sent_frames[idx], self.received_frames[idx]\n",
    "\n",
    "\n",
    "dataset = ChannelData(sent_frames_time, received_frames_time, FREQUENCIES)\n",
    "\n",
    "# Split sizes\n",
    "train_size = int(0.9 * len(dataset))\n",
    "\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size  # ensures total = 100%\n",
    "\n",
    "# Perform split\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset,\n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator()\n",
    ")\n",
    "print(\"Train Size\", train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.fft.fft(received_frames_time[0, CP_LENGTH:].cpu()).abs()\n",
    "plt.plot(t[:len(t)//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca0e6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_frames_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff91cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "received_frames_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa6d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.fft.fft(sent_frames_time[0, CP_LENGTH:].cpu()).abs()\n",
    "plt.plot(t[:len(t)//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f21c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = received_frames_time.cpu().numpy()\n",
    "plt.plot(r[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse_pct_loss(y, y_pred):\n",
    "    r = y - y_pred\n",
    "    return (torch.sqrt(torch.mean(r ** 2) / torch.mean(y ** 2)) * 100).item()\n",
    "\n",
    "def train(model, optimizer, loss_fn, loop):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    batch_count = 0\n",
    "    thetas = []\n",
    "    for batch in loop:\n",
    "        x, y = batch[0], batch[1]\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        noisy_y_pred, y_pred, y_pred_std, y_pred_nu = model(x)\n",
    "\n",
    "        # calculate residual\n",
    "        r = y - y_pred\n",
    "\n",
    "        if model.learn_noise:\n",
    "            if model.gaussian:\n",
    "                loss = loss_fn(r, y_pred_std)\n",
    "            else:\n",
    "                loss = loss_fn(r, y_pred_std, y_pred_nu)\n",
    "        else:\n",
    "            loss = loss_fn(y, y_pred)\n",
    "\n",
    "        mse_loss = F.mse_loss(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        wandb.log({\"nnl_train_loss\": loss.item()})\n",
    "        wandb.log({\"mse_train_loss\": mse_loss.item()})\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        wandb.log({\"learning_rate\": lr})\n",
    "        batch_count += 1\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    loop.close()\n",
    "\n",
    "\n",
    "def val(model, loss_fn, val_loader, memory_polynomial=None):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    batch_count = 0\n",
    "    y_preds = []\n",
    "    std_preds = []\n",
    "    nu_preds = []\n",
    "    true_ys = []\n",
    "    noisy_ys = []\n",
    "    val_mse_loss = 0\n",
    "    nrmse_pct_loss = 0.0\n",
    "    mse_mem_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            noisy_y, mean_y, std_y, nu_y = model(x)\n",
    "            y_preds.append(mean_y)\n",
    "            std_preds.append(std_y)\n",
    "            nu_preds.append(nu_y)\n",
    "            true_ys.append(y)\n",
    "            noisy_ys.append(noisy_y)\n",
    "            if model.learn_noise:\n",
    "                if model.gaussian:\n",
    "                    loss = loss_fn(y - mean_y, std_y) # Use mean for validation\n",
    "                else:\n",
    "                    loss = loss_fn(y - mean_y, std_y, nu_y) # Use mean for validation\n",
    "            else:\n",
    "                loss = loss_fn(y, mean_y)\n",
    "            mse_loss = F.mse_loss(y, mean_y)\n",
    "            nrmse_pct_loss += calculate_rmse_pct_loss(y, mean_y)\n",
    "            val_mse_loss += mse_loss.item()\n",
    "            val_loss += loss.item()\n",
    "            batch_count += 1\n",
    "            if memory_polynomial:\n",
    "                mse_mem_loss += calculate_rmse_pct_loss(y, memory_polynomial(x))\n",
    "\n",
    "    avg_val_loss = (val_loss / batch_count)\n",
    "    avg_val_mse_loss = (val_mse_loss / batch_count)\n",
    "    avg_val_mem_loss = (mse_mem_loss / batch_count)\n",
    "    avg_nrmse_pct_loss = (nrmse_pct_loss / batch_count)\n",
    "\n",
    "    y_preds = torch.vstack(y_preds)\n",
    "    std_preds = torch.vstack(std_preds)\n",
    "    nu_preds = torch.vstack(nu_preds)\n",
    "    true_ys = torch.vstack(true_ys)\n",
    "    noisy_ys = torch.vstack(noisy_ys)\n",
    "\n",
    "\n",
    "    noise_pred = noisy_ys - y_preds\n",
    "    noise_power_pred_k = torch.fft.fft(noise_pred[:, CP_LENGTH:], norm='ortho', dim=-1).abs().square().mean(dim=0)\n",
    "    signal_power_model = torch.fft.fft(y_preds[:, CP_LENGTH:], norm='ortho', dim=-1).abs().square().mean(dim=0)\n",
    "    snr_k_model = (signal_power_model / (noise_power_pred_k + 1e-8))\n",
    "    sample_rate = delta_f * NUM_POINTS_FRAME\n",
    "    snr_mag_model = 10 * torch.log10(torch.abs(snr_k_model) + 1e-8)\n",
    "    freqs = torch.fft.fftfreq(len(snr_mag_model), d=1/sample_rate)\n",
    "    half = len(freqs)//2\n",
    "    freqs = freqs[:half]\n",
    "    snr_mag_model = snr_mag_model[:half]\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.plot(freqs, snr_mag_model.cpu(), lw=1.5, color=\"orange\")\n",
    "    ax.set_title(\"SNR vs Frequency (Model)\", fontsize=11)\n",
    "    ax.set_xlabel(\"Frequency\", fontsize=9)\n",
    "    ax.set_ylabel(\"SNR Magnitude (dB)\", fontsize=9)\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    # # ---- Log to WandB ----\n",
    "    wandb.log({\"SNR_Frequency\": wandb.Image(fig)})\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "    # Log both scalar and histogram\n",
    "    wandb.log({\n",
    "        'val_nll_loss': avg_val_loss,\n",
    "        \"avg_val_mse_loss\": avg_val_mse_loss,\n",
    "        \"avg_nrmse_pct_loss\": avg_nrmse_pct_loss\n",
    "    })\n",
    "    if memory_polynomial:\n",
    "     wandb.log({\n",
    "        'val_mem_poly_nrmse_pct_loss': avg_val_mem_loss\n",
    "    })\n",
    "\n",
    "    # print(f\"Average Val Loss: {avg_val_loss:.2e}\")\n",
    "\n",
    "    # visualize_std(model, x[:, :200])\n",
    "    return avg_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d961ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def students_t_loss(difference, y_pred_std, y_pred_nu):\n",
    "    # nu = y_pred_nu.clamp_min(2.0)\n",
    "    nu = y_pred_nu\n",
    "    z_resid = (difference) / (y_pred_std)\n",
    "    term1 = -1 * torch.lgamma((nu + 1) / 2) + 0.5 * torch.log(torch.pi * nu) + torch.lgamma(nu / 2) + torch.log(y_pred_std + 1e-8)\n",
    "    term2 = ((nu + 1) / 2) * torch.log(1 + (1 / nu) * torch.square(z_resid) + 1e-8)\n",
    "    loss = torch.mean(term1 + term2)\n",
    "    if torch.isnan(loss):\n",
    "        raise ValueError(\"NaN in loss\")\n",
    "    return loss\n",
    "\n",
    "def gaussian_nll(difference, y_pred_std):\n",
    "    term1 = 0.5 * torch.log(2 * torch.pi * (y_pred_std ** 2))\n",
    "    term2 = 0.5 * torch.square((difference) / y_pred_std)\n",
    "    loss = torch.mean(term1 + term2)\n",
    "    if torch.isnan(loss):\n",
    "        raise ValueError(\"NaN in loss\")\n",
    "    return loss\n",
    "\n",
    "noise_model = None\n",
    "\n",
    "def make_optimizer(mode):\n",
    "    if mode == \"channel_only\":\n",
    "        return optim.AdamW(\n",
    "            list(channel_model.parameters()),\n",
    "            lr=float(config.lr_channel),\n",
    "            weight_decay=float(config.wd_channel)\n",
    "        )\n",
    "\n",
    "    elif mode == \"noise_only\":\n",
    "        return optim.AdamW(\n",
    "            list(noise_model.parameters()),\n",
    "            lr=float(config.lr_noise),\n",
    "            weight_decay=float(config.wd_noise)\n",
    "        )\n",
    "\n",
    "    elif mode == \"joint\":\n",
    "        return optim.AdamW(\n",
    "            list(channel_model.parameters()) +\n",
    "            list(noise_model.parameters()),\n",
    "            lr=float(config.lr_joint),\n",
    "            weight_decay=float(config.wd_joint)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unknown mode\")\n",
    "\n",
    "\n",
    "script_dir = os.getcwd()\n",
    "config_path = os.path.join(script_dir, \"..\", \"offline_time_channel_config.yml\")\n",
    "with open(config_path, \"r\") as f:\n",
    "    hyperparams = yaml.safe_load(f)\n",
    "\n",
    "# Start Weights and Biases session\n",
    "wandb.init(project=\"mldrivenpeled\",\n",
    "           config=hyperparams, tags=['channel_model'])\n",
    "config = wandb.config\n",
    "\n",
    "schedule = config.training_schedule\n",
    "\n",
    "\n",
    "RECEPTIVE_FIELD = (1 + (config.num_taps - 1) * (config.dilation_base**config.nlayers - 1) // (config.dilation_base - 1))\n",
    "\n",
    "\n",
    "print(f\"WandB run info:\")\n",
    "print(f\"  Name: {wandb.run.name}\")\n",
    "print(f\"  ID: {wandb.run.id}\")\n",
    "print(f\"  URL: {wandb.run.url}\")\n",
    "print(\"Chosen hyperparameters for this session:\")\n",
    "print(config)\n",
    "\n",
    "\n",
    "# Create dataloader\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=config.batch_size, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=config.batch_size, drop_last=False)\n",
    "\n",
    "\n",
    "channel_model = TCN_channel(\n",
    "    nlayers=config.nlayers,\n",
    "    dilation_base=config.dilation_base,\n",
    "    num_taps=config.num_taps,\n",
    "    hidden_channels=config.hidden_channels,\n",
    "    learn_noise=config.learn_noise,\n",
    "    gaussian=config.gaussian\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# Fit memory polynomial for reference\n",
    "memory_polynomial = memory_polynomial_channel(weights=None, memory_linear=10, memory_nonlinear=10, nonlinearity_order=2, device=device)\n",
    "memory_polynomial.fit(sent_frames_time, received_frames_time)\n",
    "\n",
    "initial_model_state = copy.deepcopy(channel_model.state_dict())\n",
    "\n",
    "if channel_model.gaussian:\n",
    "    loss_fn = gaussian_nll\n",
    "else:\n",
    "    loss_fn = students_t_loss\n",
    "\n",
    "# loss_fn = F.mse_loss\n",
    "\n",
    "num_epochs = config.epochs\n",
    "\n",
    "epoch_counter = 0\n",
    "for phase in schedule:\n",
    "    mode = phase[\"mode\"]\n",
    "    num_batches = None # if None, all batches run\n",
    "    if \"batches\" in phase:\n",
    "        num_batches = phase[\"batches\"]\n",
    "    num_phase_epochs = phase[\"epochs\"]\n",
    "\n",
    "\n",
    "    optimizer = make_optimizer(mode)\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1, min_lr=1e-6)\n",
    "\n",
    "    for local_epoch in range(num_phase_epochs):\n",
    "        epoch_counter += 1\n",
    "\n",
    "        loop = tqdm(train_loader, desc=f'Epoch {epoch_counter} [{mode}]')\n",
    "        train(channel_model,\n",
    "              optimizer,\n",
    "              loss_fn,\n",
    "              loop)\n",
    "\n",
    "        avg_val_loss = val(channel_model,\n",
    "                           loss_fn,\n",
    "                           val_loader,\n",
    "                           memory_polynomial=memory_polynomial)\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Trainable parameters: {count_parameters(channel_model):,}\")\n",
    "# Freeze model\n",
    "for param in channel_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Save model\n",
    "torch.save({\n",
    "    \"channel_model\": channel_model.state_dict(),\n",
    "}, \"channel_model_final.pth\")\n",
    "\n",
    "artifact = wandb.Artifact(\"channel_model\", type=\"model\")\n",
    "artifact.add_file(\"channel_model_final.pth\")\n",
    "logged_artifact = wandb.log_artifact(artifact)\n",
    "\n",
    "# Get version from server for next stage\n",
    "logged_artifact.wait()\n",
    "\n",
    "channel_model_version = logged_artifact.version\n",
    "channel_model_artifact_path = logged_artifact.name\n",
    "\n",
    "print(\"Finished!\")\n",
    "run_name = wandb.run.name\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feb0188",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc6339c",
   "metadata": {},
   "source": [
    "### Memory Polynomial for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99aa837",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POINTS_FRAME = 6000\n",
    "CP_LENGTH = 2000\n",
    "NUM_POINTS_SYMBOL = NUM_POINTS_FRAME + CP_LENGTH\n",
    "\n",
    "TCN_CHANNEL = False\n",
    "if TCN_CHANNEL:\n",
    "    api = wandb.Api()\n",
    "    # run = api.run(\"dylanbackprops-university-of-washington/mldrivenpeled/oibih492\") # Variable\n",
    "    model_name = \"channel_model_final\"\n",
    "    # artifact = api.artifact(\"dylanbackprops-university-of-washington/mldrivenpeled/channel_model:v581\") # Variable\n",
    "\n",
    "\n",
    "    entity = \"dylanbackprops-university-of-washington\"\n",
    "    project = \"mldrivenpeled\"\n",
    "    artifact_name = \"channel_model\"\n",
    "    version = channel_model_version\n",
    "\n",
    "    # Construct the full path string\n",
    "    channel_model_artifact_path = f\"{entity}/{project}/{artifact_name}:{version}\"\n",
    "    artifact = api.artifact(channel_model_artifact_path)\n",
    "    artifact_dir = artifact.download()\n",
    "\n",
    "    logging_run = artifact.logged_by() \n",
    "\n",
    "    remote_config = logging_run.config\n",
    "\n",
    "    run_name = logging_run.name\n",
    "    print(\"Channel Run name:\", run_name)\n",
    "\n",
    "    channel_model = TCN_channel(\n",
    "        nlayers=remote_config['nlayers'],\n",
    "        dilation_base=remote_config['dilation_base'],\n",
    "        num_taps=remote_config['num_taps'],\n",
    "        hidden_channels=remote_config['hidden_channels'],\n",
    "        learn_noise=remote_config['learn_noise'],\n",
    "        gaussian=remote_config['gaussian']\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "    channel_model_path = os.path.join(artifact_dir, model_name + \".pth\")\n",
    "    checkpoint = torch.load(channel_model_path)\n",
    "    channel_model.load_state_dict(checkpoint[\"channel_model\"])\n",
    "else:\n",
    "    run_name = \"Trained on MP channel model\"\n",
    "    channel_model = memory_polynomial_channel(weights=None, memory_linear=10, memory_nonlinear=10, nonlinearity_order=2, device=device)\n",
    "    weights, A, residuals = channel_model.fit(sent_frames_time, received_frames_time)\n",
    "    terms, weights = channel_model.show_terms()\n",
    "\n",
    "\n",
    "\n",
    "# Freeze before moving to device\n",
    "for param in channel_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "channel_model = channel_model.to(device).float()\n",
    "channel_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f04a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_polynomial.show_terms(plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a2a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_polynomial.calculate_err(sent_frames_time, received_frames_time, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe4d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average sent power \n",
    "avg_sent_pwer = sent_frames_time.square().mean().item()\n",
    "print(avg_sent_pwer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fb341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Channel model parameters frozen:\",\n",
    "      all(not param.requires_grad for param in channel_model.parameters()))\n",
    "\n",
    "constellation_mode = \"m7_apsk_constellation\"\n",
    "\n",
    "def get_constellation(mode: str):\n",
    "        if mode == \"qpsk\":\n",
    "            constellation = QPSK_Constellation()\n",
    "        elif mode == \"m5_apsk_constellation\":\n",
    "            constellation = RingShapedConstellation(filename=r'C:\\Users\\maild\\mldrivenpeled\\lab_scripts\\saved_constellations\\m5_apsk_constellation.npy')\n",
    "        elif mode == \"m6_apsk_constellation\":\n",
    "             constellation = RingShapedConstellation(filename=r'/Users/dylanjones/Desktop/mldrivenpeled/lab_scripts/saved_constellations/m6_apsk_constellation.npy')\n",
    "        elif mode == \"m7_apsk_constellation\":\n",
    "             constellation = RingShapedConstellation(filename=r'C:\\Users\\maild\\mldrivenpeled\\lab_scripts\\saved_constellations\\m7_apsk_constellation.npy')\n",
    "        return constellation\n",
    "\n",
    "constellation = get_constellation(constellation_mode)\n",
    "\n",
    "script_dir = os.getcwd()\n",
    "config_path = os.path.join(script_dir, \"..\", \"offline_time_ae_config.yml\")\n",
    "with open(config_path, \"r\") as f:\n",
    "    hyperparams = yaml.safe_load(f)\n",
    "\n",
    "    wandb.init(project=\"mldrivenpeled\",\n",
    "            config=hyperparams,\n",
    "            tags=['autoencoder'])\n",
    "    config = wandb.config\n",
    "    if wandb.run.notes is None:\n",
    "        wandb.run.notes = \"\"\n",
    "    config.modulator = constellation_mode\n",
    "    wandb.run.notes += wandb.run.notes + f\"\\n | trained on channel model {run_name} \\n | {constellation_mode}\"\n",
    "    print(\"WandB run info:\")\n",
    "    print(f\"  Name: {wandb.run.name}\")\n",
    "    print(f\"  ID: {wandb.run.id}\")\n",
    "    print(f\"  URL: {wandb.run.url}\")\n",
    "    print(\"Chosen hyperparameters for this session:\")\n",
    "    print(config)\n",
    "\n",
    "encoder = TCN(\n",
    "    nlayers=config.nlayers,\n",
    "    dilation_base=config.dilation_base,\n",
    "    num_taps=config.num_taps,\n",
    "    hidden_channels=config.hidden_channels,\n",
    ").to(device)\n",
    "\n",
    "decoder = TCN(\n",
    "    nlayers=config.nlayers,\n",
    "    dilation_base=config.dilation_base,\n",
    "    num_taps=config.num_taps,\n",
    "    hidden_channels=config.hidden_channels\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=config.lr, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20, min_lr=1e-6)\n",
    "\n",
    "\n",
    "NUM_BITS = config.Nt * config.Nf * constellation.modulation_order\n",
    "FREQUENCIES = torch.arange(float(config.flow), float(config.fhigh), float(config.subcarrier_spacing))\n",
    "delta_f = FREQUENCIES[1] - FREQUENCIES[0]\n",
    "KS = (FREQUENCIES / delta_f).to(torch.int)\n",
    "K_MIN = int(KS[0].item())\n",
    "K_MAX = int(KS[-1].item())\n",
    "NUM_ZEROS = K_MIN - 1\n",
    "UPSAMPLING_ZEROS= (NUM_POINTS_FRAME  +  -2 * K_MIN + -2 * len(KS)) // 2\n",
    "PREAMBLE_MAX = config.preamble_amplitude\n",
    "UPSAMPLING_ZEROS\n",
    "\n",
    "\n",
    "def make_time_validate_plots(enc_in, enc_out, dec_in, dec_out,\n",
    "                             frame_BER, run_model, step=0, zoom_samples=200):\n",
    "\n",
    "    # Convert to numpy\n",
    "    enc_in = enc_in.detach().cpu().numpy().flatten()\n",
    "    enc_out = enc_out.detach().cpu().numpy().flatten()\n",
    "    dec_in = dec_in.detach().cpu().numpy().flatten()\n",
    "    dec_out = dec_out.detach().cpu().numpy().flatten()\n",
    "\n",
    "    # Power and scaling\n",
    "    enc_power_in = np.mean(enc_in**2)\n",
    "    enc_power_out = np.mean(enc_out**2)\n",
    "    enc_scale = enc_power_out / (enc_power_in + 1e-12)\n",
    "\n",
    "    dec_power_in = np.mean(dec_in**2)\n",
    "    dec_power_out = np.mean(dec_out**2)\n",
    "    dec_scale = dec_power_out / (dec_power_in + 1e-12)\n",
    "\n",
    "    # MSEs\n",
    "    mse_encoder = np.mean((enc_in - enc_out) ** 2)\n",
    "    mse_decoder = np.mean((dec_in - dec_out) ** 2)\n",
    "    mse_total = np.mean((enc_in - dec_out) ** 2)\n",
    "\n",
    "    # Log scalars\n",
    "    prefix = \"time_\"\n",
    "    wandb.log({f\"{prefix}mse_loss\": mse_total}, step=step)\n",
    "    wandb.log({f\"{prefix}frame_BER\": frame_BER}, step=step)\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 16))\n",
    "    time_points = np.arange(zoom_samples)\n",
    "\n",
    "    axes[0].plot(time_points, enc_in[:zoom_samples], 'r', alpha=0.5, label='Encoder Input')\n",
    "    axes[0].plot(time_points, enc_out[:zoom_samples], 'b', alpha=0.8, label='Encoder Output')\n",
    "    axes[0].set_title(\n",
    "        f\"Encoder Comparison (MSE: {mse_encoder:.2e}) | \"\n",
    "        f\"In {enc_power_in:.3f} | Out {enc_power_out:.3f} | Scale {enc_scale:.3f}\"\n",
    "    )\n",
    "    axes[0].legend(); axes[0].grid(True)\n",
    "\n",
    "    axes[1].plot(time_points, dec_in[:zoom_samples], 'r', alpha=0.5, label='Decoder Input')\n",
    "    axes[1].plot(time_points, dec_out[:zoom_samples], 'b', alpha=0.8, label='Decoder Output')\n",
    "    axes[1].set_title(\n",
    "        f\"Decoder Comparison (MSE: {mse_decoder:.2e}) | \"\n",
    "        f\"In {dec_power_in:.3f} | Out {dec_power_out:.3f} | Scale {dec_scale:.3f}\"\n",
    "    )\n",
    "    axes[1].legend(); axes[1].grid(True)\n",
    "\n",
    "    axes[2].plot(time_points, enc_in[:zoom_samples], 'r', alpha=0.5, label='Original Input')\n",
    "    axes[2].plot(time_points, dec_out[:zoom_samples], 'b', alpha=0.8, label='Final Output')\n",
    "    axes[2].set_title(\n",
    "        f\"End-to-End Comparison ({'Trained' if run_model else 'Untrained'})\\n\"\n",
    "        f\"MSE: {mse_total:.2e}, BER: {frame_BER:.2f}\"\n",
    "    )\n",
    "    axes[2].legend(); axes[2].grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    wandb.log({f\"{prefix}time_signals\": wandb.Image(fig)}, step=step)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def evm_loss(true_symbols, predicted_symbols):\n",
    "    return torch.mean(torch.abs(true_symbols - predicted_symbols) ** 2)\n",
    "\n",
    "def in_band_filter(x, ks_indices, nfft):\n",
    "    mask = torch.zeros(nfft, device=device)\n",
    "    neg_ks_indices = nfft - ks_indices\n",
    "    mask[ks_indices] = 1.0\n",
    "    mask[neg_ks_indices] = 1.0\n",
    "\n",
    "    impulse_response = torch.fft.ifftshift(torch.fft.ifft(mask).real)\n",
    "    h = impulse_response.view(1, 1, -1)\n",
    "    filtered_x = F.conv1d(x.unsqueeze(1), h, padding='same').squeeze(1)\n",
    "    return filtered_x\n",
    "\n",
    "\n",
    "def in_band_time_loss(sent_time, decoded_time, ks_indices, n_fft, num_taps):\n",
    "    \"\"\"Compute in-band loss directly in time domain using filtering\"\"\"\n",
    "    # Create frequency mask\n",
    "    mask = torch.zeros(n_fft, device=sent_time.device)\n",
    "    neg_ks_indices = n_fft - ks_indices\n",
    "    mask[ks_indices] = 1.0\n",
    "    mask[neg_ks_indices] = 1.0\n",
    "\n",
    "    # Convert to time-domain filter (this is differentiable)\n",
    "    impulse_response = torch.fft.ifftshift(torch.fft.ifft(mask).real)\n",
    "    h = impulse_response.view(1, 1, -1)\n",
    "\n",
    "    # Filter both signals\n",
    "    sent_filtered = F.conv1d(sent_time.unsqueeze(1), h, padding='same').squeeze(1)\n",
    "    decoded_filtered = F.conv1d(decoded_time.unsqueeze(1), h, padding='same').squeeze(1)\n",
    "\n",
    "    # Compute MSE on filtered signals (equivalent to in-band frequency loss)\n",
    "    loss = torch.mean((sent_filtered[:, num_taps:] - decoded_filtered[:, num_taps:]).pow(2))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def symbols_to_time(X, num_padding_zeros: int, num_leading_zeros=0):\n",
    "    # Make hermetian symmetric\n",
    "    Nt, Nf = X.shape\n",
    "    padding_zeros = torch.zeros(Nt, num_padding_zeros, device=device)\n",
    "    leading_zeros = torch.zeros(Nt, num_leading_zeros, device=device)\n",
    "    X = torch.cat([leading_zeros, X.to(device), padding_zeros], dim=-1)\n",
    "    DC_Nyquist = torch.zeros((X.shape[0], 1), device=X.device)\n",
    "    X_hermitian = torch.flip(X, dims=[1]).conj()\n",
    "    X_full = torch.hstack([DC_Nyquist, X, DC_Nyquist, X_hermitian])\n",
    "    # Convert to time domain\n",
    "    x_time = torch.fft.ifft(X_full, dim=-1, norm=\"ortho\").real\n",
    "    return x_time.to(device)\n",
    "\n",
    "\n",
    "def add_noise_time_cp(signal_with_cp, cp_length, snr_in, snr_low, snr_high, inband_idx, print_snr=False):\n",
    "    \"\"\"\n",
    "    Adds spectrally-shaped noise with three regions:\n",
    "      - In-band: indices in inband_idx\n",
    "      - Low out-of-band: below min(inband_idx)\n",
    "      - High out-of-band: above max(inband_idx)\n",
    "    \"\"\"\n",
    "    B, N_with_cp = signal_with_cp.shape\n",
    "    device = signal_with_cp.device\n",
    "\n",
    "    signal_no_cp = signal_with_cp[:, cp_length:]\n",
    "    P_sig = signal_no_cp.pow(2).mean(dim=-1, keepdim=True)\n",
    "\n",
    "    Pn_in_target = P_sig / snr_in\n",
    "    Pn_low_target = P_sig / snr_low\n",
    "    Pn_high_target = P_sig / snr_high\n",
    "\n",
    "    num_pos_freqs = (N_with_cp - 1) // 2\n",
    "    pos_freq_slice = slice(1, num_pos_freqs + 1)\n",
    "    neg_freq_slice = slice(N_with_cp - num_pos_freqs, N_with_cp)\n",
    "\n",
    "    inband_mask = torch.zeros(num_pos_freqs, dtype=bool, device=device)\n",
    "    valid_inband_indices = inband_idx[(inband_idx > 0) & (inband_idx <= num_pos_freqs)]\n",
    "    if valid_inband_indices.numel() > 0:\n",
    "        inband_mask[valid_inband_indices - 1] = True\n",
    "\n",
    "    all_idx = torch.arange(num_pos_freqs, device=device)\n",
    "    low_mask = (all_idx < inband_idx.min()) & ~inband_mask\n",
    "    high_mask = (all_idx > inband_idx.max()) & ~inband_mask\n",
    "\n",
    "    num_in_bins = inband_mask.sum()\n",
    "    num_low_bins = low_mask.sum()\n",
    "    num_high_bins = high_mask.sum()\n",
    "\n",
    "    def make_noise(num_bins, target_power):\n",
    "        if num_bins == 0:\n",
    "            return torch.zeros((B, 0), dtype=torch.complex64, device=device)\n",
    "        var_per_bin = (target_power * N_with_cp) / (2 * num_bins)\n",
    "        std_per_bin = torch.sqrt(var_per_bin)\n",
    "        noise = (torch.randn(B, num_bins, device=device) +\n",
    "                 1j * torch.randn(B, num_bins, device=device)) / math.sqrt(2.0)\n",
    "        return std_per_bin * noise\n",
    "\n",
    "    noise_in_pos = make_noise(num_in_bins, Pn_in_target)\n",
    "    noise_low_pos = make_noise(num_low_bins, Pn_low_target)\n",
    "    noise_high_pos = make_noise(num_high_bins, Pn_high_target)\n",
    "\n",
    "    noise_pos = torch.zeros(B, num_pos_freqs, dtype=torch.complex64, device=device)\n",
    "    if num_in_bins > 0: noise_pos[:, inband_mask] = noise_in_pos\n",
    "    if num_low_bins > 0: noise_pos[:, low_mask] = noise_low_pos\n",
    "    if num_high_bins > 0: noise_pos[:, high_mask] = noise_high_pos\n",
    "\n",
    "    noise_fft = torch.zeros(B, N_with_cp, dtype=torch.complex64, device=device)\n",
    "    noise_fft[:, pos_freq_slice] = noise_pos\n",
    "    noise_fft[:, neg_freq_slice] = torch.conj(torch.flip(noise_pos, dims=[1]))\n",
    "    noise_fft[:, 0] = 0\n",
    "    noise_time = torch.fft.ifft(noise_fft, norm=\"ortho\").real\n",
    "\n",
    "    if print_snr:\n",
    "        P_sig_mean = P_sig.mean().item()\n",
    "        def check(mask, noise_vals, target):\n",
    "            if mask.sum() == 0: return\n",
    "            tmp_fft = torch.zeros_like(noise_fft)\n",
    "            tmp_pos = torch.zeros_like(noise_pos); tmp_pos[:, mask] = noise_vals\n",
    "            tmp_fft[:, pos_freq_slice] = tmp_pos\n",
    "            tmp_fft[:, neg_freq_slice] = torch.conj(torch.flip(tmp_pos, dims=[1]))\n",
    "            Pn_actual = torch.fft.ifft(tmp_fft, norm=\"ortho\").real.pow(2).mean().item()\n",
    "            print(f\"SNR Check: target={target:.2f}, actual={P_sig_mean/Pn_actual:.2f}\")\n",
    "        check(inband_mask, noise_in_pos, snr_in)\n",
    "        check(low_mask, noise_low_pos, snr_low)\n",
    "        check(high_mask, noise_high_pos, snr_high)\n",
    "\n",
    "    return signal_with_cp + noise_time\n",
    "\n",
    "\n",
    "\n",
    "def calculate_BER(received_symbols, true_bits, constellation):\n",
    "    # Demap symbols to bits\n",
    "    constellation_symbols = torch.tensor(\n",
    "        list(constellation._symbols_to_bits_map.keys()),\n",
    "        dtype=received_symbols.dtype,\n",
    "        device=received_symbols.device\n",
    "    )\n",
    "    distances = abs(received_symbols.reshape(-1, 1) - constellation_symbols.reshape(1, -1))\n",
    "\n",
    "    closest_idx = distances.argmin(axis=1)\n",
    "    constellation_symbols_list = list(constellation._symbols_to_bits_map.keys())\n",
    "    decided_bits = [constellation._symbols_to_bits_map[constellation_symbols_list[idx]] for idx in closest_idx.cpu().numpy()]\n",
    "\n",
    "    # Flatten decided bits into a 1D array\n",
    "    decided_bits_flat = [int(bit) for symbol_bits in decided_bits for bit in symbol_bits]\n",
    "\n",
    "\n",
    "    # Convert to NumPy arrays for comparison\n",
    "    true_bits_array = np.array(true_bits)\n",
    "    decided_bits_flat_array = np.array(decided_bits_flat)\n",
    "\n",
    "    # Take minimum length to avoid shape mismatch\n",
    "    min_len = min(len(true_bits_array), len(decided_bits_flat_array))\n",
    "    true_bits_array = true_bits_array[:min_len]\n",
    "    decided_bits_flat_array = decided_bits_flat_array[:min_len]\n",
    "\n",
    "    # Calculate BER\n",
    "    BER = float(np.sum(true_bits_array != decided_bits_flat_array) / len(true_bits_array))\n",
    "    return BER\n",
    "\n",
    "\n",
    "def train(channel_model, encoder, decoder, optimizer, scheduler, config, device, mask=None):\n",
    "\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    average_encoded_power = 0.0\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_freq_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        batch_entries = []\n",
    "        true_bits_list = []\n",
    "        for batch in range(config[\"batch_size\"]):\n",
    "            # Generate frame data\n",
    "            true_bits = np.random.randint(0, 2, size=NUM_BITS)\n",
    "            true_bits_list.append(torch.tensor(true_bits))\n",
    "            true_bits_str = ''.join(map(str, true_bits))\n",
    "            true_symbols = torch.tensor(\n",
    "                constellation.bits_to_symbols(true_bits_str),\n",
    "                dtype=torch.complex64, device=device\n",
    "            )\n",
    "            true_frame = true_symbols.reshape(config[\"Nt\"], config[\"Nf\"])\n",
    "\n",
    "\n",
    "            batch_entries.append(true_frame)\n",
    "\n",
    "        true_bits = torch.stack(true_bits_list)\n",
    "\n",
    "        # Batch along time domain\n",
    "        true_frame = torch.cat(batch_entries)\n",
    "\n",
    "        # print(\"Inband symbol power\", true_frame.abs().square().mean())\n",
    "        # Convert to time domain\n",
    "        sent_frames_time = symbols_to_time(true_frame, UPSAMPLING_ZEROS, NUM_ZEROS)\n",
    "        sent_frames_time = torch.hstack((sent_frames_time[:, -CP_LENGTH:], sent_frames_time))\n",
    "\n",
    "        # print(f\"Encoder Ave Pwr In {sent_frames_time.square().mean().item(): .3f}\")\n",
    "        encoded_frames_time = encoder(sent_frames_time)\n",
    "        average_encoded_power += encoded_frames_time.square().mean().item()\n",
    "\n",
    "        # print(f\"Encoder Ave Pwr Out {encoded_frames_time.square().mean().item(): .3f}\")\n",
    "\n",
    "        # encoded_frames_time = in_band_filter(encoded_frames_time, KS, NUM_POINTS_FRAME)\n",
    "\n",
    "        # Clip to preamble make\n",
    "        encoded_frames_time = torch.clip(encoded_frames_time, -PREAMBLE_MAX, PREAMBLE_MAX)\n",
    "\n",
    "        if TCN_CHANNEL:\n",
    "            received_frames_time, mean, std, nu = channel_model(encoded_frames_time)\n",
    "            if torch.isnan(received_frames_time).any():\n",
    "                raise ValueError(\"NaN in Loss!\")\n",
    "        else:\n",
    "            received_frames_time = channel_model(encoded_frames_time)\n",
    "            mean = received_frames_time\n",
    "            std = 0\n",
    "            nu = 0\n",
    "\n",
    "\n",
    "        # Filter out of band noise\n",
    "        # received_frames_time_noisy = in_band_filter(received_frames_time_noisy, KS, NUM_POINTS_FRAME)\n",
    "\n",
    "        # received_frames_time = add_noise(received_frames_time, SNR=10**(config[\"snr_db\"]/10))\n",
    "        decoded_frames_time = decoder(received_frames_time)\n",
    "\n",
    "        # Convert to frequency domain for loss\n",
    "        sent_frames_frequency = torch.tensor(rfft(sent_frames_time[:, CP_LENGTH:].detach().cpu().numpy(), norm='ortho', axis=1)[:, KS])\n",
    "        decoded_frames_frequency = torch.tensor(rfft(decoded_frames_time[:, CP_LENGTH:].detach().cpu().numpy(), norm='ortho', axis=1)[:, KS])\n",
    "\n",
    "\n",
    "        loss = in_band_time_loss(sent_frames_time, decoded_frames_time, ks_indices=KS, n_fft=NUM_POINTS_FRAME, num_taps=config['num_taps'])\n",
    "\n",
    "        \n",
    "        diff_complex = sent_frames_frequency.detach() - decoded_frames_frequency.detach()\n",
    "        freq_loss = torch.mean(diff_complex.abs().pow(2))\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_freq_loss += freq_loss.item()\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step(epoch_loss)\n",
    "\n",
    "        wandb.log({\"loss\": epoch_loss}, step=epoch)\n",
    "        wandb.log({\"freq_loss\": epoch_freq_loss}, step=epoch)\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        wandb.log({\"learning_rate\": lr}, step=epoch)\n",
    "\n",
    "        # Get BER\n",
    "        ber = calculate_BER(decoded_frames_frequency.detach().flatten(), true_bits.flatten(), constellation=constellation)\n",
    "        wandb.log({\"BER\": ber}, step=epoch)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            make_time_validate_plots(\n",
    "            sent_frames_time[0],\n",
    "            encoded_frames_time[0],\n",
    "            received_frames_time[0],\n",
    "            decoded_frames_time[0],\n",
    "            frame_BER=ber,\n",
    "            run_model=True,\n",
    "            step=epoch\n",
    "            )\n",
    "\n",
    "            # Plot first example of sent and reconstructed time\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(sent_frames_time[0][:100].detach().cpu().numpy(), label=\"Sent (time)\")\n",
    "            ax.plot(decoded_frames_time[0][:100].detach().cpu().numpy(), label=\"Decoded (time)\")\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"Sent vs Decoded (Time Domain) EVM: {loss: 0.3e}\")\n",
    "            wandb.log({\"time_domain_plot\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "            sent_symbols = sent_frames_frequency[0].detach().cpu().numpy()\n",
    "            decoded_symbols = decoded_frames_frequency[0].detach().cpu().numpy()\n",
    "\n",
    "            # Compute EVM for logging (per frame)\n",
    "            evm_val = evm_loss(torch.tensor(sent_symbols), torch.tensor(decoded_symbols)).item()\n",
    "\n",
    "            # Create constellation plot\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.scatter(sent_symbols.real, sent_symbols.imag, color='blue', alpha=0.6, label='Sent')\n",
    "            ax.scatter(decoded_symbols.real, decoded_symbols.imag, color='red', alpha=0.6, label='Decoded')\n",
    "            ax.set_xlabel('In-phase')\n",
    "            ax.set_ylabel('Quadrature')\n",
    "            ax.set_title(f'Constellation Diagram EVM: {evm_val:0.3e}')\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "\n",
    "            # Log to wandb\n",
    "            wandb.log({\"constellation\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "            evm_per_freq = ((sent_frames_frequency[0] - decoded_frames_frequency[0]).abs()**2).detach().cpu().numpy()\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(evm_per_freq)\n",
    "            ax.set_title(\"EVM vs Frequency\")\n",
    "            wandb.log({\"evm_vs_freq\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "\n",
    "            # Plot Model SNRs\n",
    "            sent_k = torch.fft.fft(encoded_frames_time[:, CP_LENGTH:], norm=\"ortho\", dim=-1)\n",
    "            received_k = torch.fft.fft(mean[:, CP_LENGTH:], norm=\"ortho\", dim=-1)\n",
    "\n",
    "            residual = received_frames_time - mean\n",
    "            received_noise_k = torch.fft.fft(residual[:, CP_LENGTH:] ** 2, norm=\"ortho\", dim=-1)\n",
    "\n",
    "\n",
    "            signal_power = torch.mean(torch.abs(sent_k) ** 2, dim=0).detach().cpu().numpy()\n",
    "            received_power = torch.mean(torch.abs(received_k) ** 2, dim=0).detach().cpu().numpy()\n",
    "            received_noise_power = torch.mean(torch.abs(received_noise_k), dim=0).detach().cpu().numpy()\n",
    "            snr_vs_freq = (received_power / received_noise_power + 1e-12)\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(10 * np.log10(signal_power[:len(signal_power)//2]))\n",
    "            ax.axvline(30, c='r', linestyle='--')\n",
    "            ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            ax.set_title(\"Encoded Signal Frequency Power Spectrum\")\n",
    "            ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            ax.set_ylabel(\"Power (dB)\")\n",
    "            wandb.log({\"encoded_signal_power_spectrum\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(10 * np.log10(received_power[:len(received_power)//2]))\n",
    "            ax.axvline(30, c='r', linestyle='--')\n",
    "            ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            ax.set_title(\"Received Signal Frequency Power Spectrum\")\n",
    "            ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            ax.set_ylabel(\"Power (dB)\")\n",
    "            wandb.log({\"received_signal_power_spectrum\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(10 * np.log10(snr_vs_freq[:len(snr_vs_freq)//2]))\n",
    "            ax.set_title(\"SNR vs Freq Estimate\")\n",
    "            ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            ax.set_ylabel(\"SNR (dB)\")\n",
    "            ax.axvline(30, c='r', linestyle='--')\n",
    "            ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            wandb.log({\"snr_vs_freq\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(10 * np.log10(received_noise_power[:len(snr_vs_freq)//2]))\n",
    "            ax.set_title(\"Noise power vs Freq Estimate\")\n",
    "            ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            ax.set_ylabel(\"Power (dB)\")\n",
    "            ax.axvline(30, c='r', linestyle='--')\n",
    "            ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            wandb.log({\"noise_power_vs_freq\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "    average_encoded_power /= config['epochs']\n",
    "\n",
    "\n",
    "    # Save model\n",
    "    torch.save({\n",
    "        \"time_encoder\": encoder.state_dict(),\n",
    "        \"time_decoder\": decoder.state_dict()\n",
    "    }, \"time_autoencoder.pth\")\n",
    "\n",
    "    artifact = wandb.Artifact(\"time_autoencoder\", type=\"model\")\n",
    "    artifact.add_file(\"time_autoencoder.pth\")\n",
    "    wandb.log_artifact(artifact)\n",
    "\n",
    "    return epoch_loss, average_encoded_power\n",
    "\n",
    "_, average_enc_power = train(channel_model, encoder, decoder, optimizer, scheduler, config, device)\n",
    "wandb.finish()\n",
    "print(average_enc_power)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldrivenpeled",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
