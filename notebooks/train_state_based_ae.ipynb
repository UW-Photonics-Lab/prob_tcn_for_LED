{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46ccdd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maild\\miniconda3\\envs\\mldrivenpeled\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from scipy.fft import irfft, rfft\n",
    "import gc\n",
    "import time\n",
    "sys.path.append(os.path.abspath(\"../lab_scripts\"))\n",
    "from constellation_diagram import QPSK_Constellation\n",
    "from constellation_diagram import RingShapedConstellation\n",
    "\n",
    "if wandb.run is not None:\n",
    "    wandb.run.tags = list(wandb.run.tags) + [\"junk\"]\n",
    "wandb.finish()\n",
    "NUM_POINTS_FRAME = 6000\n",
    "# NUM_POINTS_FRAME = 3040\n",
    "CP_LENGTH = 2000\n",
    "# CP_LENGTH = 1013\n",
    "NUM_POINTS_SYMBOL = NUM_POINTS_FRAME + CP_LENGTH\n",
    "POWER_NORMALIZATION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688026f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel Run name: earnest-bee-7750\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "run = api.run(\"dylanbackprops-university-of-washington/mldrivenpeled/1zfa43s4\") # Variable\n",
    "model_name = \"channel_model_final\"\n",
    "artifact = api.artifact(\"dylanbackprops-university-of-washington/mldrivenpeled/channel_model:v1943\") # Variable\n",
    "artifact_dir = artifact.download()\n",
    "remote_config = run.config\n",
    "run_name = run.name\n",
    "print(\"Channel Run name:\", run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac2c30fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nf': 1499,\n",
       " 'Nt': 1,\n",
       " 'lr': 0.001,\n",
       " 'wd': 0.001,\n",
       " 'flow': 300000,\n",
       " 'gain': 20,\n",
       " 'fhigh': '15e6',\n",
       " 'ar_taps': 0,\n",
       " 'fnyquist': '30e6',\n",
       " 'num_taps': 10,\n",
       " 'dc_offset': 3.5,\n",
       " 'batch_size': 32,\n",
       " 'state_size': 8,\n",
       " 'grid_run_id': 'grid_20251202_103823',\n",
       " 'hidden_size': 8,\n",
       " 'linear_fast': False,\n",
       " 'weight_init': 'default',\n",
       " 'dilation_base': 2,\n",
       " 'scheduler_type': 'reduce_lr_on_plateu',\n",
       " 'detach_residuals': False,\n",
       " 'training_schedule': [{'mode': 'normal', 'epochs': 10}],\n",
       " 'subcarrier_spacing': '1e4'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7eea4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of artifact_dir: ['channel_model_final.pth']\n"
     ]
    }
   ],
   "source": [
    "print(\"Contents of artifact_dir:\", os.listdir(artifact_dir))\n",
    "# Set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\") # for M chip Macs\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8add790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_last_layer(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.zeros_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "class StateSpaceModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 deterministic_num_taps,\n",
    "                 deterministic_state_size,\n",
    "                 deterministic_hidden_size,\n",
    "                 stochastic_state_size,\n",
    "                 stochastic_hidden_size\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.deterministic_state_size = deterministic_state_size\n",
    "        self.stochastic_state_size = stochastic_state_size\n",
    "        self.deterministic_num_taps = deterministic_num_taps\n",
    "        self.deterministic_state_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(deterministic_hidden_size, deterministic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(deterministic_hidden_size, deterministic_state_size)\n",
    "        )\n",
    "        self.deterministic_out_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(deterministic_hidden_size, 1) # Predict next scalar ouptut\n",
    "        )\n",
    "        self.stochastic_state_map = nn.Sequential(\n",
    "            nn.Linear(stochastic_state_size + deterministic_num_taps + 1, stochastic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(stochastic_hidden_size, stochastic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(stochastic_hidden_size, stochastic_state_size)\n",
    "        )\n",
    "        self.stochastic_out_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + stochastic_state_size + deterministic_state_size, stochastic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(stochastic_hidden_size, 1)\n",
    "        )\n",
    "        self.linear_det_out_map = nn.Linear(deterministic_num_taps + deterministic_state_size, 1)\n",
    "        self.linear_det_state_map = nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_state_size)\n",
    "        self.linear_stoch_state_map = nn.Linear(stochastic_state_size + deterministic_num_taps + 1, stochastic_state_size)\n",
    "        self.linear_stoch_out_map = nn.Linear(deterministic_num_taps + stochastic_state_size + deterministic_state_size, 1)\n",
    "\n",
    "        self.n0 = nn.Parameter(torch.zeros(deterministic_state_size))\n",
    "        self.z0 = nn.Parameter(torch.zeros(stochastic_state_size))\n",
    "\n",
    "        # Make it so that the stochastic output starts at zero\n",
    "        self.deterministic_state_map[-1].apply(zero_last_layer)\n",
    "        self.deterministic_out_map[-1].apply(zero_last_layer)\n",
    "        self.stochastic_state_map[-1].apply(zero_last_layer)\n",
    "        self.stochastic_out_map[-1].apply(zero_last_layer)\n",
    "        self.mode = \"nonlinear\"\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        mode = self.mode\n",
    "        device = x.device\n",
    "        y_pred = torch.zeros_like(x, device=device)\n",
    "        e_pred = torch.zeros_like(x, device=device)\n",
    "        T = x.size(-1)\n",
    "        B = x.size(0)\n",
    "        # n_t = torch.zeros(B, self.deterministic_state_size, device=device)\n",
    "        # z_t = torch.zeros(B, self.stochastic_state_size, device=device)\n",
    "        n_t = self.n0.unsqueeze(0).expand(B, -1)  # [B, nx]\n",
    "        z_t = self.z0.unsqueeze(0).expand(B, -1)  # [B, nz]\n",
    "        # add zeros in front equal to num_taps - 1\n",
    "        x = torch.cat([torch.zeros(B, self.deterministic_num_taps - 1, device=device), x], dim=-1)\n",
    "        for t in range(T):\n",
    "            x_t = x[:, t: t + self.deterministic_num_taps]\n",
    "\n",
    "            if mode == \"linear\":\n",
    "                y_t_pred = self.linear_det_out_map(torch.cat([x_t, n_t], dim=-1))\n",
    "            else:\n",
    "                y_t_pred = self.deterministic_out_map(torch.cat([x_t, n_t], dim=-1)) + self.linear_det_out_map(torch.cat([x_t, n_t], dim=-1))\n",
    "\n",
    "            if y is None:\n",
    "                '''INFERENCE MODE'''\n",
    "                y_pred[:, t] = y_t_pred.squeeze(-1)\n",
    "                # Assume residuals are an innovation process with zero mean\n",
    "                if mode == \"linear\":\n",
    "                    n_t = n_t + self.linear_det_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "                else:\n",
    "                    n_t = n_t + self.deterministic_state_map(torch.cat([x_t, n_t], dim=-1)) + self.linear_det_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "\n",
    "            else:\n",
    "                '''TRAINING MODE'''\n",
    "                # Training mode\n",
    "                y_t = y[:, t]\n",
    "                r_t = y_t.unsqueeze(-1) - y_t_pred\n",
    "\n",
    "                if mode == \"linear\":\n",
    "                    nonlinear_noise_t = self.linear_stoch_out_map(torch.cat([x_t, n_t, z_t], dim=-1))\n",
    "                else:\n",
    "                    nonlinear_noise_t = self.stochastic_out_map(torch.cat([x_t, n_t, z_t], dim=-1)) + self.linear_stoch_out_map(torch.cat([x_t, n_t, z_t], dim=-1))\n",
    "                y_t_next_pred = y_t_pred + nonlinear_noise_t\n",
    "                y_pred[:, t] = y_t_next_pred.squeeze(-1)\n",
    "                e_t = r_t - nonlinear_noise_t\n",
    "                e_pred[:, t] = e_t.squeeze(-1)\n",
    "                # Make state updates\n",
    "\n",
    "                if mode == \"linear\":\n",
    "                    z_t = z_t + self.linear_stoch_state_map(torch.cat([x_t, z_t, r_t], dim=-1))\n",
    "                    n_t = n_t + self.linear_det_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "                else:\n",
    "                    z_t = z_t + self.stochastic_state_map(torch.cat([x_t, z_t, r_t], dim=-1)) + self.linear_stoch_state_map(torch.cat([x_t, z_t, r_t], dim=-1))\n",
    "                    n_t = n_t + self.deterministic_state_map(torch.cat([x_t, n_t], dim=-1)) + self.linear_det_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "        return y_pred, e_pred\n",
    "\n",
    "\n",
    "class TCNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation=dilation,\n",
    "            padding=0\n",
    "        )\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        self.SiLU = nn.SiLU()\n",
    "        self.resample = None\n",
    "        if in_channels != out_channels:\n",
    "            self.resample = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.pad(x, (self.padding, 0))\n",
    "        out = self.conv(out)\n",
    "        out = self.SiLU(out)\n",
    "        if out.size(2) > x.size(2):\n",
    "            out = out[:, :, :x.size(2)]\n",
    "        if self.resample:\n",
    "            x = self.resample(x)\n",
    "        return out + x  # residual connection\n",
    "\n",
    "\n",
    "def sample_student_t_mps(mean, std, nu):\n",
    "    '''\n",
    "    Wilson-Hilferty Approximation for chi^2 converted to scaled and shifted student t\n",
    "    '''\n",
    "    z = torch.randn_like(mean)\n",
    "    z_chi = torch.randn_like(mean)\n",
    "    chi2_approx = nu * (1 - 2/(9*nu) + z_chi * torch.sqrt(2/(9*nu))).pow(3)\n",
    "    chi2_approx = chi2_approx.clamp(min=0.01)\n",
    "    scale = torch.sqrt(nu / chi2_approx)\n",
    "    return mean + std * z * scale\n",
    "\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, nlayers=3, dilation_base=2, num_taps=10, hidden_channels=32):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "        for i in range(nlayers):\n",
    "            dilation = dilation_base ** i\n",
    "            layers.append(\n",
    "                TCNBlock(in_channels, hidden_channels, num_taps, dilation)\n",
    "            )\n",
    "            in_channels = hidden_channels\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.readout = nn.Conv1d(hidden_channels, 1, kernel_size=1)\n",
    "\n",
    "        # Calculate the total receptive field for the whole TCN stack\n",
    "        self.receptive_field = 1\n",
    "        for i in range(nlayers):\n",
    "            dilation = dilation_base ** i\n",
    "            self.receptive_field += (num_taps - 1) * dilation\n",
    "\n",
    "    def forward(self, xin):\n",
    "        x = xin.unsqueeze(1)    # [B,1,T]\n",
    "        out = self.tcn(x)     # [B,H,T]\n",
    "        out = self.readout(out).squeeze(1)\n",
    "        out = out - out.mean(dim=1, keepdim=True)  # [B,T]\n",
    "        return out\n",
    "\n",
    "\n",
    "class TCN_channel(nn.Module):\n",
    "    def __init__(self, nlayers=3, dilation_base=2, num_taps=10, hidden_channels=32, learn_noise=False, gaussian=True):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "        for i in range(nlayers):\n",
    "            dilation = dilation_base ** i\n",
    "            layers.append(\n",
    "                TCNBlock(in_channels, hidden_channels, num_taps, dilation)\n",
    "            )\n",
    "            in_channels = hidden_channels\n",
    "        self.learn_noise = learn_noise\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        if gaussian:\n",
    "            self.readout = nn.Conv1d(hidden_channels, 2, kernel_size=1) # 2 channels mean | std\n",
    "        else:\n",
    "            self.readout = nn.Conv1d(hidden_channels, 3, kernel_size=1) # 3 channels mean | std | nu\n",
    "        self.num_taps = num_taps\n",
    "        self.gaussian = gaussian\n",
    "\n",
    "        if not gaussian:\n",
    "            with torch.no_grad():\n",
    "                # Initialize log_nu bias\n",
    "                self.readout.bias[2].fill_(48)\n",
    "\n",
    "    def forward(self, xin):\n",
    "        x = xin.unsqueeze(1)    # [B,1,T]\n",
    "        out = self.tcn(x)     # [B,H,T]\n",
    "        out = self.readout(out) # [B, 3, T] mean | std | nu\n",
    "        mean_out = out[:, 0, :]\n",
    "        log_std_out = out[:, 1, :]\n",
    "        std_out = torch.exp(log_std_out)\n",
    "        if not self.gaussian:\n",
    "            log_nu_out = out[:, 2, :]\n",
    "            nu_out = torch.nn.functional.softplus(log_nu_out)\n",
    "            nu_out = torch.clamp(nu_out, 2, 50) # nu between 2 and 50\n",
    "        mean_out = mean_out - mean_out.mean(dim=1, keepdim=True)  # [B ,T]\n",
    "\n",
    "        # # Produce noisy output\n",
    "        if self.gaussian:\n",
    "            z = torch.randn_like(mean_out)\n",
    "            noisy_out = mean_out + std_out * z\n",
    "            nu_out = torch.zeros_like(mean_out)\n",
    "        else:\n",
    "            noisy_out = sample_student_t_mps(mean_out, std_out, nu_out)\n",
    "        if self.learn_noise:\n",
    "            return noisy_out, mean_out, std_out, nu_out\n",
    "        else:\n",
    "            return mean_out, mean_out, torch.zeros_like(mean_out)\n",
    "\n",
    "class ProbabilisticStateSpaceModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_taps,\n",
    "                 state_size,\n",
    "                 hidden_size,\n",
    "                 ar_taps,\n",
    "                 detach_residuals=True,\n",
    "                 linear_fast=True\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.state_size = state_size\n",
    "        self.num_taps = num_taps\n",
    "        self.linear_fast = linear_fast\n",
    "        self.detach_residuals = detach_residuals\n",
    "        self.state_map = nn.Sequential(\n",
    "            nn.Linear(num_taps + state_size, hidden_size),\n",
    "            # nn.SiLU(),\n",
    "            # nn.Linear(hidden_size, hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, state_size)\n",
    "        )\n",
    "        self.state_out_map = nn.Sequential(\n",
    "            nn.Linear(num_taps + state_size, hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, 2 + ar_taps) # Predict mean and std\n",
    "        )\n",
    "        if linear_fast:\n",
    "            self.fast_feedthrough = nn.Linear(num_taps, 1, bias=False)\n",
    "        else:\n",
    "            self.fast_feedthrough = nn.Sequential(\n",
    "                nn.Linear(num_taps, hidden_size, bias=False),\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(hidden_size, 1, bias=False)\n",
    "            )\n",
    "        # nn.init.zeros_(self.fast_feedthrough.weight)\n",
    "        # nn.init.zeros_(self.fast_feedthrough.weight)\n",
    "        self.n0 = nn.Parameter(torch.zeros(state_size))\n",
    "        # self.alpha = nn.Parameter(torch.tensor(0.5))\n",
    "        self.alpha = nn.Parameter(torch.tensor(3 * torch.randn(state_size)))\n",
    "        # self.state_map[-1].apply(zero_last_layer)\n",
    "        # self.state_out_map[-1].apply(zero_last_layer)\n",
    "        self.ar_coeffs = nn.Parameter(torch.zeros(ar_taps))\n",
    "        self.ar_taps = ar_taps\n",
    "\n",
    "    def _whiten(self, x, ar_preds):\n",
    "        out = torch.zeros_like(x)\n",
    "        for t in range(x.size(-1)):\n",
    "            x_whitened_t = x[:, t]\n",
    "            for i in range(self.ar_taps):\n",
    "                j = t - (i + 1)\n",
    "                if j >= 0: # Enforce boundary\n",
    "                #   x_whitened_t = x_whitened_t - nn.Tanh(ar_preds[i]) * x[:, j]\n",
    "                    if self.detach_residuals:\n",
    "                        x_whitened_t = x_whitened_t - ar_preds[:, t, i] * x[:, j].detach()\n",
    "                    else:\n",
    "                        x_whitened_t = x_whitened_t - ar_preds[:, t, i] * x[:, j] # Remove the possibility of cheating by spiking previous errors\n",
    "            out[:, t] = x_whitened_t\n",
    "        return out\n",
    "\n",
    "    def _step(self, xt, nt):\n",
    "        inp = torch.cat([xt, nt], dim=-1)\n",
    "        out = self.state_out_map(inp)\n",
    "        y_pred = out[:, 0]\n",
    "        y_fast = self.fast_feedthrough(xt).squeeze(-1)\n",
    "        # y_fast_sq = self.fast_square(xt ** 2).squeeze(-1)\n",
    "        y_pred = y_pred + y_fast\n",
    "        std_pred = F.softplus(out[:, 1]) + 1e-4\n",
    "        ar_preds = F.tanh(out[:, 2:])\n",
    "        delta_n = self.state_map(inp)\n",
    "        alpha = torch.sigmoid(self.alpha)\n",
    "        nt_next = (1.0 - alpha) * nt + delta_n\n",
    "        return y_pred, std_pred, ar_preds, nt_next\n",
    "\n",
    "    def forward_train(self, x, y):\n",
    "        device = x.device\n",
    "        T = x.size(-1)\n",
    "        B = x.size(0)\n",
    "        y_pred = torch.zeros(B, T, device=device)\n",
    "        std_pred = torch.zeros(B, T, device=device)\n",
    "        residuals = torch.zeros(B, T, device=device)\n",
    "        ar_preds = torch.zeros(B, T, self.ar_taps, device=device)\n",
    "        nt = self.n0.unsqueeze(0).repeat(B, 1).clone()  # [B, nx]\n",
    "        # add zeros in front equal to num_taps - 1\n",
    "        x = torch.cat([torch.zeros(B, self.num_taps - 1, device=device), x], dim=-1)\n",
    "\n",
    "        for t in range(T):\n",
    "            xt = x[:, t: t + self.num_taps]\n",
    "            y_pred_t, std_pred_t, ar_preds_t, nt = self._step(xt, nt)\n",
    "            y_pred[:, t] = y_pred_t\n",
    "\n",
    "            # get residuals\n",
    "            r_t = (y[:, t] - y_pred_t)\n",
    "            residuals[:, t] = r_t #\n",
    "            std_pred[:, t] = std_pred_t\n",
    "            ar_preds[:, t, :] = ar_preds_t\n",
    "\n",
    "        # whiten the innovations\n",
    "        innovations = self._whiten(residuals, ar_preds)\n",
    "        return y_pred, std_pred, innovations\n",
    "\n",
    "\n",
    "    def forward_simulate(self, x, eps=None):\n",
    "        device = x.device\n",
    "        T = x.size(-1)\n",
    "        B = x.size(0)\n",
    "        y_pred = torch.zeros(B, T, device=device)\n",
    "        if eps is None:\n",
    "            eps = torch.randn(B, T, device=device)\n",
    "        residuals = []\n",
    "        x = torch.cat([torch.zeros(B, self.num_taps - 1, device=device), x], dim=-1)\n",
    "        n_t = self.n0.unsqueeze(0).repeat(B, 1).clone()\n",
    "        for t in range(T):\n",
    "            max_lag = min(self.ar_taps, t)\n",
    "            xt = x[:, t: t + self.num_taps]\n",
    "            y_pred_t, std_pred_t, ar_preds, n_t = self._step(xt, n_t)\n",
    "            if max_lag > 0:\n",
    "                past_resids = torch.stack(residuals[-max_lag:], dim=0) # [max_lag, B]\n",
    "                past_resids = past_resids.transpose(0, 1) # [B, max_lag]\n",
    "                past_resids = past_resids.flip(dims=[1]) # Flip so that first residual is closest in time\n",
    "                ar_component = torch.sum(ar_preds[:, :max_lag] * past_resids, dim=1) # [B, max_lag] * [B, max_lag]\n",
    "            else:\n",
    "                ar_component = torch.zeros(B, device=device)\n",
    "\n",
    "            r_t = ar_component + std_pred_t * eps[:, t]\n",
    "            residuals.append(r_t)\n",
    "            y_pred[:, t] = y_pred_t + r_t\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be83bd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel model parameters frozen: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maild\\AppData\\Local\\Temp\\ipykernel_14764\\624795791.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.alpha = nn.Parameter(torch.tensor(3 * torch.randn(state_size)))\n",
      "C:\\Users\\maild\\AppData\\Local\\Temp\\ipykernel_14764\\1104233139.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(channel_model_path)\n"
     ]
    }
   ],
   "source": [
    "# channel_model = StateSpaceModel(\n",
    "#     deterministic_num_taps=remote_config['deterministic_num_taps'],\n",
    "#     deterministic_state_size=remote_config['deterministic_state_size'],\n",
    "#     deterministic_hidden_size=remote_config['deterministic_hidden_size'],\n",
    "#     stochastic_state_size=remote_config['stochastic_state_size'],\n",
    "#     stochastic_hidden_size=remote_config['stochastic_hidden_size']\n",
    "# )\n",
    "\n",
    "channel_model = ProbabilisticStateSpaceModel(\n",
    "    num_taps = remote_config[\"num_taps\"],\n",
    "    state_size = remote_config[\"state_size\"],\n",
    "    hidden_size = remote_config[\"hidden_size\"],\n",
    "    ar_taps = remote_config[\"ar_taps\"],\n",
    "    detach_residuals = remote_config[\"detach_residuals\"],\n",
    "    linear_fast = remote_config[\"linear_fast\"]\n",
    ")\n",
    "\n",
    "channel_model_path = os.path.join(artifact_dir, model_name + \".pth\")\n",
    "checkpoint = torch.load(channel_model_path)\n",
    "channel_model.load_state_dict(checkpoint[\"channel_model\"])\n",
    "\n",
    "# Freeze before moving to device\n",
    "for param in channel_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "channel_model = channel_model.to(device).float()\n",
    "channel_model.eval()\n",
    "\n",
    "print(\"Channel model parameters frozen:\",\n",
    "      all(not param.requires_grad for param in channel_model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bca40a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "constellation_mode = \"m7_apsk_constellation\"\n",
    "\n",
    "def get_constellation(mode: str):\n",
    "        if mode == \"qpsk\":\n",
    "            constellation = QPSK_Constellation()\n",
    "        elif mode == \"m5_apsk_constellation\":\n",
    "            constellation = RingShapedConstellation(filename=r'/Users/dylanjones/Desktop/mldrivenpeled/lab_scripts/saved_constellations/m5_apsk_constellation.npy')\n",
    "        elif mode == \"m6_apsk_constellation\":\n",
    "             constellation = RingShapedConstellation(filename=r'/Users/dylanjones/Desktop/mldrivenpeled/lab_scripts/saved_constellations/m6_apsk_constellation.npy')\n",
    "        elif mode == \"m7_apsk_constellation\":\n",
    "             # /Users/dylanjones/Desktop/mldrivenpeled/lab_scripts/saved_constellations/m7_apsk_constellation.npy\n",
    "             # C:\\Users\\maild\\mldrivenpeled\\lab_scripts\\saved_constellations\\m7_apsk_constellation.npy\n",
    "             constellation = RingShapedConstellation(filename=r'C:\\Users\\maild\\mldrivenpeled\\lab_scripts\\saved_constellations\\m7_apsk_constellation.npy')\n",
    "        return constellation\n",
    "\n",
    "constellation = get_constellation(constellation_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "727b880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdylanbackprops\u001b[0m (\u001b[33mdylanbackprops-university-of-washington\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\maild\\mldrivenpeled\\notebooks\\wandb\\run-20251202_104442-grppk2fb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/grppk2fb' target=\"_blank\">sleek-bee-7752</a></strong> to <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/grppk2fb' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/grppk2fb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run info:\n",
      "  Name: sleek-bee-7752\n",
      "  ID: grppk2fb\n",
      "  URL: https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/grppk2fb\n",
      "Chosen hyperparameters for this session:\n",
      "{'CP_ratio': 0.25, 'batch_size': 16, 'dc_offset': 0, 'num_taps': 10, 'epochs': 300, 'gain': 20, 'lr': 0.001, 'nlayers': 2, 'hidden_channels': 16, 'dilation_base': 2, 'preamble_amplitude': 3, 'num_symbols_per_frame': 1, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'Nf': 370, 'Nt': 1, 'flow': 300000, 'fhigh': '4e6', 'subcarrier_spacing': '1e4', 'modulator': 'm7_apsk_constellation'}\n"
     ]
    }
   ],
   "source": [
    "script_dir = os.getcwd()\n",
    "config_path = os.path.join(script_dir, \"..\", \"offline_time_ae_config.yml\")\n",
    "with open(config_path, \"r\") as f:\n",
    "    hyperparams = yaml.safe_load(f)\n",
    "\n",
    "    wandb.init(project=\"mldrivenpeled\",\n",
    "            config=hyperparams,\n",
    "            tags=['autoencoder'])\n",
    "    config = wandb.config\n",
    "    if wandb.run.notes is None:\n",
    "        wandb.run.notes = \"\"\n",
    "    config.modulator = constellation_mode\n",
    "    wandb.run.notes += wandb.run.notes + f\"\\n | trained on channel model {run_name} \\n | {constellation_mode}\"\n",
    "    print(f\"WandB run info:\")\n",
    "    print(f\"  Name: {wandb.run.name}\")\n",
    "    print(f\"  ID: {wandb.run.id}\")\n",
    "    print(f\"  URL: {wandb.run.url}\")\n",
    "    print(\"Chosen hyperparameters for this session:\")\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f73f372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TCN(\n",
    "    nlayers=config.nlayers,\n",
    "    dilation_base=config.dilation_base,\n",
    "    num_taps=config.num_taps,\n",
    "    hidden_channels=config.hidden_channels,\n",
    ").to(device)\n",
    "\n",
    "decoder = TCN(\n",
    "    nlayers=config.nlayers,\n",
    "    dilation_base=config.dilation_base,\n",
    "    num_taps=config.num_taps,\n",
    "    hidden_channels=config.hidden_channels\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f581d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=config.lr, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec7549ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2600"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_BITS = config.Nt * config.Nf * constellation.modulation_order\n",
    "FREQUENCIES = torch.arange(float(config.flow), float(config.fhigh), float(config.subcarrier_spacing))\n",
    "delta_f = FREQUENCIES[1] - FREQUENCIES[0]\n",
    "KS = (FREQUENCIES / delta_f).to(torch.int)\n",
    "K_MIN = int(KS[0].item())\n",
    "K_MAX = int(KS[-1].item())\n",
    "NUM_ZEROS = K_MIN - 1\n",
    "UPSAMPLING_ZEROS= (NUM_POINTS_FRAME  +  -2 * K_MIN + -2 * len(KS)) // 2\n",
    "PREAMBLE_MAX = config.preamble_amplitude\n",
    "UPSAMPLING_ZEROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db9546e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2590"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_BITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "435f914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_time_validate_plots(sent_frames_time, received_frames_time, decoded_frames_time,\n",
    "                             frame_BER, run_model, step=0, zoom_samples=200):\n",
    "\n",
    "    # Convert to numpy\n",
    "    enc_in = sent_frames_time.detach().cpu().numpy().flatten()\n",
    "    enc_out = received_frames_time.detach().cpu().numpy().flatten()\n",
    "    dec_in = received_frames_time.detach().cpu().numpy().flatten()\n",
    "    dec_out = decoded_frames_time.detach().cpu().numpy().flatten()\n",
    "\n",
    "    # Power and scaling\n",
    "    enc_power_in = np.mean(enc_in**2)\n",
    "    enc_power_out = np.mean(enc_out**2)\n",
    "    enc_scale = enc_power_out / (enc_power_in + 1e-12)\n",
    "\n",
    "    dec_power_in = np.mean(dec_in**2)\n",
    "    dec_power_out = np.mean(dec_out**2)\n",
    "    dec_scale = dec_power_out / (dec_power_in + 1e-12)\n",
    "\n",
    "    # MSEs\n",
    "    mse_encoder = np.mean((enc_in - enc_out) ** 2)\n",
    "    mse_decoder = np.mean((dec_in - dec_out) ** 2)\n",
    "    mse_total = np.mean((enc_in - dec_out) ** 2)\n",
    "\n",
    "    # Log scalars\n",
    "    prefix = \"time_\"\n",
    "    wandb.log({f\"{prefix}mse_loss\": mse_total}, step=step)\n",
    "    wandb.log({f\"{prefix}frame_BER\": frame_BER}, step=step)\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 16))\n",
    "    time_points = np.arange(zoom_samples)\n",
    "\n",
    "    axes[0].plot(time_points, enc_in[:zoom_samples], 'r', alpha=0.5, label='Encoder Input')\n",
    "    axes[0].plot(time_points, enc_out[:zoom_samples], 'b', alpha=0.8, label='Encoder Output')\n",
    "    axes[0].set_title(\n",
    "        f\"Encoder Comparison (MSE: {mse_encoder:.2e}) | \"\n",
    "        f\"In {enc_power_in:.3f} | Out {enc_power_out:.3f} | Scale {enc_scale:.3f}\"\n",
    "    )\n",
    "    axes[0].legend(); axes[0].grid(True)\n",
    "\n",
    "    axes[1].plot(time_points, dec_in[:zoom_samples], 'r', alpha=0.5, label='Decoder Input')\n",
    "    axes[1].plot(time_points, dec_out[:zoom_samples], 'b', alpha=0.8, label='Decoder Output')\n",
    "    axes[1].set_title(\n",
    "        f\"Decoder Comparison (MSE: {mse_decoder:.2e}) | \"\n",
    "        f\"In {dec_power_in:.3f} | Out {dec_power_out:.3f} | Scale {dec_scale:.3f}\"\n",
    "    )\n",
    "    axes[1].legend(); axes[1].grid(True)\n",
    "\n",
    "    axes[2].plot(time_points, enc_in[:zoom_samples], 'r', alpha=0.5, label='Original Input')\n",
    "    axes[2].plot(time_points, dec_out[:zoom_samples], 'b', alpha=0.8, label='Final Output')\n",
    "    axes[2].set_title(\n",
    "        f\"End-to-End Comparison ({'Trained' if run_model else 'Untrained'})\\n\"\n",
    "        f\"MSE: {mse_total:.2e}, BER: {frame_BER:.2f}\"\n",
    "    )\n",
    "    axes[2].legend(); axes[2].grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    wandb.log({f\"{prefix}time_signals\": wandb.Image(fig)}, step=step)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c91e8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CP_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c0f48d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
       "         44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,\n",
       "         58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
       "         72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,\n",
       "         86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
       "        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
       "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
       "        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
       "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
       "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
       "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
       "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
       "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
       "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
       "        254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,\n",
       "        268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,\n",
       "        282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,\n",
       "        296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n",
       "        310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,\n",
       "        324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
       "        352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,\n",
       "        366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,\n",
       "        380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
       "        394, 395, 396, 397, 398, 399], dtype=torch.int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c109ac27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maild\\AppData\\Local\\Temp\\ipykernel_14764\\2405448157.py:29: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\Convolution.cpp:1037.)\n",
      "  sent_filtered = F.conv1d(sent_time.unsqueeze(1), h, padding='same').squeeze(1)\n",
      "C:\\Users\\maild\\AppData\\Local\\Temp\\ipykernel_14764\\2405448157.py:160: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  true_bits_array = np.array(true_bits)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Finished | Avg Loss: 0.12044768035411835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maild\\AppData\\Local\\Temp\\ipykernel_14764\\2405448157.py:160: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  true_bits_array = np.array(true_bits)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Finished | Avg Loss: 0.11955181509256363\n",
      "Epoch 2 Finished | Avg Loss: 0.1183292493224144\n",
      "Epoch 3 Finished | Avg Loss: 0.11794055998325348\n",
      "Epoch 4 Finished | Avg Loss: 0.11445077508687973\n",
      "Epoch 5 Finished | Avg Loss: 0.11368311941623688\n",
      "Epoch 6 Finished | Avg Loss: 0.11236777901649475\n",
      "Epoch 7 Finished | Avg Loss: 0.10975070297718048\n",
      "Epoch 8 Finished | Avg Loss: 0.1090206578373909\n",
      "Epoch 9 Finished | Avg Loss: 0.10685618966817856\n",
      "Epoch 10 Finished | Avg Loss: 0.10436522960662842\n",
      "Epoch 11 Finished | Avg Loss: 0.10026341676712036\n",
      "Epoch 12 Finished | Avg Loss: 0.09785860031843185\n",
      "Epoch 13 Finished | Avg Loss: 0.09673261642456055\n",
      "Epoch 14 Finished | Avg Loss: 0.09390603005886078\n",
      "Epoch 15 Finished | Avg Loss: 0.08937866985797882\n",
      "Epoch 16 Finished | Avg Loss: 0.0863528922200203\n",
      "Epoch 17 Finished | Avg Loss: 0.08346813172101974\n",
      "Epoch 18 Finished | Avg Loss: 0.07959093898534775\n",
      "Epoch 19 Finished | Avg Loss: 0.07460330426692963\n",
      "Epoch 20 Finished | Avg Loss: 0.07132095098495483\n",
      "Epoch 21 Finished | Avg Loss: 0.06795806437730789\n",
      "Epoch 22 Finished | Avg Loss: 0.06376460939645767\n",
      "Epoch 23 Finished | Avg Loss: 0.05970225855708122\n",
      "Epoch 24 Finished | Avg Loss: 0.05668886378407478\n",
      "Epoch 25 Finished | Avg Loss: 0.05302081257104874\n",
      "Epoch 26 Finished | Avg Loss: 0.04902076721191406\n",
      "Epoch 27 Finished | Avg Loss: 0.045141834765672684\n",
      "Epoch 28 Finished | Avg Loss: 0.0416732020676136\n",
      "Epoch 29 Finished | Avg Loss: 0.03895598277449608\n",
      "Epoch 30 Finished | Avg Loss: 0.034927867352962494\n",
      "Epoch 31 Finished | Avg Loss: 0.03206309303641319\n",
      "Epoch 32 Finished | Avg Loss: 0.029217593371868134\n",
      "Epoch 33 Finished | Avg Loss: 0.02587711438536644\n",
      "Epoch 34 Finished | Avg Loss: 0.02307162992656231\n",
      "Epoch 35 Finished | Avg Loss: 0.02110935188829899\n",
      "Epoch 36 Finished | Avg Loss: 0.01925758831202984\n",
      "Epoch 37 Finished | Avg Loss: 0.017165396362543106\n",
      "Epoch 38 Finished | Avg Loss: 0.015649795532226562\n",
      "Epoch 39 Finished | Avg Loss: 0.014315147884190083\n",
      "Epoch 40 Finished | Avg Loss: 0.013191711157560349\n",
      "Epoch 41 Finished | Avg Loss: 0.012023771181702614\n",
      "Epoch 42 Finished | Avg Loss: 0.011253662407398224\n",
      "Epoch 43 Finished | Avg Loss: 0.010813923552632332\n",
      "Epoch 44 Finished | Avg Loss: 0.010363195091485977\n",
      "Epoch 45 Finished | Avg Loss: 0.009888522326946259\n",
      "Epoch 46 Finished | Avg Loss: 0.009521536529064178\n",
      "Epoch 47 Finished | Avg Loss: 0.008513406850397587\n",
      "Epoch 48 Finished | Avg Loss: 0.00802907720208168\n",
      "Epoch 49 Finished | Avg Loss: 0.007500527426600456\n",
      "Epoch 50 Finished | Avg Loss: 0.0066768755204975605\n",
      "Epoch 51 Finished | Avg Loss: 0.00593572435900569\n",
      "Epoch 52 Finished | Avg Loss: 0.005426978226751089\n",
      "Epoch 53 Finished | Avg Loss: 0.0048086270689964294\n",
      "Epoch 54 Finished | Avg Loss: 0.004519787151366472\n",
      "Epoch 55 Finished | Avg Loss: 0.004015485290437937\n",
      "Epoch 56 Finished | Avg Loss: 0.0037150888238102198\n",
      "Epoch 57 Finished | Avg Loss: 0.003599919844418764\n",
      "Epoch 58 Finished | Avg Loss: 0.0034540921915322542\n",
      "Epoch 59 Finished | Avg Loss: 0.0034488271921873093\n",
      "Epoch 60 Finished | Avg Loss: 0.0032404251396656036\n",
      "Epoch 61 Finished | Avg Loss: 0.0033091495279222727\n",
      "Epoch 62 Finished | Avg Loss: 0.0032453208696097136\n",
      "Epoch 63 Finished | Avg Loss: 0.0031601479277014732\n",
      "Epoch 64 Finished | Avg Loss: 0.003097698325291276\n",
      "Epoch 65 Finished | Avg Loss: 0.003030854742974043\n",
      "Epoch 66 Finished | Avg Loss: 0.002942844061180949\n",
      "Epoch 67 Finished | Avg Loss: 0.0027915420942008495\n",
      "Epoch 68 Finished | Avg Loss: 0.0026272472459822893\n",
      "Epoch 69 Finished | Avg Loss: 0.0025175458285957575\n",
      "Epoch 70 Finished | Avg Loss: 0.0023688790388405323\n",
      "Epoch 71 Finished | Avg Loss: 0.0022473095450550318\n",
      "Epoch 72 Finished | Avg Loss: 0.0021884196903556585\n",
      "Epoch 73 Finished | Avg Loss: 0.002016659826040268\n",
      "Epoch 74 Finished | Avg Loss: 0.001985318260267377\n",
      "Epoch 75 Finished | Avg Loss: 0.001886857207864523\n",
      "Epoch 76 Finished | Avg Loss: 0.0018695017788559198\n",
      "Epoch 77 Finished | Avg Loss: 0.0018292648019269109\n",
      "Epoch 78 Finished | Avg Loss: 0.001750068855471909\n",
      "Epoch 79 Finished | Avg Loss: 0.0017690440872684121\n",
      "Epoch 80 Finished | Avg Loss: 0.001697016297839582\n",
      "Epoch 81 Finished | Avg Loss: 0.0016969982534646988\n",
      "Epoch 82 Finished | Avg Loss: 0.001647006836719811\n",
      "Epoch 83 Finished | Avg Loss: 0.0016361484304070473\n",
      "Epoch 84 Finished | Avg Loss: 0.0015479127177968621\n",
      "Epoch 85 Finished | Avg Loss: 0.0015405929880216718\n",
      "Epoch 86 Finished | Avg Loss: 0.0015041854931041598\n",
      "Epoch 87 Finished | Avg Loss: 0.001442728447727859\n",
      "Epoch 88 Finished | Avg Loss: 0.0014028435107320547\n",
      "Epoch 89 Finished | Avg Loss: 0.0014209480723366141\n",
      "Epoch 90 Finished | Avg Loss: 0.0013523094821721315\n",
      "Epoch 91 Finished | Avg Loss: 0.0013316554250195622\n",
      "Epoch 92 Finished | Avg Loss: 0.0012542280601337552\n",
      "Epoch 93 Finished | Avg Loss: 0.0012694166507571936\n",
      "Epoch 94 Finished | Avg Loss: 0.0013168653240427375\n",
      "Epoch 95 Finished | Avg Loss: 0.0012591318227350712\n",
      "Epoch 96 Finished | Avg Loss: 0.0012378861429169774\n",
      "Epoch 97 Finished | Avg Loss: 0.0012249008286744356\n",
      "Epoch 98 Finished | Avg Loss: 0.001153513789176941\n",
      "Epoch 99 Finished | Avg Loss: 0.0011884905397891998\n",
      "Epoch 100 Finished | Avg Loss: 0.0011057062074542046\n",
      "Epoch 101 Finished | Avg Loss: 0.001105243805795908\n",
      "Epoch 102 Finished | Avg Loss: 0.0010871815029531717\n",
      "Epoch 103 Finished | Avg Loss: 0.0010813685366883874\n",
      "Epoch 104 Finished | Avg Loss: 0.0010670990450307727\n",
      "Epoch 105 Finished | Avg Loss: 0.0010664606234058738\n",
      "Epoch 106 Finished | Avg Loss: 0.0010113040916621685\n",
      "Epoch 107 Finished | Avg Loss: 0.0010179602541029453\n",
      "Epoch 108 Finished | Avg Loss: 0.0010028760880231857\n",
      "Epoch 109 Finished | Avg Loss: 0.00098022585734725\n",
      "Epoch 110 Finished | Avg Loss: 0.0009823371656239033\n",
      "Epoch 111 Finished | Avg Loss: 0.0009433098020963371\n",
      "Epoch 112 Finished | Avg Loss: 0.0009204379748553038\n",
      "Epoch 113 Finished | Avg Loss: 0.0008974304655566812\n",
      "Epoch 114 Finished | Avg Loss: 0.0009177991887554526\n",
      "Epoch 115 Finished | Avg Loss: 0.0008940639672800899\n",
      "Epoch 116 Finished | Avg Loss: 0.0009247767156921327\n",
      "Epoch 117 Finished | Avg Loss: 0.000920526625122875\n",
      "Epoch 118 Finished | Avg Loss: 0.0008890885510481894\n",
      "Epoch 119 Finished | Avg Loss: 0.0008621127344667912\n",
      "Epoch 120 Finished | Avg Loss: 0.000838125532027334\n",
      "Epoch 121 Finished | Avg Loss: 0.0008620159351266921\n",
      "Epoch 122 Finished | Avg Loss: 0.0008292222046293318\n",
      "Epoch 123 Finished | Avg Loss: 0.0008011595928110182\n",
      "Epoch 124 Finished | Avg Loss: 0.0008189261425286531\n",
      "Epoch 125 Finished | Avg Loss: 0.0008045540889725089\n",
      "Epoch 126 Finished | Avg Loss: 0.0007699398556724191\n",
      "Epoch 127 Finished | Avg Loss: 0.0007863460923545063\n",
      "Epoch 128 Finished | Avg Loss: 0.0007581730023957789\n",
      "Epoch 129 Finished | Avg Loss: 0.0007332693785429001\n",
      "Epoch 130 Finished | Avg Loss: 0.000763760763220489\n",
      "Epoch 131 Finished | Avg Loss: 0.0007623238489031792\n",
      "Epoch 132 Finished | Avg Loss: 0.0007467208197340369\n",
      "Epoch 133 Finished | Avg Loss: 0.0007382192998193204\n",
      "Epoch 134 Finished | Avg Loss: 0.0007471827557310462\n",
      "Epoch 135 Finished | Avg Loss: 0.0006974428542889655\n",
      "Epoch 136 Finished | Avg Loss: 0.000688656815327704\n",
      "Epoch 137 Finished | Avg Loss: 0.0006894106627441943\n",
      "Epoch 138 Finished | Avg Loss: 0.0007256848621182144\n",
      "Epoch 139 Finished | Avg Loss: 0.0006838206318207085\n",
      "Epoch 140 Finished | Avg Loss: 0.0006699017249047756\n",
      "Epoch 141 Finished | Avg Loss: 0.0006626987596973777\n",
      "Epoch 142 Finished | Avg Loss: 0.0006454303511418402\n",
      "Epoch 143 Finished | Avg Loss: 0.0006695214542560279\n",
      "Epoch 144 Finished | Avg Loss: 0.000628368987236172\n",
      "Epoch 145 Finished | Avg Loss: 0.0006532334955409169\n",
      "Epoch 146 Finished | Avg Loss: 0.0006712159374728799\n",
      "Epoch 147 Finished | Avg Loss: 0.0006330260657705367\n",
      "Epoch 148 Finished | Avg Loss: 0.0006590398261323571\n",
      "Epoch 149 Finished | Avg Loss: 0.0005944836884737015\n",
      "Epoch 150 Finished | Avg Loss: 0.0005955667584203184\n",
      "Epoch 151 Finished | Avg Loss: 0.0005862824036739767\n",
      "Epoch 152 Finished | Avg Loss: 0.0005944727454334497\n",
      "Epoch 153 Finished | Avg Loss: 0.000604976259637624\n",
      "Epoch 154 Finished | Avg Loss: 0.0005833863979205489\n",
      "Epoch 155 Finished | Avg Loss: 0.0005912057822570205\n",
      "Epoch 156 Finished | Avg Loss: 0.0005558054544962943\n",
      "Epoch 157 Finished | Avg Loss: 0.0005762097425758839\n",
      "Epoch 158 Finished | Avg Loss: 0.0005474530626088381\n",
      "Epoch 159 Finished | Avg Loss: 0.000595109595451504\n",
      "Epoch 160 Finished | Avg Loss: 0.0005569998756982386\n",
      "Epoch 161 Finished | Avg Loss: 0.0005574464448727667\n",
      "Epoch 162 Finished | Avg Loss: 0.0005352430744096637\n",
      "Epoch 163 Finished | Avg Loss: 0.0005797919002361596\n",
      "Epoch 164 Finished | Avg Loss: 0.0005610330845229328\n",
      "Epoch 165 Finished | Avg Loss: 0.0005341622745618224\n",
      "Epoch 166 Finished | Avg Loss: 0.0005292775458656251\n",
      "Epoch 167 Finished | Avg Loss: 0.0005300819175317883\n",
      "Epoch 168 Finished | Avg Loss: 0.0005330361891537905\n",
      "Epoch 169 Finished | Avg Loss: 0.0005375423934310675\n",
      "Epoch 170 Finished | Avg Loss: 0.0005174403777346015\n",
      "Epoch 171 Finished | Avg Loss: 0.0005043369019404054\n",
      "Epoch 172 Finished | Avg Loss: 0.0005068504251539707\n",
      "Epoch 173 Finished | Avg Loss: 0.0004934283788315952\n",
      "Epoch 174 Finished | Avg Loss: 0.0004895167658105493\n",
      "Epoch 175 Finished | Avg Loss: 0.0004979114164598286\n",
      "Epoch 176 Finished | Avg Loss: 0.0004898779443465173\n",
      "Epoch 177 Finished | Avg Loss: 0.0004984200932085514\n",
      "Epoch 178 Finished | Avg Loss: 0.0004739509604405612\n",
      "Epoch 179 Finished | Avg Loss: 0.00044776650611311197\n",
      "Epoch 180 Finished | Avg Loss: 0.0004678326367866248\n",
      "Epoch 181 Finished | Avg Loss: 0.00045969351776875556\n",
      "Epoch 182 Finished | Avg Loss: 0.0004651316849049181\n",
      "Epoch 183 Finished | Avg Loss: 0.0004888128023594618\n",
      "Epoch 184 Finished | Avg Loss: 0.0005029185558669269\n",
      "Epoch 185 Finished | Avg Loss: 0.0004482608346734196\n",
      "Epoch 186 Finished | Avg Loss: 0.00047106287092901766\n",
      "Epoch 187 Finished | Avg Loss: 0.00048181929741986096\n",
      "Epoch 188 Finished | Avg Loss: 0.00048780793440528214\n",
      "Epoch 189 Finished | Avg Loss: 0.0004607555456459522\n",
      "Epoch 190 Finished | Avg Loss: 0.00044996346696279943\n",
      "Epoch 191 Finished | Avg Loss: 0.00044027206604368985\n",
      "Epoch 192 Finished | Avg Loss: 0.00041753461118787527\n",
      "Epoch 193 Finished | Avg Loss: 0.0004520510556176305\n",
      "Epoch 194 Finished | Avg Loss: 0.00046722436673007905\n",
      "Epoch 195 Finished | Avg Loss: 0.0004473206354305148\n",
      "Epoch 196 Finished | Avg Loss: 0.00042052578646689653\n",
      "Epoch 197 Finished | Avg Loss: 0.00040828139754012227\n",
      "Epoch 198 Finished | Avg Loss: 0.0004070978320669383\n",
      "Epoch 199 Finished | Avg Loss: 0.0004272164369467646\n",
      "Epoch 200 Finished | Avg Loss: 0.00042697967728599906\n",
      "Epoch 201 Finished | Avg Loss: 0.00041471453732810915\n",
      "Epoch 202 Finished | Avg Loss: 0.0004122014215681702\n",
      "Epoch 203 Finished | Avg Loss: 0.0004131757013965398\n",
      "Epoch 204 Finished | Avg Loss: 0.0003972443810198456\n",
      "Epoch 205 Finished | Avg Loss: 0.0004188718448858708\n",
      "Epoch 206 Finished | Avg Loss: 0.00042912253411486745\n",
      "Epoch 207 Finished | Avg Loss: 0.0004163317789789289\n",
      "Epoch 208 Finished | Avg Loss: 0.00041833813884295523\n",
      "Epoch 209 Finished | Avg Loss: 0.00041285500628873706\n",
      "Epoch 210 Finished | Avg Loss: 0.00039304594974964857\n",
      "Epoch 211 Finished | Avg Loss: 0.00038895494071766734\n",
      "Epoch 212 Finished | Avg Loss: 0.0003950691898353398\n",
      "Epoch 213 Finished | Avg Loss: 0.0003823882434517145\n",
      "Epoch 214 Finished | Avg Loss: 0.00038412405410781503\n",
      "Epoch 215 Finished | Avg Loss: 0.00041273023816756904\n",
      "Epoch 216 Finished | Avg Loss: 0.00038161809789016843\n",
      "Epoch 217 Finished | Avg Loss: 0.0003912399406544864\n",
      "Epoch 218 Finished | Avg Loss: 0.0003843560698442161\n",
      "Epoch 219 Finished | Avg Loss: 0.00037424545735120773\n",
      "Epoch 220 Finished | Avg Loss: 0.00035747408401221037\n",
      "Epoch 221 Finished | Avg Loss: 0.00035066920099779963\n",
      "Epoch 222 Finished | Avg Loss: 0.0003768057213164866\n",
      "Epoch 223 Finished | Avg Loss: 0.00036494413507170975\n",
      "Epoch 224 Finished | Avg Loss: 0.00039052413194440305\n",
      "Epoch 225 Finished | Avg Loss: 0.000352970149833709\n",
      "Epoch 226 Finished | Avg Loss: 0.0003738294180948287\n",
      "Epoch 227 Finished | Avg Loss: 0.0003532550181262195\n",
      "Epoch 228 Finished | Avg Loss: 0.00034161063376814127\n",
      "Epoch 229 Finished | Avg Loss: 0.0003648993733804673\n",
      "Epoch 230 Finished | Avg Loss: 0.0003599414776545018\n",
      "Epoch 231 Finished | Avg Loss: 0.0003581467899493873\n",
      "Epoch 232 Finished | Avg Loss: 0.0003449758514761925\n",
      "Epoch 233 Finished | Avg Loss: 0.0003411763464100659\n",
      "Epoch 234 Finished | Avg Loss: 0.0003519818128552288\n",
      "Epoch 235 Finished | Avg Loss: 0.00035225419560447335\n",
      "Epoch 236 Finished | Avg Loss: 0.00034293244243599474\n",
      "Epoch 237 Finished | Avg Loss: 0.0003475401026662439\n",
      "Epoch 238 Finished | Avg Loss: 0.00031827608472667634\n",
      "Epoch 239 Finished | Avg Loss: 0.00034267158480361104\n",
      "Epoch 240 Finished | Avg Loss: 0.0003388458862900734\n",
      "Epoch 241 Finished | Avg Loss: 0.0003608054539654404\n",
      "Epoch 242 Finished | Avg Loss: 0.00032708406797610223\n",
      "Epoch 243 Finished | Avg Loss: 0.00033473060466349125\n",
      "Epoch 244 Finished | Avg Loss: 0.0003300027165096253\n",
      "Epoch 245 Finished | Avg Loss: 0.0003233706229366362\n",
      "Epoch 246 Finished | Avg Loss: 0.00034642842365428805\n",
      "Epoch 247 Finished | Avg Loss: 0.0003229460562579334\n",
      "Epoch 248 Finished | Avg Loss: 0.0003345934965182096\n",
      "Epoch 249 Finished | Avg Loss: 0.000317357771564275\n",
      "Epoch 250 Finished | Avg Loss: 0.0003310288011562079\n",
      "Epoch 251 Finished | Avg Loss: 0.00031340980785898864\n",
      "Epoch 252 Finished | Avg Loss: 0.00032579529215581715\n",
      "Epoch 253 Finished | Avg Loss: 0.0003026553604286164\n",
      "Epoch 254 Finished | Avg Loss: 0.00031431656680069864\n",
      "Epoch 255 Finished | Avg Loss: 0.00030923745362088084\n",
      "Epoch 256 Finished | Avg Loss: 0.00031397934071719646\n",
      "Epoch 257 Finished | Avg Loss: 0.00031536747701466084\n",
      "Epoch 258 Finished | Avg Loss: 0.00035512345493771136\n",
      "Epoch 259 Finished | Avg Loss: 0.0003326034056954086\n",
      "Epoch 260 Finished | Avg Loss: 0.00034474156564101577\n",
      "Epoch 261 Finished | Avg Loss: 0.0003127653035335243\n",
      "Epoch 262 Finished | Avg Loss: 0.0003294152265880257\n",
      "Epoch 263 Finished | Avg Loss: 0.00029773166170343757\n",
      "Epoch 264 Finished | Avg Loss: 0.000297533260891214\n",
      "Epoch 265 Finished | Avg Loss: 0.0003310633765067905\n",
      "Epoch 266 Finished | Avg Loss: 0.0003139231412205845\n",
      "Epoch 267 Finished | Avg Loss: 0.0003139328910037875\n",
      "Epoch 268 Finished | Avg Loss: 0.0003071032406296581\n",
      "Epoch 269 Finished | Avg Loss: 0.0003249916189815849\n",
      "Epoch 270 Finished | Avg Loss: 0.0003100232279393822\n",
      "Epoch 271 Finished | Avg Loss: 0.0002803376701194793\n",
      "Epoch 272 Finished | Avg Loss: 0.00028939222102053463\n",
      "Epoch 273 Finished | Avg Loss: 0.00029486973653547466\n",
      "Epoch 274 Finished | Avg Loss: 0.0003010823857039213\n",
      "Epoch 275 Finished | Avg Loss: 0.0003116981824859977\n",
      "Epoch 276 Finished | Avg Loss: 0.00030392143526114523\n",
      "Epoch 277 Finished | Avg Loss: 0.0002985876926686615\n",
      "Epoch 278 Finished | Avg Loss: 0.00029988758615218103\n",
      "Epoch 279 Finished | Avg Loss: 0.00029789755353704095\n",
      "Epoch 280 Finished | Avg Loss: 0.00030321089434437454\n",
      "Epoch 281 Finished | Avg Loss: 0.00029676005942746997\n",
      "Epoch 282 Finished | Avg Loss: 0.0003227171837352216\n",
      "Epoch 283 Finished | Avg Loss: 0.00029206491308286786\n",
      "Epoch 284 Finished | Avg Loss: 0.000292889861157164\n",
      "Epoch 285 Finished | Avg Loss: 0.0002894652425311506\n",
      "Epoch 286 Finished | Avg Loss: 0.0002816577034536749\n",
      "Epoch 287 Finished | Avg Loss: 0.0002989545464515686\n",
      "Epoch 288 Finished | Avg Loss: 0.000292555196210742\n",
      "Epoch 289 Finished | Avg Loss: 0.00032200361602008343\n",
      "Epoch 290 Finished | Avg Loss: 0.0002948367618955672\n",
      "Epoch 291 Finished | Avg Loss: 0.0002774169552139938\n",
      "Epoch 292 Finished | Avg Loss: 0.0002756109170150012\n",
      "Epoch 293 Finished | Avg Loss: 0.0003026972699444741\n",
      "Epoch 294 Finished | Avg Loss: 0.00028271847986616194\n",
      "Epoch 295 Finished | Avg Loss: 0.00027145686908625066\n",
      "Epoch 296 Finished | Avg Loss: 0.00031106758979149163\n",
      "Epoch 297 Finished | Avg Loss: 0.00029056804487481713\n",
      "Epoch 298 Finished | Avg Loss: 0.0003247898130211979\n",
      "Epoch 299 Finished | Avg Loss: 0.00027069845236837864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>BER</td><td></td></tr><tr><td>freq_loss</td><td></td></tr><tr><td>learning_rate</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>time_frame_BER</td><td></td></tr><tr><td>time_mse_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>BER</td><td>0.00442</td></tr><tr><td>freq_loss</td><td>0.00215</td></tr><tr><td>learning_rate</td><td>0.001</td></tr><tr><td>loss</td><td>0.00027</td></tr><tr><td>time_frame_BER</td><td>0.00543</td></tr><tr><td>time_mse_loss</td><td>0.00181</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sleek-bee-7752</strong> at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/grppk2fb' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/grppk2fb</a><br> View project at: <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a><br>Synced 5 W&B file(s), 240 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251202_104442-grppk2fb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evm_loss(true_symbols, predicted_symbols):\n",
    "    return torch.mean(torch.abs(true_symbols - predicted_symbols) ** 2)\n",
    "\n",
    "def in_band_filter(x, ks_indices, nfft):\n",
    "    mask = torch.zeros(nfft, device=device)\n",
    "    neg_ks_indices = nfft - ks_indices\n",
    "    mask[ks_indices] = 1.0\n",
    "    mask[neg_ks_indices] = 1.0\n",
    "\n",
    "    impulse_response = torch.fft.ifftshift(torch.fft.ifft(mask).real)\n",
    "    h = impulse_response.view(1, 1, -1)\n",
    "    filtered_x = F.conv1d(x.unsqueeze(1), h, padding='same').squeeze(1)\n",
    "    return filtered_x\n",
    "\n",
    "\n",
    "def in_band_time_loss(sent_time, decoded_time, ks_indices, n_fft, num_taps):\n",
    "    \"\"\"Compute in-band loss directly in time domain using filtering\"\"\"\n",
    "    # Create frequency mask\n",
    "    mask = torch.zeros(n_fft, device=sent_time.device)\n",
    "    neg_ks_indices = n_fft - ks_indices\n",
    "    mask[ks_indices] = 1.0\n",
    "    mask[neg_ks_indices] = 1.0\n",
    "\n",
    "    # Convert to time-domain filter (this is differentiable)\n",
    "    impulse_response = torch.fft.ifftshift(torch.fft.ifft(mask).real)\n",
    "    h = impulse_response.view(1, 1, -1)\n",
    "\n",
    "    # Filter both signals\n",
    "    sent_filtered = F.conv1d(sent_time.unsqueeze(1), h, padding='same').squeeze(1)\n",
    "    decoded_filtered = F.conv1d(decoded_time.unsqueeze(1), h, padding='same').squeeze(1)\n",
    "\n",
    "    # Compute MSE on filtered signals (equivalent to in-band frequency loss)\n",
    "    loss = torch.mean((sent_filtered[:, num_taps:] - decoded_filtered[:, num_taps:]).pow(2))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def symbols_to_time(X, num_padding_zeros: int, num_leading_zeros=0):\n",
    "    # Make hermetian symmetric\n",
    "    Nt, Nf = X.shape\n",
    "    padding_zeros = torch.zeros(Nt, num_padding_zeros, device=device)\n",
    "    leading_zeros = torch.zeros(Nt, num_leading_zeros, device=device)\n",
    "    X = torch.cat([leading_zeros, X.to(device), padding_zeros], dim=-1)\n",
    "    DC_Nyquist = torch.zeros((X.shape[0], 1), device=X.device)\n",
    "    X_hermitian = torch.flip(X, dims=[1]).conj()\n",
    "    X_full = torch.hstack([DC_Nyquist, X, DC_Nyquist, X_hermitian])\n",
    "    # Convert to time domain\n",
    "    x_time = torch.fft.ifft(X_full, dim=-1, norm=\"ortho\").real\n",
    "    return x_time.to(device)\n",
    "\n",
    "def add_noise(signal, SNR):\n",
    "    signal_power = signal.abs().pow(2).mean()\n",
    "    noise_power = signal_power / SNR\n",
    "    noise_std = (noise_power / 2) ** 0.5 # real and complex\n",
    "    noise = noise_std * torch.randn_like(signal) + noise_std * 1j * torch.randn_like(signal)\n",
    "    signal += noise\n",
    "    return signal\n",
    "\n",
    "# def add_noise_time(signal, SNR):\n",
    "#     signal_power = signal.pow(2).mean()\n",
    "#     noise_power = signal_power / SNR\n",
    "#     noise_std = noise_power.sqrt()\n",
    "#     noise = noise_std * torch.randn_like(signal)\n",
    "#     return signal + noise\n",
    "\n",
    "\n",
    "def add_noise_time_cp(signal_with_cp, cp_length, snr_in, snr_low, snr_high, inband_idx, print_snr=False):\n",
    "    \"\"\"\n",
    "    Adds spectrally-shaped noise with three regions:\n",
    "      - In-band: indices in inband_idx\n",
    "      - Low out-of-band: below min(inband_idx)\n",
    "      - High out-of-band: above max(inband_idx)\n",
    "    \"\"\"\n",
    "    B, N_with_cp = signal_with_cp.shape\n",
    "    device = signal_with_cp.device\n",
    "\n",
    "    signal_no_cp = signal_with_cp[:, cp_length:]\n",
    "    P_sig = signal_no_cp.pow(2).mean(dim=-1, keepdim=True)\n",
    "\n",
    "    Pn_in_target = P_sig / snr_in\n",
    "    Pn_low_target = P_sig / snr_low\n",
    "    Pn_high_target = P_sig / snr_high\n",
    "\n",
    "    num_pos_freqs = (N_with_cp - 1) // 2\n",
    "    pos_freq_slice = slice(1, num_pos_freqs + 1)\n",
    "    neg_freq_slice = slice(N_with_cp - num_pos_freqs, N_with_cp)\n",
    "\n",
    "    inband_mask = torch.zeros(num_pos_freqs, dtype=bool, device=device)\n",
    "    valid_inband_indices = inband_idx[(inband_idx > 0) & (inband_idx <= num_pos_freqs)]\n",
    "    if valid_inband_indices.numel() > 0:\n",
    "        inband_mask[valid_inband_indices - 1] = True\n",
    "\n",
    "    all_idx = torch.arange(num_pos_freqs, device=device)\n",
    "    low_mask = (all_idx < inband_idx.min()) & ~inband_mask\n",
    "    high_mask = (all_idx > inband_idx.max()) & ~inband_mask\n",
    "\n",
    "    num_in_bins = inband_mask.sum()\n",
    "    num_low_bins = low_mask.sum()\n",
    "    num_high_bins = high_mask.sum()\n",
    "\n",
    "    def make_noise(num_bins, target_power):\n",
    "        if num_bins == 0:\n",
    "            return torch.zeros((B, 0), dtype=torch.complex64, device=device)\n",
    "        var_per_bin = (target_power * N_with_cp) / (2 * num_bins)\n",
    "        std_per_bin = torch.sqrt(var_per_bin)\n",
    "        noise = (torch.randn(B, num_bins, device=device) +\n",
    "                 1j * torch.randn(B, num_bins, device=device)) / math.sqrt(2.0)\n",
    "        return std_per_bin * noise\n",
    "\n",
    "    noise_in_pos = make_noise(num_in_bins, Pn_in_target)\n",
    "    noise_low_pos = make_noise(num_low_bins, Pn_low_target)\n",
    "    noise_high_pos = make_noise(num_high_bins, Pn_high_target)\n",
    "\n",
    "    noise_pos = torch.zeros(B, num_pos_freqs, dtype=torch.complex64, device=device)\n",
    "    if num_in_bins > 0: noise_pos[:, inband_mask] = noise_in_pos\n",
    "    if num_low_bins > 0: noise_pos[:, low_mask] = noise_low_pos\n",
    "    if num_high_bins > 0: noise_pos[:, high_mask] = noise_high_pos\n",
    "\n",
    "    noise_fft = torch.zeros(B, N_with_cp, dtype=torch.complex64, device=device)\n",
    "    noise_fft[:, pos_freq_slice] = noise_pos\n",
    "    noise_fft[:, neg_freq_slice] = torch.conj(torch.flip(noise_pos, dims=[1]))\n",
    "    noise_fft[:, 0] = 0\n",
    "    noise_time = torch.fft.ifft(noise_fft, norm=\"ortho\").real\n",
    "\n",
    "    if print_snr:\n",
    "        P_sig_mean = P_sig.mean().item()\n",
    "        def check(mask, noise_vals, target):\n",
    "            if mask.sum() == 0: return\n",
    "            tmp_fft = torch.zeros_like(noise_fft)\n",
    "            tmp_pos = torch.zeros_like(noise_pos); tmp_pos[:, mask] = noise_vals\n",
    "            tmp_fft[:, pos_freq_slice] = tmp_pos\n",
    "            tmp_fft[:, neg_freq_slice] = torch.conj(torch.flip(tmp_pos, dims=[1]))\n",
    "            Pn_actual = torch.fft.ifft(tmp_fft, norm=\"ortho\").real.pow(2).mean().item()\n",
    "            print(f\"SNR Check: target={target:.2f}, actual={P_sig_mean/Pn_actual:.2f}\")\n",
    "        check(inband_mask, noise_in_pos, snr_in)\n",
    "        check(low_mask, noise_low_pos, snr_low)\n",
    "        check(high_mask, noise_high_pos, snr_high)\n",
    "\n",
    "    return signal_with_cp + noise_time\n",
    "\n",
    "\n",
    "\n",
    "def calculate_BER(received_symbols, true_bits, constellation):\n",
    "    # Demap symbols to bits\n",
    "    constellation_symbols = torch.tensor(\n",
    "        list(constellation._symbols_to_bits_map.keys()),\n",
    "        dtype=received_symbols.dtype,\n",
    "        device=received_symbols.device\n",
    "    )\n",
    "    distances = abs(received_symbols.reshape(-1, 1) - constellation_symbols.reshape(1, -1))\n",
    "\n",
    "    closest_idx = distances.argmin(axis=1)\n",
    "    constellation_symbols_list = list(constellation._symbols_to_bits_map.keys())\n",
    "    decided_bits = [constellation._symbols_to_bits_map[constellation_symbols_list[idx]] for idx in closest_idx.cpu().numpy()]\n",
    "\n",
    "    # Flatten decided bits into a 1D array\n",
    "    decided_bits_flat = [int(bit) for symbol_bits in decided_bits for bit in symbol_bits]\n",
    "\n",
    "\n",
    "    # Convert to NumPy arrays for comparison\n",
    "    true_bits_array = np.array(true_bits)\n",
    "    decided_bits_flat_array = np.array(decided_bits_flat)\n",
    "\n",
    "    # Take minimum length to avoid shape mismatch\n",
    "    min_len = min(len(true_bits_array), len(decided_bits_flat_array))\n",
    "    true_bits_array = true_bits_array[:min_len]\n",
    "    decided_bits_flat_array = decided_bits_flat_array[:min_len]\n",
    "\n",
    "    # Calculate BER\n",
    "    BER = float(np.sum(true_bits_array != decided_bits_flat_array) / len(true_bits_array))\n",
    "    return BER\n",
    "\n",
    "\n",
    "def train(encoder, decoder, optimizer, scheduler, config, device, mask=None):\n",
    "\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "\n",
    "        epoch_loss = 0\n",
    "        epoch_freq_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        batch_entries = []\n",
    "        true_bits_list = []\n",
    "        for batch in range(config[\"batch_size\"]):\n",
    "            # Generate frame data\n",
    "            true_bits = np.random.randint(0, 2, size=NUM_BITS)\n",
    "            true_bits_list.append(torch.tensor(true_bits))\n",
    "            # true_bits = np.zeros(NUM_BITS).astype(int)\n",
    "            true_bits_str = ''.join(map(str, true_bits))\n",
    "            true_symbols = torch.tensor(\n",
    "                constellation.bits_to_symbols(true_bits_str),\n",
    "                dtype=torch.complex64, device=device\n",
    "            )\n",
    "            true_frame = true_symbols.reshape(config[\"Nt\"], config[\"Nf\"])\n",
    "\n",
    "            # Add known experimental noise\n",
    "\n",
    "            # true_frame = torch.zeros(config[\"Nt\"], config[\"Nf\"])\n",
    "            # true_frame[:, 100] = 10\n",
    "\n",
    "            if POWER_NORMALIZATION:\n",
    "                true_frame = true_frame / true_frame.abs().pow(2).mean(dim=1, keepdim=True).sqrt()\n",
    "            batch_entries.append(true_frame)\n",
    "\n",
    "        true_bits = torch.stack(true_bits_list)\n",
    "\n",
    "        # Batch along time domain\n",
    "        true_frame = torch.cat(batch_entries)\n",
    "\n",
    "        # print(\"Inband symbol power\", true_frame.abs().square().mean())\n",
    "        # Convert to time domain\n",
    "        sent_frames_time = symbols_to_time(true_frame, UPSAMPLING_ZEROS, NUM_ZEROS)\n",
    "        sent_frames_time = torch.hstack((sent_frames_time[:, -CP_LENGTH:], sent_frames_time))\n",
    "\n",
    "        encoded_frames_time = encoder(sent_frames_time)\n",
    "        # encoded_frames_time = in_band_filter(encoded_frames_time, KS, NUM_POINTS_FRAME)\n",
    "\n",
    "        # Clip to preamble make\n",
    "        encoded_frames_time = torch.clip(encoded_frames_time, -PREAMBLE_MAX, PREAMBLE_MAX)\n",
    "        # encoded_frames_time = add_noise_time_cp(encoded_frames_time,\n",
    "        #                                              snr_in=float(100000),\n",
    "        #                                                 snr_low=float(100000),\n",
    "        #                                                snr_high=0,\n",
    "        #                                               inband_idx=torch.arange(int(1), int(25e6)),\n",
    "        #                                              cp_length=CP_LENGTH)\n",
    "\n",
    "        received_frames_time = channel_model.forward_simulate(encoded_frames_time)\n",
    "\n",
    "\n",
    "        # Filter out of band noise\n",
    "        # received_frames_time_noisy = in_band_filter(received_frames_time_noisy, KS, NUM_POINTS_FRAME)\n",
    "\n",
    "        # received_frames_time = add_noise(received_frames_time, SNR=10**(config[\"snr_db\"]/10))\n",
    "        decoded_frames_time = decoder(received_frames_time)\n",
    "\n",
    "        # Convert to frequency domain for loss\n",
    "        sent_frames_frequency = torch.tensor(rfft(sent_frames_time[:, CP_LENGTH:].detach().cpu().numpy(), norm='ortho', axis=1)[:, KS])\n",
    "        decoded_frames_frequency = torch.tensor(rfft(decoded_frames_time[:, CP_LENGTH:].detach().cpu().numpy(), norm='ortho', axis=1)[:, KS])\n",
    "\n",
    "        sent_norm = sent_frames_frequency.abs().square().mean(dim=1, keepdim=True).sqrt()\n",
    "        decoded_norm = decoded_frames_frequency.abs().square().mean(dim=1, keepdim=True).sqrt()\n",
    "\n",
    "\n",
    "        if POWER_NORMALIZATION:\n",
    "            sent_frames_frequency = sent_frames_frequency / sent_norm\n",
    "            decoded_frames_frequency = decoded_frames_frequency / decoded_norm\n",
    "\n",
    "\n",
    "        # print(\"Time power through channel\", sent_frames_time.abs().square().mean().item(), received_frames_time.abs().square().mean().item(), sent_frames_time.shape)\n",
    "        loss = in_band_time_loss(sent_frames_time, decoded_frames_time, ks_indices=KS, n_fft=NUM_POINTS_FRAME, num_taps=config['num_taps'])\n",
    "        # loss = evm_loss(sent_frames_time, decoded_frames_time)\n",
    "        diff_complex = sent_frames_frequency.detach() - decoded_frames_frequency.detach()\n",
    "        # print(\"evm shapes\", sent_frames_frequency.shape, decoded_frames_frequency.shape)\n",
    "        freq_loss = torch.mean(diff_complex.abs().pow(2))\n",
    "\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_freq_loss += freq_loss.item()\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step(epoch_loss)\n",
    "\n",
    "        wandb.log({\"loss\": epoch_loss}, step=epoch)\n",
    "        wandb.log({\"freq_loss\": epoch_freq_loss}, step=epoch)\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        wandb.log({\"learning_rate\": lr}, step=epoch)\n",
    "\n",
    "        # Get BER\n",
    "        ber = calculate_BER(decoded_frames_frequency.detach().flatten(), true_bits.flatten(), constellation=constellation)\n",
    "        wandb.log({\"BER\": ber}, step=epoch)\n",
    "        print(f\"Epoch {epoch} Finished | Avg Loss: {epoch_loss}\")\n",
    "        if epoch % 5 == 0:\n",
    "            make_time_validate_plots(\n",
    "            sent_frames_time[0],\n",
    "            received_frames_time[0],\n",
    "            decoded_frames_time[0],\n",
    "            frame_BER=ber,\n",
    "            run_model=True,\n",
    "            step=epoch\n",
    "            )\n",
    "\n",
    "            # Plot first example of sent and reconstructed time\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(sent_frames_time[0][:100].detach().cpu().numpy(), label=\"Sent (time)\")\n",
    "            ax.plot(decoded_frames_time[0][:100].detach().cpu().numpy(), label=\"Decoded (time)\")\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"Sent vs Decoded (Time Domain) EVM: {loss: 0.3e}\")\n",
    "            wandb.log({\"time_domain_plot\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "            sent_symbols = sent_frames_frequency[0].detach().cpu().numpy()\n",
    "            decoded_symbols = decoded_frames_frequency[0].detach().cpu().numpy()\n",
    "\n",
    "            # Compute EVM for logging (per frame)\n",
    "            evm_val = evm_loss(torch.tensor(sent_symbols), torch.tensor(decoded_symbols)).item()\n",
    "\n",
    "            # Create constellation plot\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.scatter(sent_symbols.real, sent_symbols.imag, color='blue', alpha=0.6, label='Sent')\n",
    "            ax.scatter(decoded_symbols.real, decoded_symbols.imag, color='red', alpha=0.6, label='Decoded')\n",
    "            ax.set_xlabel('In-phase')\n",
    "            ax.set_ylabel('Quadrature')\n",
    "            ax.set_title(f'Constellation Diagram EVM: {evm_val:0.3e}')\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "\n",
    "            # Log to wandb\n",
    "            wandb.log({\"constellation\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "            evm_per_freq = ((sent_frames_frequency[0] - decoded_frames_frequency[0]).abs()**2).detach().cpu().numpy()\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(evm_per_freq)\n",
    "            ax.set_title(\"EVM vs Frequency\")\n",
    "            wandb.log({\"evm_vs_freq\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "\n",
    "            # # Plot Model SNRs\n",
    "            # sent_k = torch.fft.fft(encoded_frames_time[:, CP_LENGTH:], norm=\"ortho\", dim=-1)\n",
    "            # received_k = torch.fft.fft(received_frames_time[:, CP_LENGTH:], norm=\"ortho\", dim=-1)\n",
    "\n",
    "            # residual = received_frames_time - mean\n",
    "            # received_noise_k = torch.fft.fft(residual[:, CP_LENGTH:] ** 2, norm=\"ortho\", dim=-1)\n",
    "\n",
    "\n",
    "            # signal_power = torch.mean(torch.abs(sent_k) ** 2, dim=0).detach().cpu().numpy()\n",
    "            # received_power = torch.mean(torch.abs(received_k) ** 2, dim=0).detach().cpu().numpy()\n",
    "            # received_noise_power = torch.mean(torch.abs(received_noise_k), dim=0).detach().cpu().numpy()\n",
    "            # snr_vs_freq = (received_power / received_noise_power + 1e-12)\n",
    "\n",
    "            # fig, ax = plt.subplots()\n",
    "            # ax.plot(10 * np.log10(signal_power[:len(signal_power)//2]))\n",
    "            # ax.axvline(30, c='r', linestyle='--')\n",
    "            # ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            # ax.set_title(f\"Encoded Signal Frequency Power Spectrum for {run.name}\")\n",
    "            # ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            # ax.set_ylabel(\"Power (dB)\")\n",
    "            # wandb.log({\"encoded_signal_power_spectrum\": wandb.Image(fig)}, step=epoch)\n",
    "            # plt.close(fig)\n",
    "\n",
    "            # fig, ax = plt.subplots()\n",
    "            # ax.plot(10 * np.log10(received_power[:len(received_power)//2]))\n",
    "            # ax.axvline(30, c='r', linestyle='--')\n",
    "            # ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            # ax.set_title(f\"Received Signal Frequency Power Spectrum for {run.name}\")\n",
    "            # ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            # ax.set_ylabel(\"Power (dB)\")\n",
    "            # wandb.log({\"received_signal_power_spectrum\": wandb.Image(fig)}, step=epoch)\n",
    "            # plt.close(fig)\n",
    "\n",
    "            # fig, ax = plt.subplots()\n",
    "            # ax.plot(10 * np.log10(snr_vs_freq[:len(snr_vs_freq)//2]))\n",
    "            # ax.set_title(f\"SNR vs Freq Estimate for {run.name}\")\n",
    "            # ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            # ax.set_ylabel(\"SNR (dB)\")\n",
    "            # ax.axvline(30, c='r', linestyle='--')\n",
    "            # ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            # wandb.log({\"snr_vs_freq\": wandb.Image(fig)}, step=epoch)\n",
    "            # plt.close(fig)\n",
    "\n",
    "            # fig, ax = plt.subplots()\n",
    "            # ax.plot(10 * np.log10(received_noise_power[:len(snr_vs_freq)//2]))\n",
    "            # ax.set_title(f\"Noise power vs Freq Estimate for {run.name}\")\n",
    "            # ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            # ax.set_ylabel(\"Power (dB)\")\n",
    "            # ax.axvline(30, c='r', linestyle='--')\n",
    "            # ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            # wandb.log({\"noise_power_vs_freq\": wandb.Image(fig)}, step=epoch)\n",
    "            # plt.close(fig)\n",
    "\n",
    "    # Save model\n",
    "    torch.save({\n",
    "        \"time_encoder\": encoder.state_dict(),\n",
    "        \"time_decoder\": decoder.state_dict()\n",
    "    }, \"time_autoencoder.pth\")\n",
    "\n",
    "    artifact = wandb.Artifact(\"time_autoencoder\", type=\"model\")\n",
    "    artifact.add_file(\"time_autoencoder.pth\")\n",
    "    wandb.log_artifact(artifact)\n",
    "\n",
    "    return epoch_loss\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "train(encoder, decoder, optimizer, scheduler, config, device)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f393d297",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Module [ProbabilisticStateSpaceModel] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m sent_frames_time \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhstack((sent_frames_time[:, \u001b[38;5;241m-\u001b[39mCP_LENGTH:], sent_frames_time))\n\u001b[0;32m     19\u001b[0m encoded_frames_time \u001b[38;5;241m=\u001b[39m encoder(sent_frames_time)\n\u001b[1;32m---> 20\u001b[0m received_frames_time_noisy, mean, std, nu \u001b[38;5;241m=\u001b[39m \u001b[43mchannel_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_frames_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m decoded_frames_time \u001b[38;5;241m=\u001b[39m decoder(received_frames_time_noisy)\n\u001b[0;32m     23\u001b[0m sent_k \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mfft(encoded_frames_time[:, CP_LENGTH:], norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mortho\u001b[39m\u001b[38;5;124m\"\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\maild\\miniconda3\\envs\\mldrivenpeled\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maild\\miniconda3\\envs\\mldrivenpeled\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\maild\\miniconda3\\envs\\mldrivenpeled\\Lib\\site-packages\\torch\\nn\\modules\\module.py:394\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_forward_unimplemented\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Define the computation performed at every call.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    395\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModule [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] is missing the required \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m function\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    396\u001b[0m     )\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Module [ProbabilisticStateSpaceModel] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "# Get SNR vs freq estimate\n",
    "test_freqs = torch.arange(0, 1e4 * 2999, 1e4, device=device)\n",
    "test_ks = (test_freqs / (1e4)).to(torch.int)\n",
    "true_bits = np.random.randint(0, 2, size=7 * len(test_freqs) * 100)\n",
    "\n",
    "\n",
    "true_bits_str = ''.join(map(str, true_bits))\n",
    "true_symbols = torch.tensor(\n",
    "    constellation.bits_to_symbols(true_bits_str),\n",
    "    dtype=torch.complex64, device=device\n",
    ")\n",
    "\n",
    "test = (NUM_POINTS_FRAME  +  -2 * test_ks[0] + -2 * len(test_ks)) // 2\n",
    "\n",
    "true_frame = true_symbols.reshape(100, 2999)\n",
    "true_bits = torch.tensor(true_bits)\n",
    "sent_frames_time = symbols_to_time(true_frame, test, 0)\n",
    "sent_frames_time = torch.hstack((sent_frames_time[:, -CP_LENGTH:], sent_frames_time))\n",
    "encoded_frames_time = encoder(sent_frames_time)\n",
    "received_frames_time_noisy, mean, std, nu = channel_model(encoded_frames_time)\n",
    "decoded_frames_time = decoder(received_frames_time_noisy)\n",
    "\n",
    "sent_k = torch.fft.fft(encoded_frames_time[:, CP_LENGTH:], norm=\"ortho\", dim=-1)\n",
    "received_k = torch.fft.fft(mean[:, CP_LENGTH:], norm=\"ortho\", dim=-1)\n",
    "\n",
    "residual = received_frames_time_noisy - mean\n",
    "received_noise_k = torch.fft.fft(residual[:, CP_LENGTH:] ** 2, norm=\"ortho\", dim=-1)\n",
    "\n",
    "\n",
    "signal_power = torch.mean(torch.abs(sent_k) ** 2, dim=0).detach().cpu().numpy()\n",
    "received_power = torch.mean(torch.abs(received_k) ** 2, dim=0).detach().cpu().numpy()\n",
    "received_noise_power = torch.mean(torch.abs(received_noise_k), dim=0).detach().cpu().numpy()\n",
    "snr_vs_freq = (received_power / received_noise_power + 1e-12)\n",
    "\n",
    "\n",
    "plt.plot(10 * np.log10(signal_power[:len(signal_power)//2]))\n",
    "plt.axvline(30, c='r', linestyle='--')\n",
    "plt.axvline(int(4e2), c='r', linestyle='--')\n",
    "plt.title(f\"Encoded Signal Frequency Power Spectrum for {run.name}\")\n",
    "plt.xlabel(\"Freq Index k (10 kHz)\")\n",
    "plt.ylabel(\"Power (dB)\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(10 * np.log10(received_power[:len(received_power)//2]))\n",
    "plt.axvline(30, c='r', linestyle='--')\n",
    "plt.axvline(int(4e2), c='r', linestyle='--')\n",
    "plt.title(f\"Received Signal Frequency Power Spectrum for {run.name}\")\n",
    "plt.xlabel(\"Freq Index k (10 kHz)\")\n",
    "plt.ylabel(\"Power (dB)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(10 * np.log10(snr_vs_freq[:len(snr_vs_freq)//2]))\n",
    "plt.title(f\"SNR vs Freq Estimate for {run.name}\")\n",
    "plt.xlabel(\"Freq Index k (10 kHz)\")\n",
    "plt.ylabel(\"SNR (dB)\")\n",
    "plt.axvline(30, c='r', linestyle='--')\n",
    "plt.axvline(int(4e2), c='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(10 * np.log10(received_noise_power[30:len(snr_vs_freq)//2]))\n",
    "plt.title(f\"Noise power vs Freq Estimate for {run.name}\")\n",
    "plt.xlabel(\"Freq Index k (10 kHz)\")\n",
    "plt.ylabel(\"Power (dB)\")\n",
    "plt.axvline(30, c='r', linestyle='--')\n",
    "plt.axvline(int(4e2), c='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, tag):\n",
    "    # Sample hyperparameters\n",
    "    dilation_base = trial.suggest_categorical(\"dilation_base\", [2])\n",
    "    num_taps = trial.suggest_int(\"num_taps\", 10, 30, step=2)\n",
    "    hidden_channels = trial.suggest_int(\"hidden_channels\", 4, 64, step=8)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2)\n",
    "    nlayers = trial.suggest_categorical(\"nlayers\", [2, 3, 4])\n",
    "\n",
    "    local_config = {\n",
    "        \"dilation_base\": dilation_base,\n",
    "        \"num_taps\": num_taps,\n",
    "        \"hidden_channels\": hidden_channels,\n",
    "        \"lr\": lr,\n",
    "        \"epochs\": 800,\n",
    "        \"batch_size\": 16,\n",
    "        \"Nt\": 1,\n",
    "        \"Nf\": 370,\n",
    "        \"save_path\": \"./saved_models\",\n",
    "        \"nlayers\": nlayers,\n",
    "        \"weight_init\": \"default\",\n",
    "        \"scheduler_type\": \"reduce_lr_on_plateu\",\n",
    "        \"modulator\": f\"{constellation_mode}\"\n",
    "    }\n",
    "\n",
    "    wandb.init(project=\"mldrivenpeled\", config=local_config, reinit=True,\n",
    "               tags=['autoencoder', f'{tag}', f'trial {trial.number}'], mode='online')\n",
    "\n",
    "    wandb.run.notes = f\"\\n | trained on channel model {run_name} \\n | {constellation_mode}\"\n",
    "\n",
    "    encoder = None\n",
    "    decoder = None\n",
    "    optimizer = None\n",
    "    scheduler = None\n",
    "\n",
    "    try:\n",
    "        encoder = TCN(\n",
    "            nlayers=nlayers,\n",
    "            dilation_base=dilation_base,\n",
    "            num_taps=num_taps,\n",
    "            hidden_channels=hidden_channels\n",
    "        ).to(device)\n",
    "\n",
    "        decoder = TCN(\n",
    "            nlayers=nlayers,\n",
    "            dilation_base=dilation_base,\n",
    "            num_taps=num_taps,\n",
    "            hidden_channels=hidden_channels\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(\n",
    "            list(encoder.parameters()) + list(decoder.parameters()), lr=lr\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "\n",
    "        final_loss = train(encoder, decoder, optimizer, scheduler, local_config, device)\n",
    "\n",
    "        return final_loss\n",
    "\n",
    "    finally:\n",
    "        wandb.finish()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        del encoder, decoder, optimizer, scheduler\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7232b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "study_name = f\"optuna_offline_ae_model_{timestamp}\"\n",
    "# study_name= \"optuna_offline_ae_model_20250919_174002\"\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=study_name, storage=\"sqlite:///optuna_results.db\", load_if_exists=True)\n",
    "study.optimize(lambda trial: objective(trial, study_name), n_trials=100)\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)\n",
    "\n",
    "'''\n",
    "{'dilation_base': 2, 'num_taps': 12, 'hidden_channels': 20, 'lr': 0.0005269745303114973, 'nlayers': 4, 'taps': 20} Current best with loss 2e-3\n",
    "Trial 44 finished with value: 0.001965869450941682 and parameters: {'dilation_base': 2, 'num_taps': 10, 'hidden_channels': 44, 'lr': 0.009314226151764216, 'nlayers': 4}. Best is trial 44 with value: 0.001965869450941682\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3987779",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = \"sqlite:///optuna_results.db\"\n",
    "summaries = optuna.get_all_study_summaries(storage=storage)\n",
    "for summary in summaries:\n",
    "    print(f\"Study name: {summary.study_name}\")\n",
    "    print(f\"  Trial count: {summary.n_trials}\")\n",
    "    if summary.best_trial is not None:\n",
    "        print(f\"  Best value: {summary.best_trial.value}\")\n",
    "        print(f\"  Best params: {summary.best_trial.params}\")\n",
    "    else:\n",
    "        print(\"  No trials completed yet.\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90307804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    "    plot_slice,\n",
    "    plot_parallel_coordinate\n",
    ")\n",
    "\n",
    "# Step 1: Choose your study name (copy it from the summaries you printed earlier)\n",
    "study_name = \"optuna_offline_ae_model_20250928_115643\"\n",
    "storage = \"sqlite:///optuna_results.db\"\n",
    "\n",
    "# Step 2: Load the study\n",
    "study = optuna.load_study(study_name=study_name, storage=storage)\n",
    "\n",
    "# Step 3: Plot using interactive Plotly charts\n",
    "plot_optimization_history(study).show()\n",
    "plot_param_importances(study).show()\n",
    "plot_slice(study).show()\n",
    "plot_parallel_coordinate(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcb5c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f19e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc26e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldrivenpeled",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
