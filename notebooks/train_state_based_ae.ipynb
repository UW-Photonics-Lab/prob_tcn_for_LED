{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ccdd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from scipy.fft import irfft, rfft\n",
    "import gc\n",
    "import time\n",
    "sys.path.append(os.path.abspath(\"../lab_scripts\"))\n",
    "from constellation_diagram import QPSK_Constellation\n",
    "from constellation_diagram import RingShapedConstellation\n",
    "\n",
    "if wandb.run is not None:\n",
    "    wandb.run.tags = list(wandb.run.tags) + [\"junk\"]\n",
    "wandb.finish()\n",
    "NUM_POINTS_FRAME = 6000\n",
    "# NUM_POINTS_FRAME = 3040\n",
    "CP_LENGTH = 2000\n",
    "# CP_LENGTH = 1013\n",
    "NUM_POINTS_SYMBOL = NUM_POINTS_FRAME + CP_LENGTH\n",
    "POWER_NORMALIZATION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688026f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "run = api.run(\"dylanbackprops-university-of-washington/mldrivenpeled/m62g9j8z\") # Variable\n",
    "model_name = \"channel_model_final\"\n",
    "artifact = api.artifact(\"dylanbackprops-university-of-washington/mldrivenpeled/channel_model:v1830\") # Variable\n",
    "artifact_dir = artifact.download()\n",
    "remote_config = run.config\n",
    "run_name = run.name\n",
    "print(\"Channel Run name:\", run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c30fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eea4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Contents of artifact_dir:\", os.listdir(artifact_dir))\n",
    "# Set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\") # for M chip Macs\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8add790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_last_layer(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.zeros_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "class StateSpaceModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 deterministic_num_taps,\n",
    "                 deterministic_state_size,\n",
    "                 deterministic_hidden_size,\n",
    "                 stochastic_state_size,\n",
    "                 stochastic_hidden_size\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.deterministic_state_size = deterministic_state_size\n",
    "        self.stochastic_state_size = stochastic_state_size\n",
    "        self.deterministic_num_taps = deterministic_num_taps\n",
    "        self.deterministic_state_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(deterministic_hidden_size, deterministic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(deterministic_hidden_size, deterministic_state_size)\n",
    "        )\n",
    "        self.deterministic_out_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(deterministic_hidden_size, 1) # Predict next scalar ouptut\n",
    "        )\n",
    "        self.stochastic_state_map = nn.Sequential(\n",
    "            nn.Linear(stochastic_state_size + deterministic_num_taps + 1, stochastic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(stochastic_hidden_size, stochastic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(stochastic_hidden_size, stochastic_state_size)\n",
    "        )\n",
    "        self.stochastic_out_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + stochastic_state_size + deterministic_state_size, stochastic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(stochastic_hidden_size, 1)\n",
    "        )\n",
    "        self.linear_det_out_map = nn.Linear(deterministic_num_taps + deterministic_state_size, 1)\n",
    "        self.linear_det_state_map = nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_state_size)\n",
    "        self.linear_stoch_state_map = nn.Linear(stochastic_state_size + deterministic_num_taps + 1, stochastic_state_size)\n",
    "        self.linear_stoch_out_map = nn.Linear(deterministic_num_taps + stochastic_state_size + deterministic_state_size, 1)\n",
    "\n",
    "        self.n0 = nn.Parameter(torch.zeros(deterministic_state_size))\n",
    "        self.z0 = nn.Parameter(torch.zeros(stochastic_state_size))\n",
    "\n",
    "        # Make it so that the stochastic output starts at zero\n",
    "        self.deterministic_state_map[-1].apply(zero_last_layer)\n",
    "        self.deterministic_out_map[-1].apply(zero_last_layer)\n",
    "        self.stochastic_state_map[-1].apply(zero_last_layer)\n",
    "        self.stochastic_out_map[-1].apply(zero_last_layer)\n",
    "        self.mode = \"nonlinear\"\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        mode = self.mode\n",
    "        device = x.device\n",
    "        y_pred = torch.zeros_like(x, device=device)\n",
    "        e_pred = torch.zeros_like(x, device=device)\n",
    "        T = x.size(-1)\n",
    "        B = x.size(0)\n",
    "        # n_t = torch.zeros(B, self.deterministic_state_size, device=device)\n",
    "        # z_t = torch.zeros(B, self.stochastic_state_size, device=device)\n",
    "        n_t = self.n0.unsqueeze(0).expand(B, -1)  # [B, nx]\n",
    "        z_t = self.z0.unsqueeze(0).expand(B, -1)  # [B, nz]\n",
    "        # add zeros in front equal to num_taps - 1\n",
    "        x = torch.cat([torch.zeros(B, self.deterministic_num_taps - 1, device=device), x], dim=-1)\n",
    "        for t in range(T):\n",
    "            x_t = x[:, t: t + self.deterministic_num_taps]\n",
    "\n",
    "            if mode == \"linear\":\n",
    "                y_t_pred = self.linear_det_out_map(torch.cat([x_t, n_t], dim=-1))\n",
    "            else:\n",
    "                y_t_pred = self.deterministic_out_map(torch.cat([x_t, n_t], dim=-1)) + self.linear_det_out_map(torch.cat([x_t, n_t], dim=-1))\n",
    "\n",
    "            if y is None:\n",
    "                '''INFERENCE MODE'''\n",
    "                y_pred[:, t] = y_t_pred.squeeze(-1)\n",
    "                # Assume residuals are an innovation process with zero mean\n",
    "                if mode == \"linear\":\n",
    "                    n_t = n_t + self.linear_det_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "                else:\n",
    "                    n_t = n_t + self.deterministic_state_map(torch.cat([x_t, n_t], dim=-1)) + self.linear_det_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "\n",
    "            else:\n",
    "                '''TRAINING MODE'''\n",
    "                # Training mode\n",
    "                y_t = y[:, t]\n",
    "                r_t = y_t.unsqueeze(-1) - y_t_pred\n",
    "\n",
    "                if mode == \"linear\":\n",
    "                    nonlinear_noise_t = self.linear_stoch_out_map(torch.cat([x_t, n_t, z_t], dim=-1))\n",
    "                else:\n",
    "                    nonlinear_noise_t = self.stochastic_out_map(torch.cat([x_t, n_t, z_t], dim=-1)) + self.linear_stoch_out_map(torch.cat([x_t, n_t, z_t], dim=-1))\n",
    "                y_t_next_pred = y_t_pred + nonlinear_noise_t\n",
    "                y_pred[:, t] = y_t_next_pred.squeeze(-1)\n",
    "                e_t = r_t - nonlinear_noise_t\n",
    "                e_pred[:, t] = e_t.squeeze(-1)\n",
    "                # Make state updates\n",
    "\n",
    "                if mode == \"linear\":\n",
    "                    z_t = z_t + self.linear_stoch_state_map(torch.cat([x_t, z_t, r_t], dim=-1))\n",
    "                    n_t = n_t + self.linear_det_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "                else:\n",
    "                    z_t = z_t + self.stochastic_state_map(torch.cat([x_t, z_t, r_t], dim=-1)) + self.linear_stoch_state_map(torch.cat([x_t, z_t, r_t], dim=-1))\n",
    "                    n_t = n_t + self.deterministic_state_map(torch.cat([x_t, n_t], dim=-1)) + self.linear_det_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "        return y_pred, e_pred\n",
    "\n",
    "\n",
    "class TCNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation=dilation,\n",
    "            padding=0\n",
    "        )\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        self.SiLU = nn.SiLU()\n",
    "        self.resample = None\n",
    "        if in_channels != out_channels:\n",
    "            self.resample = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.pad(x, (self.padding, 0))\n",
    "        out = self.conv(out)\n",
    "        out = self.SiLU(out)\n",
    "        if out.size(2) > x.size(2):\n",
    "            out = out[:, :, :x.size(2)]\n",
    "        if self.resample:\n",
    "            x = self.resample(x)\n",
    "        return out + x  # residual connection\n",
    "\n",
    "\n",
    "def sample_student_t_mps(mean, std, nu):\n",
    "    '''\n",
    "    Wilson-Hilferty Approximation for chi^2 converted to scaled and shifted student t\n",
    "    '''\n",
    "    z = torch.randn_like(mean)\n",
    "    z_chi = torch.randn_like(mean)\n",
    "    chi2_approx = nu * (1 - 2/(9*nu) + z_chi * torch.sqrt(2/(9*nu))).pow(3)\n",
    "    chi2_approx = chi2_approx.clamp(min=0.01)\n",
    "    scale = torch.sqrt(nu / chi2_approx)\n",
    "    return mean + std * z * scale\n",
    "\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, nlayers=3, dilation_base=2, num_taps=10, hidden_channels=32):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "        for i in range(nlayers):\n",
    "            dilation = dilation_base ** i\n",
    "            layers.append(\n",
    "                TCNBlock(in_channels, hidden_channels, num_taps, dilation)\n",
    "            )\n",
    "            in_channels = hidden_channels\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.readout = nn.Conv1d(hidden_channels, 1, kernel_size=1)\n",
    "\n",
    "        # Calculate the total receptive field for the whole TCN stack\n",
    "        self.receptive_field = 1\n",
    "        for i in range(nlayers):\n",
    "            dilation = dilation_base ** i\n",
    "            self.receptive_field += (num_taps - 1) * dilation\n",
    "\n",
    "    def forward(self, xin):\n",
    "        x = xin.unsqueeze(1)    # [B,1,T]\n",
    "        out = self.tcn(x)     # [B,H,T]\n",
    "        out = self.readout(out).squeeze(1)\n",
    "        out = out - out.mean(dim=1, keepdim=True)  # [B,T]\n",
    "        return out\n",
    "\n",
    "\n",
    "class TCN_channel(nn.Module):\n",
    "    def __init__(self, nlayers=3, dilation_base=2, num_taps=10, hidden_channels=32, learn_noise=False, gaussian=True):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "        for i in range(nlayers):\n",
    "            dilation = dilation_base ** i\n",
    "            layers.append(\n",
    "                TCNBlock(in_channels, hidden_channels, num_taps, dilation)\n",
    "            )\n",
    "            in_channels = hidden_channels\n",
    "        self.learn_noise = learn_noise\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        if gaussian:\n",
    "            self.readout = nn.Conv1d(hidden_channels, 2, kernel_size=1) # 2 channels mean | std\n",
    "        else:\n",
    "            self.readout = nn.Conv1d(hidden_channels, 3, kernel_size=1) # 3 channels mean | std | nu\n",
    "        self.num_taps = num_taps\n",
    "        self.gaussian = gaussian\n",
    "\n",
    "        if not gaussian:\n",
    "            with torch.no_grad():\n",
    "                # Initialize log_nu bias\n",
    "                self.readout.bias[2].fill_(48)\n",
    "\n",
    "    def forward(self, xin):\n",
    "        x = xin.unsqueeze(1)    # [B,1,T]\n",
    "        out = self.tcn(x)     # [B,H,T]\n",
    "        out = self.readout(out) # [B, 3, T] mean | std | nu\n",
    "        mean_out = out[:, 0, :]\n",
    "        log_std_out = out[:, 1, :]\n",
    "        std_out = torch.exp(log_std_out)\n",
    "        if not self.gaussian:\n",
    "            log_nu_out = out[:, 2, :]\n",
    "            nu_out = torch.nn.functional.softplus(log_nu_out)\n",
    "            nu_out = torch.clamp(nu_out, 2, 50) # nu between 2 and 50\n",
    "        mean_out = mean_out - mean_out.mean(dim=1, keepdim=True)  # [B ,T]\n",
    "\n",
    "        # # Produce noisy output\n",
    "        if self.gaussian:\n",
    "            z = torch.randn_like(mean_out)\n",
    "            noisy_out = mean_out + std_out * z\n",
    "            nu_out = torch.zeros_like(mean_out)\n",
    "        else:\n",
    "            noisy_out = sample_student_t_mps(mean_out, std_out, nu_out)\n",
    "        if self.learn_noise:\n",
    "            return noisy_out, mean_out, std_out, nu_out\n",
    "        else:\n",
    "            return mean_out, mean_out, torch.zeros_like(mean_out)\n",
    "\n",
    "class ProbabilisticStateSpaceModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_taps,\n",
    "                 state_size,\n",
    "                 hidden_size,\n",
    "                 ar_taps,\n",
    "                 detach_residuals=True,\n",
    "                 linear_fast=True\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.state_size = state_size\n",
    "        self.num_taps = num_taps\n",
    "        self.linear_fast = linear_fast\n",
    "        self.detach_residuals = detach_residuals\n",
    "        self.state_map = nn.Sequential(\n",
    "            nn.Linear(num_taps + state_size, hidden_size),\n",
    "            # nn.SiLU(),\n",
    "            # nn.Linear(hidden_size, hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, state_size)\n",
    "        )\n",
    "        self.state_out_map = nn.Sequential(\n",
    "            nn.Linear(num_taps + state_size, hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, 2 + ar_taps) # Predict mean and std\n",
    "        )\n",
    "        if linear_fast:\n",
    "            self.fast_feedthrough = nn.Linear(num_taps, 1, bias=False)\n",
    "        else:\n",
    "            self.fast_feedthrough = nn.Sequential(\n",
    "                nn.Linear(num_taps, hidden_size, bias=False),\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(hidden_size, 1, bias=False)\n",
    "            )\n",
    "        # nn.init.zeros_(self.fast_feedthrough.weight)\n",
    "        # nn.init.zeros_(self.fast_feedthrough.weight)\n",
    "        self.n0 = nn.Parameter(torch.zeros(state_size))\n",
    "        # self.alpha = nn.Parameter(torch.tensor(0.5))\n",
    "        self.alpha = nn.Parameter(torch.tensor(3 * torch.randn(state_size)))\n",
    "        # self.state_map[-1].apply(zero_last_layer)\n",
    "        # self.state_out_map[-1].apply(zero_last_layer)\n",
    "        self.ar_coeffs = nn.Parameter(torch.zeros(ar_taps))\n",
    "        self.ar_taps = ar_taps\n",
    "\n",
    "    def _whiten(self, x, ar_preds):\n",
    "        out = torch.zeros_like(x)\n",
    "        for t in range(x.size(-1)):\n",
    "            x_whitened_t = x[:, t]\n",
    "            for i in range(self.ar_taps):\n",
    "                j = t - (i + 1)\n",
    "                if j >= 0: # Enforce boundary\n",
    "                #   x_whitened_t = x_whitened_t - nn.Tanh(ar_preds[i]) * x[:, j]\n",
    "                    if self.detach_residuals:\n",
    "                        x_whitened_t = x_whitened_t - ar_preds[:, t, i] * x[:, j].detach()\n",
    "                    else:\n",
    "                        x_whitened_t = x_whitened_t - ar_preds[:, t, i] * x[:, j] # Remove the possibility of cheating by spiking previous errors\n",
    "            out[:, t] = x_whitened_t\n",
    "        return out\n",
    "\n",
    "    def _step(self, xt, nt):\n",
    "        inp = torch.cat([xt, nt], dim=-1)\n",
    "        out = self.state_out_map(inp)\n",
    "        y_pred = out[:, 0]\n",
    "        y_fast = self.fast_feedthrough(xt).squeeze(-1)\n",
    "        # y_fast_sq = self.fast_square(xt ** 2).squeeze(-1)\n",
    "        y_pred = y_pred + y_fast\n",
    "        std_pred = F.softplus(out[:, 1]) + 1e-4\n",
    "        ar_preds = F.tanh(out[:, 2:])\n",
    "        delta_n = self.state_map(inp)\n",
    "        alpha = torch.sigmoid(self.alpha)\n",
    "        nt_next = (1.0 - alpha) * nt + delta_n\n",
    "        return y_pred, std_pred, ar_preds, nt_next\n",
    "\n",
    "    def forward_train(self, x, y):\n",
    "        device = x.device\n",
    "        T = x.size(-1)\n",
    "        B = x.size(0)\n",
    "        y_pred = torch.zeros(B, T, device=device)\n",
    "        std_pred = torch.zeros(B, T, device=device)\n",
    "        residuals = torch.zeros(B, T, device=device)\n",
    "        ar_preds = torch.zeros(B, T, self.ar_taps, device=device)\n",
    "        innovations = torch.zeros(B, T, device=device)\n",
    "        nt = self.n0.unsqueeze(0).repeat(B, 1).clone()  # [B, nx]\n",
    "        # add zeros in front equal to num_taps - 1\n",
    "        x = torch.cat([torch.zeros(B, self.num_taps - 1, device=device), x], dim=-1)\n",
    "\n",
    "        for t in range(T):\n",
    "            xt = x[:, t: t + self.num_taps]\n",
    "            y_pred_t, std_pred_t, ar_preds_t, nt = self._step(xt, nt)\n",
    "            y_pred[:, t] = y_pred_t\n",
    "\n",
    "            # get residuals\n",
    "            r_t = (y[:, t] - y_pred_t)\n",
    "            residuals[:, t] = r_t #\n",
    "            std_pred[:, t] = std_pred_t\n",
    "            eps_t = r_t\n",
    "            innovations[:, t] = eps_t\n",
    "            ar_preds[:, t, :] = ar_preds_t\n",
    "\n",
    "        # whiten the innovations\n",
    "        innovations = self._whiten(innovations, ar_preds)\n",
    "        return y_pred, std_pred, innovations\n",
    "\n",
    "\n",
    "    def forward_simulate(self, x, eps=None):\n",
    "        device = x.device\n",
    "        T = x.size(-1)\n",
    "        B = x.size(0)\n",
    "        y_pred = torch.zeros(B, T, device=device)\n",
    "        if eps is None:\n",
    "            eps = torch.randn(B, T, device=device)\n",
    "        residuals = []\n",
    "        x = torch.cat([torch.zeros(B, self.num_taps - 1, device=device), x], dim=-1)\n",
    "        n_t = self.n0.unsqueeze(0).repeat(B, 1).clone()\n",
    "        for t in range(T):\n",
    "            max_lag = min(self.ar_taps, t)\n",
    "            xt = x[:, t: t + self.num_taps]\n",
    "            y_pred_t, std_pred_t, ar_preds, n_t = self._step(xt, n_t)\n",
    "\n",
    "\n",
    "            if max_lag > 0:\n",
    "                past_resids = torch.stack(residuals[-max_lag:], dim=0) # [max_lag, B]\n",
    "                past_resids = past_resids.transpose(0, 1) # [B, max_lag]\n",
    "                past_resids = past_resids.flip(dims=[1]) # Flip so that first residual is closest in time\n",
    "                ar_component = torch.sum(ar_preds[:, :max_lag] * past_resids, dim=1) # [B, max_lag] * [B, max_lag]\n",
    "            else:\n",
    "                ar_component = torch.zeros(B, device=device)\n",
    "\n",
    "            r_t = ar_component + std_pred_t * eps[:, t]\n",
    "            residuals.append(r_t)\n",
    "            y_pred[:, t] = y_pred_t + r_t\n",
    "        return y_pred\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be83bd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel_model = StateSpaceModel(\n",
    "#     deterministic_num_taps=remote_config['deterministic_num_taps'],\n",
    "#     deterministic_state_size=remote_config['deterministic_state_size'],\n",
    "#     deterministic_hidden_size=remote_config['deterministic_hidden_size'],\n",
    "#     stochastic_state_size=remote_config['stochastic_state_size'],\n",
    "#     stochastic_hidden_size=remote_config['stochastic_hidden_size']\n",
    "# )\n",
    "\n",
    "channel_model = ProbabilisticStateSpaceModel(\n",
    "    num_taps = remote_config[\"num_taps\"],\n",
    "    state_size = remote_config[\"state_size\"],\n",
    "    hidden_size = remote_config[\"hidden_size\"],\n",
    "    ar_taps = remote_config[\"ar_taps\"],\n",
    "    detach_residuals = remote_config[\"detach_residuals\"],\n",
    "    linear_fast = remote_config[\"linear_fast\"]\n",
    ")\n",
    "\n",
    "channel_model_path = os.path.join(artifact_dir, model_name + \".pth\")\n",
    "checkpoint = torch.load(channel_model_path)\n",
    "channel_model.load_state_dict(checkpoint[\"channel_model\"])\n",
    "\n",
    "# Freeze before moving to device\n",
    "for param in channel_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "channel_model = channel_model.to(device).float()\n",
    "channel_model.eval()\n",
    "\n",
    "print(\"Channel model parameters frozen:\",\n",
    "      all(not param.requires_grad for param in channel_model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca40a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "constellation_mode = \"m7_apsk_constellation\"\n",
    "\n",
    "def get_constellation(mode: str):\n",
    "        if mode == \"qpsk\":\n",
    "            constellation = QPSK_Constellation()\n",
    "        elif mode == \"m5_apsk_constellation\":\n",
    "            constellation = RingShapedConstellation(filename=r'/Users/dylanjones/Desktop/mldrivenpeled/lab_scripts/saved_constellations/m5_apsk_constellation.npy')\n",
    "        elif mode == \"m6_apsk_constellation\":\n",
    "             constellation = RingShapedConstellation(filename=r'/Users/dylanjones/Desktop/mldrivenpeled/lab_scripts/saved_constellations/m6_apsk_constellation.npy')\n",
    "        elif mode == \"m7_apsk_constellation\":\n",
    "             # /Users/dylanjones/Desktop/mldrivenpeled/lab_scripts/saved_constellations/m7_apsk_constellation.npy\n",
    "             constellation = RingShapedConstellation(filename=r'/Users/dylanjones/Desktop/mldrivenpeled/lab_scripts/saved_constellations/m7_apsk_constellation.npy')\n",
    "        return constellation\n",
    "\n",
    "constellation = get_constellation(constellation_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.getcwd()\n",
    "config_path = os.path.join(script_dir, \"..\", \"offline_time_ae_config.yml\")\n",
    "with open(config_path, \"r\") as f:\n",
    "    hyperparams = yaml.safe_load(f)\n",
    "\n",
    "    wandb.init(project=\"mldrivenpeled\",\n",
    "            config=hyperparams,\n",
    "            tags=['autoencoder'])\n",
    "    config = wandb.config\n",
    "    if wandb.run.notes is None:\n",
    "        wandb.run.notes = \"\"\n",
    "    config.modulator = constellation_mode\n",
    "    wandb.run.notes += wandb.run.notes + f\"\\n | trained on channel model {run_name} \\n | {constellation_mode}\"\n",
    "    print(f\"WandB run info:\")\n",
    "    print(f\"  Name: {wandb.run.name}\")\n",
    "    print(f\"  ID: {wandb.run.id}\")\n",
    "    print(f\"  URL: {wandb.run.url}\")\n",
    "    print(\"Chosen hyperparameters for this session:\")\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73f372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TCN(\n",
    "    nlayers=config.nlayers,\n",
    "    dilation_base=config.dilation_base,\n",
    "    num_taps=config.num_taps,\n",
    "    hidden_channels=config.hidden_channels,\n",
    ").to(device)\n",
    "\n",
    "decoder = TCN(\n",
    "    nlayers=config.nlayers,\n",
    "    dilation_base=config.dilation_base,\n",
    "    num_taps=config.num_taps,\n",
    "    hidden_channels=config.hidden_channels\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f581d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=config.lr, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7549ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BITS = config.Nt * config.Nf * constellation.modulation_order\n",
    "FREQUENCIES = torch.arange(float(config.flow), float(config.fhigh), float(config.subcarrier_spacing))\n",
    "delta_f = FREQUENCIES[1] - FREQUENCIES[0]\n",
    "KS = (FREQUENCIES / delta_f).to(torch.int)\n",
    "K_MIN = int(KS[0].item())\n",
    "K_MAX = int(KS[-1].item())\n",
    "NUM_ZEROS = K_MIN - 1\n",
    "UPSAMPLING_ZEROS= (NUM_POINTS_FRAME  +  -2 * K_MIN + -2 * len(KS)) // 2\n",
    "PREAMBLE_MAX = config.preamble_amplitude\n",
    "UPSAMPLING_ZEROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9546e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435f914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_time_validate_plots(sent_frames_time, received_frames_time, decoded_frames_time,\n",
    "                             frame_BER, run_model, step=0, zoom_samples=200):\n",
    "\n",
    "    # Convert to numpy\n",
    "    enc_in = sent_frames_time.detach().cpu().numpy().flatten()\n",
    "    enc_out = received_frames_time.detach().cpu().numpy().flatten()\n",
    "    dec_in = received_frames_time.detach().cpu().numpy().flatten()\n",
    "    dec_out = decoded_frames_time.detach().cpu().numpy().flatten()\n",
    "\n",
    "    # Power and scaling\n",
    "    enc_power_in = np.mean(enc_in**2)\n",
    "    enc_power_out = np.mean(enc_out**2)\n",
    "    enc_scale = enc_power_out / (enc_power_in + 1e-12)\n",
    "\n",
    "    dec_power_in = np.mean(dec_in**2)\n",
    "    dec_power_out = np.mean(dec_out**2)\n",
    "    dec_scale = dec_power_out / (dec_power_in + 1e-12)\n",
    "\n",
    "    # MSEs\n",
    "    mse_encoder = np.mean((enc_in - enc_out) ** 2)\n",
    "    mse_decoder = np.mean((dec_in - dec_out) ** 2)\n",
    "    mse_total = np.mean((enc_in - dec_out) ** 2)\n",
    "\n",
    "    # Log scalars\n",
    "    prefix = \"time_\"\n",
    "    wandb.log({f\"{prefix}mse_loss\": mse_total}, step=step)\n",
    "    wandb.log({f\"{prefix}frame_BER\": frame_BER}, step=step)\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 16))\n",
    "    time_points = np.arange(zoom_samples)\n",
    "\n",
    "    axes[0].plot(time_points, enc_in[:zoom_samples], 'r', alpha=0.5, label='Encoder Input')\n",
    "    axes[0].plot(time_points, enc_out[:zoom_samples], 'b', alpha=0.8, label='Encoder Output')\n",
    "    axes[0].set_title(\n",
    "        f\"Encoder Comparison (MSE: {mse_encoder:.2e}) | \"\n",
    "        f\"In {enc_power_in:.3f} | Out {enc_power_out:.3f} | Scale {enc_scale:.3f}\"\n",
    "    )\n",
    "    axes[0].legend(); axes[0].grid(True)\n",
    "\n",
    "    axes[1].plot(time_points, dec_in[:zoom_samples], 'r', alpha=0.5, label='Decoder Input')\n",
    "    axes[1].plot(time_points, dec_out[:zoom_samples], 'b', alpha=0.8, label='Decoder Output')\n",
    "    axes[1].set_title(\n",
    "        f\"Decoder Comparison (MSE: {mse_decoder:.2e}) | \"\n",
    "        f\"In {dec_power_in:.3f} | Out {dec_power_out:.3f} | Scale {dec_scale:.3f}\"\n",
    "    )\n",
    "    axes[1].legend(); axes[1].grid(True)\n",
    "\n",
    "    axes[2].plot(time_points, enc_in[:zoom_samples], 'r', alpha=0.5, label='Original Input')\n",
    "    axes[2].plot(time_points, dec_out[:zoom_samples], 'b', alpha=0.8, label='Final Output')\n",
    "    axes[2].set_title(\n",
    "        f\"End-to-End Comparison ({'Trained' if run_model else 'Untrained'})\\n\"\n",
    "        f\"MSE: {mse_total:.2e}, BER: {frame_BER:.2f}\"\n",
    "    )\n",
    "    axes[2].legend(); axes[2].grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    wandb.log({f\"{prefix}time_signals\": wandb.Image(fig)}, step=step)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c91e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CP_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f48d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c109ac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evm_loss(true_symbols, predicted_symbols):\n",
    "    return torch.mean(torch.abs(true_symbols - predicted_symbols) ** 2)\n",
    "\n",
    "def in_band_filter(x, ks_indices, nfft):\n",
    "    mask = torch.zeros(nfft, device=device)\n",
    "    neg_ks_indices = nfft - ks_indices\n",
    "    mask[ks_indices] = 1.0\n",
    "    mask[neg_ks_indices] = 1.0\n",
    "\n",
    "    impulse_response = torch.fft.ifftshift(torch.fft.ifft(mask).real)\n",
    "    h = impulse_response.view(1, 1, -1)\n",
    "    filtered_x = F.conv1d(x.unsqueeze(1), h, padding='same').squeeze(1)\n",
    "    return filtered_x\n",
    "\n",
    "\n",
    "def in_band_time_loss(sent_time, decoded_time, ks_indices, n_fft, num_taps):\n",
    "    \"\"\"Compute in-band loss directly in time domain using filtering\"\"\"\n",
    "    # Create frequency mask\n",
    "    mask = torch.zeros(n_fft, device=sent_time.device)\n",
    "    neg_ks_indices = n_fft - ks_indices\n",
    "    mask[ks_indices] = 1.0\n",
    "    mask[neg_ks_indices] = 1.0\n",
    "\n",
    "    # Convert to time-domain filter (this is differentiable)\n",
    "    impulse_response = torch.fft.ifftshift(torch.fft.ifft(mask).real)\n",
    "    h = impulse_response.view(1, 1, -1)\n",
    "\n",
    "    # Filter both signals\n",
    "    sent_filtered = F.conv1d(sent_time.unsqueeze(1), h, padding='same').squeeze(1)\n",
    "    decoded_filtered = F.conv1d(decoded_time.unsqueeze(1), h, padding='same').squeeze(1)\n",
    "\n",
    "    # Compute MSE on filtered signals (equivalent to in-band frequency loss)\n",
    "    loss = torch.mean((sent_filtered[:, num_taps:] - decoded_filtered[:, num_taps:]).pow(2))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def symbols_to_time(X, num_padding_zeros: int, num_leading_zeros=0):\n",
    "    # Make hermetian symmetric\n",
    "    Nt, Nf = X.shape\n",
    "    padding_zeros = torch.zeros(Nt, num_padding_zeros, device=device)\n",
    "    leading_zeros = torch.zeros(Nt, num_leading_zeros, device=device)\n",
    "    X = torch.cat([leading_zeros, X.to(device), padding_zeros], dim=-1)\n",
    "    DC_Nyquist = torch.zeros((X.shape[0], 1), device=X.device)\n",
    "    X_hermitian = torch.flip(X, dims=[1]).conj()\n",
    "    X_full = torch.hstack([DC_Nyquist, X, DC_Nyquist, X_hermitian])\n",
    "    # Convert to time domain\n",
    "    x_time = torch.fft.ifft(X_full, dim=-1, norm=\"ortho\").real\n",
    "    return x_time.to(device)\n",
    "\n",
    "def add_noise(signal, SNR):\n",
    "    signal_power = signal.abs().pow(2).mean()\n",
    "    noise_power = signal_power / SNR\n",
    "    noise_std = (noise_power / 2) ** 0.5 # real and complex\n",
    "    noise = noise_std * torch.randn_like(signal) + noise_std * 1j * torch.randn_like(signal)\n",
    "    signal += noise\n",
    "    return signal\n",
    "\n",
    "# def add_noise_time(signal, SNR):\n",
    "#     signal_power = signal.pow(2).mean()\n",
    "#     noise_power = signal_power / SNR\n",
    "#     noise_std = noise_power.sqrt()\n",
    "#     noise = noise_std * torch.randn_like(signal)\n",
    "#     return signal + noise\n",
    "\n",
    "\n",
    "def add_noise_time_cp(signal_with_cp, cp_length, snr_in, snr_low, snr_high, inband_idx, print_snr=False):\n",
    "    \"\"\"\n",
    "    Adds spectrally-shaped noise with three regions:\n",
    "      - In-band: indices in inband_idx\n",
    "      - Low out-of-band: below min(inband_idx)\n",
    "      - High out-of-band: above max(inband_idx)\n",
    "    \"\"\"\n",
    "    B, N_with_cp = signal_with_cp.shape\n",
    "    device = signal_with_cp.device\n",
    "\n",
    "    signal_no_cp = signal_with_cp[:, cp_length:]\n",
    "    P_sig = signal_no_cp.pow(2).mean(dim=-1, keepdim=True)\n",
    "\n",
    "    Pn_in_target = P_sig / snr_in\n",
    "    Pn_low_target = P_sig / snr_low\n",
    "    Pn_high_target = P_sig / snr_high\n",
    "\n",
    "    num_pos_freqs = (N_with_cp - 1) // 2\n",
    "    pos_freq_slice = slice(1, num_pos_freqs + 1)\n",
    "    neg_freq_slice = slice(N_with_cp - num_pos_freqs, N_with_cp)\n",
    "\n",
    "    inband_mask = torch.zeros(num_pos_freqs, dtype=bool, device=device)\n",
    "    valid_inband_indices = inband_idx[(inband_idx > 0) & (inband_idx <= num_pos_freqs)]\n",
    "    if valid_inband_indices.numel() > 0:\n",
    "        inband_mask[valid_inband_indices - 1] = True\n",
    "\n",
    "    all_idx = torch.arange(num_pos_freqs, device=device)\n",
    "    low_mask = (all_idx < inband_idx.min()) & ~inband_mask\n",
    "    high_mask = (all_idx > inband_idx.max()) & ~inband_mask\n",
    "\n",
    "    num_in_bins = inband_mask.sum()\n",
    "    num_low_bins = low_mask.sum()\n",
    "    num_high_bins = high_mask.sum()\n",
    "\n",
    "    def make_noise(num_bins, target_power):\n",
    "        if num_bins == 0:\n",
    "            return torch.zeros((B, 0), dtype=torch.complex64, device=device)\n",
    "        var_per_bin = (target_power * N_with_cp) / (2 * num_bins)\n",
    "        std_per_bin = torch.sqrt(var_per_bin)\n",
    "        noise = (torch.randn(B, num_bins, device=device) +\n",
    "                 1j * torch.randn(B, num_bins, device=device)) / math.sqrt(2.0)\n",
    "        return std_per_bin * noise\n",
    "\n",
    "    noise_in_pos = make_noise(num_in_bins, Pn_in_target)\n",
    "    noise_low_pos = make_noise(num_low_bins, Pn_low_target)\n",
    "    noise_high_pos = make_noise(num_high_bins, Pn_high_target)\n",
    "\n",
    "    noise_pos = torch.zeros(B, num_pos_freqs, dtype=torch.complex64, device=device)\n",
    "    if num_in_bins > 0: noise_pos[:, inband_mask] = noise_in_pos\n",
    "    if num_low_bins > 0: noise_pos[:, low_mask] = noise_low_pos\n",
    "    if num_high_bins > 0: noise_pos[:, high_mask] = noise_high_pos\n",
    "\n",
    "    noise_fft = torch.zeros(B, N_with_cp, dtype=torch.complex64, device=device)\n",
    "    noise_fft[:, pos_freq_slice] = noise_pos\n",
    "    noise_fft[:, neg_freq_slice] = torch.conj(torch.flip(noise_pos, dims=[1]))\n",
    "    noise_fft[:, 0] = 0\n",
    "    noise_time = torch.fft.ifft(noise_fft, norm=\"ortho\").real\n",
    "\n",
    "    if print_snr:\n",
    "        P_sig_mean = P_sig.mean().item()\n",
    "        def check(mask, noise_vals, target):\n",
    "            if mask.sum() == 0: return\n",
    "            tmp_fft = torch.zeros_like(noise_fft)\n",
    "            tmp_pos = torch.zeros_like(noise_pos); tmp_pos[:, mask] = noise_vals\n",
    "            tmp_fft[:, pos_freq_slice] = tmp_pos\n",
    "            tmp_fft[:, neg_freq_slice] = torch.conj(torch.flip(tmp_pos, dims=[1]))\n",
    "            Pn_actual = torch.fft.ifft(tmp_fft, norm=\"ortho\").real.pow(2).mean().item()\n",
    "            print(f\"SNR Check: target={target:.2f}, actual={P_sig_mean/Pn_actual:.2f}\")\n",
    "        check(inband_mask, noise_in_pos, snr_in)\n",
    "        check(low_mask, noise_low_pos, snr_low)\n",
    "        check(high_mask, noise_high_pos, snr_high)\n",
    "\n",
    "    return signal_with_cp + noise_time\n",
    "\n",
    "\n",
    "\n",
    "def calculate_BER(received_symbols, true_bits, constellation):\n",
    "    # Demap symbols to bits\n",
    "    constellation_symbols = torch.tensor(\n",
    "        list(constellation._symbols_to_bits_map.keys()),\n",
    "        dtype=received_symbols.dtype,\n",
    "        device=received_symbols.device\n",
    "    )\n",
    "    distances = abs(received_symbols.reshape(-1, 1) - constellation_symbols.reshape(1, -1))\n",
    "\n",
    "    closest_idx = distances.argmin(axis=1)\n",
    "    constellation_symbols_list = list(constellation._symbols_to_bits_map.keys())\n",
    "    decided_bits = [constellation._symbols_to_bits_map[constellation_symbols_list[idx]] for idx in closest_idx.cpu().numpy()]\n",
    "\n",
    "    # Flatten decided bits into a 1D array\n",
    "    decided_bits_flat = [int(bit) for symbol_bits in decided_bits for bit in symbol_bits]\n",
    "\n",
    "\n",
    "    # Convert to NumPy arrays for comparison\n",
    "    true_bits_array = np.array(true_bits)\n",
    "    decided_bits_flat_array = np.array(decided_bits_flat)\n",
    "\n",
    "    # Take minimum length to avoid shape mismatch\n",
    "    min_len = min(len(true_bits_array), len(decided_bits_flat_array))\n",
    "    true_bits_array = true_bits_array[:min_len]\n",
    "    decided_bits_flat_array = decided_bits_flat_array[:min_len]\n",
    "\n",
    "    # Calculate BER\n",
    "    BER = float(np.sum(true_bits_array != decided_bits_flat_array) / len(true_bits_array))\n",
    "    return BER\n",
    "\n",
    "\n",
    "def train(encoder, decoder, optimizer, scheduler, config, device, mask=None):\n",
    "\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "\n",
    "        epoch_loss = 0\n",
    "        epoch_freq_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        batch_entries = []\n",
    "        true_bits_list = []\n",
    "        for batch in range(config[\"batch_size\"]):\n",
    "            # Generate frame data\n",
    "            true_bits = np.random.randint(0, 2, size=NUM_BITS)\n",
    "            true_bits_list.append(torch.tensor(true_bits))\n",
    "            # true_bits = np.zeros(NUM_BITS).astype(int)\n",
    "            true_bits_str = ''.join(map(str, true_bits))\n",
    "            true_symbols = torch.tensor(\n",
    "                constellation.bits_to_symbols(true_bits_str),\n",
    "                dtype=torch.complex64, device=device\n",
    "            )\n",
    "            true_frame = true_symbols.reshape(config[\"Nt\"], config[\"Nf\"])\n",
    "\n",
    "            # Add known experimental noise\n",
    "\n",
    "            # true_frame = torch.zeros(config[\"Nt\"], config[\"Nf\"])\n",
    "            # true_frame[:, 100] = 10\n",
    "\n",
    "            if POWER_NORMALIZATION:\n",
    "                true_frame = true_frame / true_frame.abs().pow(2).mean(dim=1, keepdim=True).sqrt()\n",
    "            batch_entries.append(true_frame)\n",
    "\n",
    "        true_bits = torch.stack(true_bits_list)\n",
    "\n",
    "        # Batch along time domain\n",
    "        true_frame = torch.cat(batch_entries)\n",
    "\n",
    "        # print(\"Inband symbol power\", true_frame.abs().square().mean())\n",
    "        # Convert to time domain\n",
    "        sent_frames_time = symbols_to_time(true_frame, UPSAMPLING_ZEROS, NUM_ZEROS)\n",
    "        sent_frames_time = torch.hstack((sent_frames_time[:, -CP_LENGTH:], sent_frames_time))\n",
    "\n",
    "        encoded_frames_time = encoder(sent_frames_time)\n",
    "        # encoded_frames_time = in_band_filter(encoded_frames_time, KS, NUM_POINTS_FRAME)\n",
    "\n",
    "        # Clip to preamble make\n",
    "        encoded_frames_time = torch.clip(encoded_frames_time, -PREAMBLE_MAX, PREAMBLE_MAX)\n",
    "        # encoded_frames_time = add_noise_time_cp(encoded_frames_time,\n",
    "        #                                              snr_in=float(100000),\n",
    "        #                                                 snr_low=float(100000),\n",
    "        #                                                snr_high=0,\n",
    "        #                                               inband_idx=torch.arange(int(1), int(25e6)),\n",
    "        #                                              cp_length=CP_LENGTH)\n",
    "\n",
    "        received_frames_time = channel_model.forward_simulate(encoded_frames_time)\n",
    "\n",
    "\n",
    "        # Filter out of band noise\n",
    "        # received_frames_time_noisy = in_band_filter(received_frames_time_noisy, KS, NUM_POINTS_FRAME)\n",
    "\n",
    "        # received_frames_time = add_noise(received_frames_time, SNR=10**(config[\"snr_db\"]/10))\n",
    "        decoded_frames_time = decoder(received_frames_time)\n",
    "\n",
    "        # Convert to frequency domain for loss\n",
    "        sent_frames_frequency = torch.tensor(rfft(sent_frames_time[:, CP_LENGTH:].detach().cpu().numpy(), norm='ortho', axis=1)[:, KS])\n",
    "        decoded_frames_frequency = torch.tensor(rfft(decoded_frames_time[:, CP_LENGTH:].detach().cpu().numpy(), norm='ortho', axis=1)[:, KS])\n",
    "\n",
    "        sent_norm = sent_frames_frequency.abs().square().mean(dim=1, keepdim=True).sqrt()\n",
    "        decoded_norm = decoded_frames_frequency.abs().square().mean(dim=1, keepdim=True).sqrt()\n",
    "\n",
    "\n",
    "        if POWER_NORMALIZATION:\n",
    "            sent_frames_frequency = sent_frames_frequency / sent_norm\n",
    "            decoded_frames_frequency = decoded_frames_frequency / decoded_norm\n",
    "\n",
    "\n",
    "        # print(\"Time power through channel\", sent_frames_time.abs().square().mean().item(), received_frames_time.abs().square().mean().item(), sent_frames_time.shape)\n",
    "        loss = in_band_time_loss(sent_frames_time, decoded_frames_time, ks_indices=KS, n_fft=NUM_POINTS_FRAME, num_taps=config['num_taps'])\n",
    "        # loss = evm_loss(sent_frames_time, decoded_frames_time)\n",
    "        diff_complex = sent_frames_frequency.detach() - decoded_frames_frequency.detach()\n",
    "        # print(\"evm shapes\", sent_frames_frequency.shape, decoded_frames_frequency.shape)\n",
    "        freq_loss = torch.mean(diff_complex.abs().pow(2))\n",
    "\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_freq_loss += freq_loss.item()\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step(epoch_loss)\n",
    "\n",
    "        wandb.log({\"loss\": epoch_loss}, step=epoch)\n",
    "        wandb.log({\"freq_loss\": epoch_freq_loss}, step=epoch)\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        wandb.log({\"learning_rate\": lr}, step=epoch)\n",
    "\n",
    "        # Get BER\n",
    "        ber = calculate_BER(decoded_frames_frequency.detach().flatten(), true_bits.flatten(), constellation=constellation)\n",
    "        wandb.log({\"BER\": ber}, step=epoch)\n",
    "        print(f\"Epoch {epoch} Finished | Avg Loss: {epoch_loss}\")\n",
    "        if epoch % 5 == 0:\n",
    "            make_time_validate_plots(\n",
    "            sent_frames_time[0],\n",
    "            received_frames_time[0],\n",
    "            decoded_frames_time[0],\n",
    "            frame_BER=ber,\n",
    "            run_model=True,\n",
    "            step=epoch\n",
    "            )\n",
    "\n",
    "            # Plot first example of sent and reconstructed time\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(sent_frames_time[0][:100].detach().cpu().numpy(), label=\"Sent (time)\")\n",
    "            ax.plot(decoded_frames_time[0][:100].detach().cpu().numpy(), label=\"Decoded (time)\")\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"Sent vs Decoded (Time Domain) EVM: {loss: 0.3e}\")\n",
    "            wandb.log({\"time_domain_plot\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "            sent_symbols = sent_frames_frequency[0].detach().cpu().numpy()\n",
    "            decoded_symbols = decoded_frames_frequency[0].detach().cpu().numpy()\n",
    "\n",
    "            # Compute EVM for logging (per frame)\n",
    "            evm_val = evm_loss(torch.tensor(sent_symbols), torch.tensor(decoded_symbols)).item()\n",
    "\n",
    "            # Create constellation plot\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.scatter(sent_symbols.real, sent_symbols.imag, color='blue', alpha=0.6, label='Sent')\n",
    "            ax.scatter(decoded_symbols.real, decoded_symbols.imag, color='red', alpha=0.6, label='Decoded')\n",
    "            ax.set_xlabel('In-phase')\n",
    "            ax.set_ylabel('Quadrature')\n",
    "            ax.set_title(f'Constellation Diagram EVM: {evm_val:0.3e}')\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "\n",
    "            # Log to wandb\n",
    "            wandb.log({\"constellation\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "            evm_per_freq = ((sent_frames_frequency[0] - decoded_frames_frequency[0]).abs()**2).detach().cpu().numpy()\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(evm_per_freq)\n",
    "            ax.set_title(\"EVM vs Frequency\")\n",
    "            wandb.log({\"evm_vs_freq\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "\n",
    "            # # Plot Model SNRs\n",
    "            # sent_k = torch.fft.fft(encoded_frames_time[:, CP_LENGTH:], norm=\"ortho\", dim=-1)\n",
    "            # received_k = torch.fft.fft(received_frames_time[:, CP_LENGTH:], norm=\"ortho\", dim=-1)\n",
    "\n",
    "            # residual = received_frames_time - mean\n",
    "            # received_noise_k = torch.fft.fft(residual[:, CP_LENGTH:] ** 2, norm=\"ortho\", dim=-1)\n",
    "\n",
    "\n",
    "            # signal_power = torch.mean(torch.abs(sent_k) ** 2, dim=0).detach().cpu().numpy()\n",
    "            # received_power = torch.mean(torch.abs(received_k) ** 2, dim=0).detach().cpu().numpy()\n",
    "            # received_noise_power = torch.mean(torch.abs(received_noise_k), dim=0).detach().cpu().numpy()\n",
    "            # snr_vs_freq = (received_power / received_noise_power + 1e-12)\n",
    "\n",
    "            # fig, ax = plt.subplots()\n",
    "            # ax.plot(10 * np.log10(signal_power[:len(signal_power)//2]))\n",
    "            # ax.axvline(30, c='r', linestyle='--')\n",
    "            # ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            # ax.set_title(f\"Encoded Signal Frequency Power Spectrum for {run.name}\")\n",
    "            # ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            # ax.set_ylabel(\"Power (dB)\")\n",
    "            # wandb.log({\"encoded_signal_power_spectrum\": wandb.Image(fig)}, step=epoch)\n",
    "            # plt.close(fig)\n",
    "\n",
    "            # fig, ax = plt.subplots()\n",
    "            # ax.plot(10 * np.log10(received_power[:len(received_power)//2]))\n",
    "            # ax.axvline(30, c='r', linestyle='--')\n",
    "            # ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            # ax.set_title(f\"Received Signal Frequency Power Spectrum for {run.name}\")\n",
    "            # ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            # ax.set_ylabel(\"Power (dB)\")\n",
    "            # wandb.log({\"received_signal_power_spectrum\": wandb.Image(fig)}, step=epoch)\n",
    "            # plt.close(fig)\n",
    "\n",
    "            # fig, ax = plt.subplots()\n",
    "            # ax.plot(10 * np.log10(snr_vs_freq[:len(snr_vs_freq)//2]))\n",
    "            # ax.set_title(f\"SNR vs Freq Estimate for {run.name}\")\n",
    "            # ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            # ax.set_ylabel(\"SNR (dB)\")\n",
    "            # ax.axvline(30, c='r', linestyle='--')\n",
    "            # ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            # wandb.log({\"snr_vs_freq\": wandb.Image(fig)}, step=epoch)\n",
    "            # plt.close(fig)\n",
    "\n",
    "            # fig, ax = plt.subplots()\n",
    "            # ax.plot(10 * np.log10(received_noise_power[:len(snr_vs_freq)//2]))\n",
    "            # ax.set_title(f\"Noise power vs Freq Estimate for {run.name}\")\n",
    "            # ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            # ax.set_ylabel(\"Power (dB)\")\n",
    "            # ax.axvline(30, c='r', linestyle='--')\n",
    "            # ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            # wandb.log({\"noise_power_vs_freq\": wandb.Image(fig)}, step=epoch)\n",
    "            # plt.close(fig)\n",
    "\n",
    "    # Save model\n",
    "    torch.save({\n",
    "        \"time_encoder\": encoder.state_dict(),\n",
    "        \"time_decoder\": decoder.state_dict()\n",
    "    }, \"time_autoencoder.pth\")\n",
    "\n",
    "    artifact = wandb.Artifact(\"time_autoencoder\", type=\"model\")\n",
    "    artifact.add_file(\"time_autoencoder.pth\")\n",
    "    wandb.log_artifact(artifact)\n",
    "\n",
    "    return epoch_loss\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "train(encoder, decoder, optimizer, scheduler, config, device)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SNR vs freq estimate\n",
    "test_freqs = torch.arange(0, 1e4 * 2999, 1e4, device=device)\n",
    "test_ks = (test_freqs / (1e4)).to(torch.int)\n",
    "true_bits = np.random.randint(0, 2, size=7 * len(test_freqs) * 100)\n",
    "\n",
    "\n",
    "true_bits_str = ''.join(map(str, true_bits))\n",
    "true_symbols = torch.tensor(\n",
    "    constellation.bits_to_symbols(true_bits_str),\n",
    "    dtype=torch.complex64, device=device\n",
    ")\n",
    "\n",
    "test = (NUM_POINTS_FRAME  +  -2 * test_ks[0] + -2 * len(test_ks)) // 2\n",
    "\n",
    "true_frame = true_symbols.reshape(100, 2999)\n",
    "true_bits = torch.tensor(true_bits)\n",
    "sent_frames_time = symbols_to_time(true_frame, test, 0)\n",
    "sent_frames_time = torch.hstack((sent_frames_time[:, -CP_LENGTH:], sent_frames_time))\n",
    "encoded_frames_time = encoder(sent_frames_time)\n",
    "received_frames_time_noisy, mean, std, nu = channel_model(encoded_frames_time)\n",
    "decoded_frames_time = decoder(received_frames_time_noisy)\n",
    "\n",
    "sent_k = torch.fft.fft(encoded_frames_time[:, CP_LENGTH:], norm=\"ortho\", dim=-1)\n",
    "received_k = torch.fft.fft(mean[:, CP_LENGTH:], norm=\"ortho\", dim=-1)\n",
    "\n",
    "residual = received_frames_time_noisy - mean\n",
    "received_noise_k = torch.fft.fft(residual[:, CP_LENGTH:] ** 2, norm=\"ortho\", dim=-1)\n",
    "\n",
    "\n",
    "signal_power = torch.mean(torch.abs(sent_k) ** 2, dim=0).detach().cpu().numpy()\n",
    "received_power = torch.mean(torch.abs(received_k) ** 2, dim=0).detach().cpu().numpy()\n",
    "received_noise_power = torch.mean(torch.abs(received_noise_k), dim=0).detach().cpu().numpy()\n",
    "snr_vs_freq = (received_power / received_noise_power + 1e-12)\n",
    "\n",
    "\n",
    "plt.plot(10 * np.log10(signal_power[:len(signal_power)//2]))\n",
    "plt.axvline(30, c='r', linestyle='--')\n",
    "plt.axvline(int(4e2), c='r', linestyle='--')\n",
    "plt.title(f\"Encoded Signal Frequency Power Spectrum for {run.name}\")\n",
    "plt.xlabel(\"Freq Index k (10 kHz)\")\n",
    "plt.ylabel(\"Power (dB)\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(10 * np.log10(received_power[:len(received_power)//2]))\n",
    "plt.axvline(30, c='r', linestyle='--')\n",
    "plt.axvline(int(4e2), c='r', linestyle='--')\n",
    "plt.title(f\"Received Signal Frequency Power Spectrum for {run.name}\")\n",
    "plt.xlabel(\"Freq Index k (10 kHz)\")\n",
    "plt.ylabel(\"Power (dB)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(10 * np.log10(snr_vs_freq[:len(snr_vs_freq)//2]))\n",
    "plt.title(f\"SNR vs Freq Estimate for {run.name}\")\n",
    "plt.xlabel(\"Freq Index k (10 kHz)\")\n",
    "plt.ylabel(\"SNR (dB)\")\n",
    "plt.axvline(30, c='r', linestyle='--')\n",
    "plt.axvline(int(4e2), c='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(10 * np.log10(received_noise_power[30:len(snr_vs_freq)//2]))\n",
    "plt.title(f\"Noise power vs Freq Estimate for {run.name}\")\n",
    "plt.xlabel(\"Freq Index k (10 kHz)\")\n",
    "plt.ylabel(\"Power (dB)\")\n",
    "plt.axvline(30, c='r', linestyle='--')\n",
    "plt.axvline(int(4e2), c='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, tag):\n",
    "    # Sample hyperparameters\n",
    "    dilation_base = trial.suggest_categorical(\"dilation_base\", [2])\n",
    "    num_taps = trial.suggest_int(\"num_taps\", 10, 30, step=2)\n",
    "    hidden_channels = trial.suggest_int(\"hidden_channels\", 4, 64, step=8)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2)\n",
    "    nlayers = trial.suggest_categorical(\"nlayers\", [2, 3, 4])\n",
    "\n",
    "    local_config = {\n",
    "        \"dilation_base\": dilation_base,\n",
    "        \"num_taps\": num_taps,\n",
    "        \"hidden_channels\": hidden_channels,\n",
    "        \"lr\": lr,\n",
    "        \"epochs\": 800,\n",
    "        \"batch_size\": 16,\n",
    "        \"Nt\": 1,\n",
    "        \"Nf\": 370,\n",
    "        \"save_path\": \"./saved_models\",\n",
    "        \"nlayers\": nlayers,\n",
    "        \"weight_init\": \"default\",\n",
    "        \"scheduler_type\": \"reduce_lr_on_plateu\",\n",
    "        \"modulator\": f\"{constellation_mode}\"\n",
    "    }\n",
    "\n",
    "    wandb.init(project=\"mldrivenpeled\", config=local_config, reinit=True,\n",
    "               tags=['autoencoder', f'{tag}', f'trial {trial.number}'], mode='online')\n",
    "\n",
    "    wandb.run.notes = f\"\\n | trained on channel model {run_name} \\n | {constellation_mode}\"\n",
    "\n",
    "    encoder = None\n",
    "    decoder = None\n",
    "    optimizer = None\n",
    "    scheduler = None\n",
    "\n",
    "    try:\n",
    "        encoder = TCN(\n",
    "            nlayers=nlayers,\n",
    "            dilation_base=dilation_base,\n",
    "            num_taps=num_taps,\n",
    "            hidden_channels=hidden_channels\n",
    "        ).to(device)\n",
    "\n",
    "        decoder = TCN(\n",
    "            nlayers=nlayers,\n",
    "            dilation_base=dilation_base,\n",
    "            num_taps=num_taps,\n",
    "            hidden_channels=hidden_channels\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(\n",
    "            list(encoder.parameters()) + list(decoder.parameters()), lr=lr\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "\n",
    "        final_loss = train(encoder, decoder, optimizer, scheduler, local_config, device)\n",
    "\n",
    "        return final_loss\n",
    "\n",
    "    finally:\n",
    "        wandb.finish()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        del encoder, decoder, optimizer, scheduler\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7232b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "study_name = f\"optuna_offline_ae_model_{timestamp}\"\n",
    "# study_name= \"optuna_offline_ae_model_20250919_174002\"\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=study_name, storage=\"sqlite:///optuna_results.db\", load_if_exists=True)\n",
    "study.optimize(lambda trial: objective(trial, study_name), n_trials=100)\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)\n",
    "\n",
    "'''\n",
    "{'dilation_base': 2, 'num_taps': 12, 'hidden_channels': 20, 'lr': 0.0005269745303114973, 'nlayers': 4, 'taps': 20} Current best with loss 2e-3\n",
    "Trial 44 finished with value: 0.001965869450941682 and parameters: {'dilation_base': 2, 'num_taps': 10, 'hidden_channels': 44, 'lr': 0.009314226151764216, 'nlayers': 4}. Best is trial 44 with value: 0.001965869450941682\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3987779",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = \"sqlite:///optuna_results.db\"\n",
    "summaries = optuna.get_all_study_summaries(storage=storage)\n",
    "for summary in summaries:\n",
    "    print(f\"Study name: {summary.study_name}\")\n",
    "    print(f\"  Trial count: {summary.n_trials}\")\n",
    "    if summary.best_trial is not None:\n",
    "        print(f\"  Best value: {summary.best_trial.value}\")\n",
    "        print(f\"  Best params: {summary.best_trial.params}\")\n",
    "    else:\n",
    "        print(\"  No trials completed yet.\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90307804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    "    plot_slice,\n",
    "    plot_parallel_coordinate\n",
    ")\n",
    "\n",
    "# Step 1: Choose your study name (copy it from the summaries you printed earlier)\n",
    "study_name = \"optuna_offline_ae_model_20250928_115643\"\n",
    "storage = \"sqlite:///optuna_results.db\"\n",
    "\n",
    "# Step 2: Load the study\n",
    "study = optuna.load_study(study_name=study_name, storage=storage)\n",
    "\n",
    "# Step 3: Plot using interactive Plotly charts\n",
    "plot_optimization_history(study).show()\n",
    "plot_param_importances(study).show()\n",
    "plot_slice(study).show()\n",
    "plot_parallel_coordinate(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcb5c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f19e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc26e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldrivenpeled2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
