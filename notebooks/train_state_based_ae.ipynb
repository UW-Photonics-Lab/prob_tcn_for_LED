{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46ccdd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maild\\miniconda3\\envs\\mldrivenpeled\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from scipy.fft import irfft, rfft\n",
    "import gc\n",
    "import time\n",
    "sys.path.append(os.path.abspath(\"../lab_scripts\"))\n",
    "from constellation_diagram import QPSK_Constellation\n",
    "from constellation_diagram import RingShapedConstellation\n",
    "\n",
    "if wandb.run is not None:\n",
    "    wandb.run.tags = list(wandb.run.tags) + [\"junk\"]\n",
    "wandb.finish()\n",
    "NUM_POINTS_FRAME = 6000\n",
    "# NUM_POINTS_FRAME = 3040\n",
    "CP_LENGTH = 2000\n",
    "# CP_LENGTH = 1013\n",
    "NUM_POINTS_SYMBOL = NUM_POINTS_FRAME + CP_LENGTH\n",
    "POWER_NORMALIZATION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688026f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel Run name: earnest-bee-7750\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "run = api.run(\"dylanbackprops-university-of-washington/mldrivenpeled/1zfa43s4\") # Variable\n",
    "model_name = \"channel_model_final\"\n",
    "artifact = api.artifact(\"dylanbackprops-university-of-washington/mldrivenpeled/channel_model:v1943\") # Variable\n",
    "artifact_dir = artifact.download()\n",
    "remote_config = run.config\n",
    "run_name = run.name\n",
    "print(\"Channel Run name:\", run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac2c30fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nf': 1499,\n",
       " 'Nt': 1,\n",
       " 'lr': 0.001,\n",
       " 'wd': 0.001,\n",
       " 'flow': 300000,\n",
       " 'gain': 20,\n",
       " 'fhigh': '15e6',\n",
       " 'ar_taps': 0,\n",
       " 'fnyquist': '30e6',\n",
       " 'num_taps': 10,\n",
       " 'dc_offset': 3.5,\n",
       " 'batch_size': 32,\n",
       " 'state_size': 8,\n",
       " 'grid_run_id': 'grid_20251202_103823',\n",
       " 'hidden_size': 8,\n",
       " 'linear_fast': False,\n",
       " 'weight_init': 'default',\n",
       " 'dilation_base': 2,\n",
       " 'scheduler_type': 'reduce_lr_on_plateu',\n",
       " 'detach_residuals': False,\n",
       " 'training_schedule': [{'mode': 'normal', 'epochs': 10}],\n",
       " 'subcarrier_spacing': '1e4'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7eea4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of artifact_dir: ['channel_model_final.pth']\n"
     ]
    }
   ],
   "source": [
    "print(\"Contents of artifact_dir:\", os.listdir(artifact_dir))\n",
    "# Set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\") # for M chip Macs\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8add790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_last_layer(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.zeros_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "class StateSpaceModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 deterministic_num_taps,\n",
    "                 deterministic_state_size,\n",
    "                 deterministic_hidden_size,\n",
    "                 stochastic_state_size,\n",
    "                 stochastic_hidden_size\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.deterministic_state_size = deterministic_state_size\n",
    "        self.stochastic_state_size = stochastic_state_size\n",
    "        self.deterministic_num_taps = deterministic_num_taps\n",
    "        self.deterministic_state_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(deterministic_hidden_size, deterministic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(deterministic_hidden_size, deterministic_state_size)\n",
    "        )\n",
    "        self.deterministic_out_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(deterministic_hidden_size, 1) # Predict next scalar ouptut\n",
    "        )\n",
    "        self.stochastic_state_map = nn.Sequential(\n",
    "            nn.Linear(stochastic_state_size + deterministic_num_taps + 1, stochastic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(stochastic_hidden_size, stochastic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(stochastic_hidden_size, stochastic_state_size)\n",
    "        )\n",
    "        self.stochastic_out_map = nn.Sequential(\n",
    "            nn.Linear(deterministic_num_taps + stochastic_state_size + deterministic_state_size, stochastic_hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(stochastic_hidden_size, 1)\n",
    "        )\n",
    "        self.linear_det_out_map = nn.Linear(deterministic_num_taps + deterministic_state_size, 1)\n",
    "        self.linear_det_state_map = nn.Linear(deterministic_num_taps + deterministic_state_size, deterministic_state_size)\n",
    "        self.linear_stoch_state_map = nn.Linear(stochastic_state_size + deterministic_num_taps + 1, stochastic_state_size)\n",
    "        self.linear_stoch_out_map = nn.Linear(deterministic_num_taps + stochastic_state_size + deterministic_state_size, 1)\n",
    "\n",
    "        self.n0 = nn.Parameter(torch.zeros(deterministic_state_size))\n",
    "        self.z0 = nn.Parameter(torch.zeros(stochastic_state_size))\n",
    "\n",
    "        # Make it so that the stochastic output starts at zero\n",
    "        self.deterministic_state_map[-1].apply(zero_last_layer)\n",
    "        self.deterministic_out_map[-1].apply(zero_last_layer)\n",
    "        self.stochastic_state_map[-1].apply(zero_last_layer)\n",
    "        self.stochastic_out_map[-1].apply(zero_last_layer)\n",
    "        self.mode = \"nonlinear\"\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        mode = self.mode\n",
    "        device = x.device\n",
    "        y_pred = torch.zeros_like(x, device=device)\n",
    "        e_pred = torch.zeros_like(x, device=device)\n",
    "        T = x.size(-1)\n",
    "        B = x.size(0)\n",
    "        # n_t = torch.zeros(B, self.deterministic_state_size, device=device)\n",
    "        # z_t = torch.zeros(B, self.stochastic_state_size, device=device)\n",
    "        n_t = self.n0.unsqueeze(0).expand(B, -1)  # [B, nx]\n",
    "        z_t = self.z0.unsqueeze(0).expand(B, -1)  # [B, nz]\n",
    "        # add zeros in front equal to num_taps - 1\n",
    "        x = torch.cat([torch.zeros(B, self.deterministic_num_taps - 1, device=device), x], dim=-1)\n",
    "        for t in range(T):\n",
    "            x_t = x[:, t: t + self.deterministic_num_taps]\n",
    "\n",
    "            if mode == \"linear\":\n",
    "                y_t_pred = self.linear_det_out_map(torch.cat([x_t, n_t], dim=-1))\n",
    "            else:\n",
    "                y_t_pred = self.deterministic_out_map(torch.cat([x_t, n_t], dim=-1)) + self.linear_det_out_map(torch.cat([x_t, n_t], dim=-1))\n",
    "\n",
    "            if y is None:\n",
    "                '''INFERENCE MODE'''\n",
    "                y_pred[:, t] = y_t_pred.squeeze(-1)\n",
    "                # Assume residuals are an innovation process with zero mean\n",
    "                if mode == \"linear\":\n",
    "                    n_t = n_t + self.linear_det_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "                else:\n",
    "                    n_t = n_t + self.deterministic_state_map(torch.cat([x_t, n_t], dim=-1)) + self.linear_det_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "\n",
    "            else:\n",
    "                '''TRAINING MODE'''\n",
    "                # Training mode\n",
    "                y_t = y[:, t]\n",
    "                r_t = y_t.unsqueeze(-1) - y_t_pred\n",
    "\n",
    "                if mode == \"linear\":\n",
    "                    nonlinear_noise_t = self.linear_stoch_out_map(torch.cat([x_t, n_t, z_t], dim=-1))\n",
    "                else:\n",
    "                    nonlinear_noise_t = self.stochastic_out_map(torch.cat([x_t, n_t, z_t], dim=-1)) + self.linear_stoch_out_map(torch.cat([x_t, n_t, z_t], dim=-1))\n",
    "                y_t_next_pred = y_t_pred + nonlinear_noise_t\n",
    "                y_pred[:, t] = y_t_next_pred.squeeze(-1)\n",
    "                e_t = r_t - nonlinear_noise_t\n",
    "                e_pred[:, t] = e_t.squeeze(-1)\n",
    "                # Make state updates\n",
    "\n",
    "                if mode == \"linear\":\n",
    "                    z_t = z_t + self.linear_stoch_state_map(torch.cat([x_t, z_t, r_t], dim=-1))\n",
    "                    n_t = n_t + self.linear_det_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "                else:\n",
    "                    z_t = z_t + self.stochastic_state_map(torch.cat([x_t, z_t, r_t], dim=-1)) + self.linear_stoch_state_map(torch.cat([x_t, z_t, r_t], dim=-1))\n",
    "                    n_t = n_t + self.deterministic_state_map(torch.cat([x_t, n_t], dim=-1)) + self.linear_det_state_map(torch.cat([x_t, n_t], dim=-1)) # [B, nx + num_taps]\n",
    "        return y_pred, e_pred\n",
    "\n",
    "\n",
    "class TCNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            dilation=dilation,\n",
    "            padding=0\n",
    "        )\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        self.SiLU = nn.SiLU()\n",
    "        self.resample = None\n",
    "        if in_channels != out_channels:\n",
    "            self.resample = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.pad(x, (self.padding, 0))\n",
    "        out = self.conv(out)\n",
    "        out = self.SiLU(out)\n",
    "        if out.size(2) > x.size(2):\n",
    "            out = out[:, :, :x.size(2)]\n",
    "        if self.resample:\n",
    "            x = self.resample(x)\n",
    "        return out + x  # residual connection\n",
    "\n",
    "\n",
    "def sample_student_t_mps(mean, std, nu):\n",
    "    '''\n",
    "    Wilson-Hilferty Approximation for chi^2 converted to scaled and shifted student t\n",
    "    '''\n",
    "    z = torch.randn_like(mean)\n",
    "    z_chi = torch.randn_like(mean)\n",
    "    chi2_approx = nu * (1 - 2/(9*nu) + z_chi * torch.sqrt(2/(9*nu))).pow(3)\n",
    "    chi2_approx = chi2_approx.clamp(min=0.01)\n",
    "    scale = torch.sqrt(nu / chi2_approx)\n",
    "    return mean + std * z * scale\n",
    "\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, nlayers=3, dilation_base=2, num_taps=10, hidden_channels=32):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "        for i in range(nlayers):\n",
    "            dilation = dilation_base ** i\n",
    "            layers.append(\n",
    "                TCNBlock(in_channels, hidden_channels, num_taps, dilation)\n",
    "            )\n",
    "            in_channels = hidden_channels\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        self.readout = nn.Conv1d(hidden_channels, 1, kernel_size=1)\n",
    "\n",
    "        # Calculate the total receptive field for the whole TCN stack\n",
    "        self.receptive_field = 1\n",
    "        for i in range(nlayers):\n",
    "            dilation = dilation_base ** i\n",
    "            self.receptive_field += (num_taps - 1) * dilation\n",
    "\n",
    "    def forward(self, xin):\n",
    "        x = xin.unsqueeze(1)    # [B,1,T]\n",
    "        out = self.tcn(x)     # [B,H,T]\n",
    "        out = self.readout(out).squeeze(1)\n",
    "        out = out - out.mean(dim=1, keepdim=True)  # [B,T]\n",
    "        return out\n",
    "\n",
    "\n",
    "class TCN_channel(nn.Module):\n",
    "    def __init__(self, nlayers=3, dilation_base=2, num_taps=10, hidden_channels=32, learn_noise=False, gaussian=True):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "        for i in range(nlayers):\n",
    "            dilation = dilation_base ** i\n",
    "            layers.append(\n",
    "                TCNBlock(in_channels, hidden_channels, num_taps, dilation)\n",
    "            )\n",
    "            in_channels = hidden_channels\n",
    "        self.learn_noise = learn_noise\n",
    "        self.tcn = nn.Sequential(*layers)\n",
    "        if gaussian:\n",
    "            self.readout = nn.Conv1d(hidden_channels, 2, kernel_size=1) # 2 channels mean | std\n",
    "        else:\n",
    "            self.readout = nn.Conv1d(hidden_channels, 3, kernel_size=1) # 3 channels mean | std | nu\n",
    "        self.num_taps = num_taps\n",
    "        self.gaussian = gaussian\n",
    "\n",
    "        if not gaussian:\n",
    "            with torch.no_grad():\n",
    "                # Initialize log_nu bias\n",
    "                self.readout.bias[2].fill_(48)\n",
    "\n",
    "    def forward(self, xin):\n",
    "        x = xin.unsqueeze(1)    # [B,1,T]\n",
    "        out = self.tcn(x)     # [B,H,T]\n",
    "        out = self.readout(out) # [B, 3, T] mean | std | nu\n",
    "        mean_out = out[:, 0, :]\n",
    "        log_std_out = out[:, 1, :]\n",
    "        std_out = torch.exp(log_std_out)\n",
    "        if not self.gaussian:\n",
    "            log_nu_out = out[:, 2, :]\n",
    "            nu_out = torch.nn.functional.softplus(log_nu_out)\n",
    "            nu_out = torch.clamp(nu_out, 2, 50) # nu between 2 and 50\n",
    "        mean_out = mean_out - mean_out.mean(dim=1, keepdim=True)  # [B ,T]\n",
    "\n",
    "        # # Produce noisy output\n",
    "        if self.gaussian:\n",
    "            z = torch.randn_like(mean_out)\n",
    "            noisy_out = mean_out + std_out * z\n",
    "            nu_out = torch.zeros_like(mean_out)\n",
    "        else:\n",
    "            noisy_out = sample_student_t_mps(mean_out, std_out, nu_out)\n",
    "        if self.learn_noise:\n",
    "            return noisy_out, mean_out, std_out, nu_out\n",
    "        else:\n",
    "            return mean_out, mean_out, torch.zeros_like(mean_out)\n",
    "\n",
    "class ProbabilisticStateSpaceModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_taps,\n",
    "                 state_size,\n",
    "                 hidden_size,\n",
    "                 ar_taps,\n",
    "                 detach_residuals=True,\n",
    "                 linear_fast=True\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.state_size = state_size\n",
    "        self.num_taps = num_taps\n",
    "        self.linear_fast = linear_fast\n",
    "        self.detach_residuals = detach_residuals\n",
    "        self.state_map = nn.Sequential(\n",
    "            nn.Linear(num_taps + state_size, hidden_size),\n",
    "            # nn.SiLU(),\n",
    "            # nn.Linear(hidden_size, hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, state_size)\n",
    "        )\n",
    "        self.state_out_map = nn.Sequential(\n",
    "            nn.Linear(num_taps + state_size, hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, 2 + ar_taps) # Predict mean and std\n",
    "        )\n",
    "        if linear_fast:\n",
    "            self.fast_feedthrough = nn.Linear(num_taps, 1, bias=False)\n",
    "        else:\n",
    "            self.fast_feedthrough = nn.Sequential(\n",
    "                nn.Linear(num_taps, hidden_size, bias=False),\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(hidden_size, 1, bias=False)\n",
    "            )\n",
    "        # nn.init.zeros_(self.fast_feedthrough.weight)\n",
    "        # nn.init.zeros_(self.fast_feedthrough.weight)\n",
    "        self.n0 = nn.Parameter(torch.zeros(state_size))\n",
    "        # self.alpha = nn.Parameter(torch.tensor(0.5))\n",
    "        self.alpha = nn.Parameter(torch.tensor(3 * torch.randn(state_size)))\n",
    "        # self.state_map[-1].apply(zero_last_layer)\n",
    "        # self.state_out_map[-1].apply(zero_last_layer)\n",
    "        self.ar_coeffs = nn.Parameter(torch.zeros(ar_taps))\n",
    "        self.ar_taps = ar_taps\n",
    "\n",
    "    def _whiten(self, x, ar_preds):\n",
    "        out = torch.zeros_like(x)\n",
    "        for t in range(x.size(-1)):\n",
    "            x_whitened_t = x[:, t]\n",
    "            for i in range(self.ar_taps):\n",
    "                j = t - (i + 1)\n",
    "                if j >= 0: # Enforce boundary\n",
    "                #   x_whitened_t = x_whitened_t - nn.Tanh(ar_preds[i]) * x[:, j]\n",
    "                    if self.detach_residuals:\n",
    "                        x_whitened_t = x_whitened_t - ar_preds[:, t, i] * x[:, j].detach()\n",
    "                    else:\n",
    "                        x_whitened_t = x_whitened_t - ar_preds[:, t, i] * x[:, j] # Remove the possibility of cheating by spiking previous errors\n",
    "            out[:, t] = x_whitened_t\n",
    "        return out\n",
    "\n",
    "    def _step(self, xt, nt):\n",
    "        inp = torch.cat([xt, nt], dim=-1)\n",
    "        out = self.state_out_map(inp)\n",
    "        y_pred = out[:, 0]\n",
    "        y_fast = self.fast_feedthrough(xt).squeeze(-1)\n",
    "        # y_fast_sq = self.fast_square(xt ** 2).squeeze(-1)\n",
    "        y_pred = y_pred + y_fast\n",
    "        std_pred = F.softplus(out[:, 1]) + 1e-4\n",
    "        ar_preds = F.tanh(out[:, 2:])\n",
    "        delta_n = self.state_map(inp)\n",
    "        alpha = torch.sigmoid(self.alpha)\n",
    "        nt_next = (1.0 - alpha) * nt + delta_n\n",
    "        return y_pred, std_pred, ar_preds, nt_next\n",
    "\n",
    "    def forward_train(self, x, y):\n",
    "        device = x.device\n",
    "        T = x.size(-1)\n",
    "        B = x.size(0)\n",
    "        y_pred = torch.zeros(B, T, device=device)\n",
    "        std_pred = torch.zeros(B, T, device=device)\n",
    "        residuals = torch.zeros(B, T, device=device)\n",
    "        ar_preds = torch.zeros(B, T, self.ar_taps, device=device)\n",
    "        nt = self.n0.unsqueeze(0).repeat(B, 1).clone()  # [B, nx]\n",
    "        # add zeros in front equal to num_taps - 1\n",
    "        x = torch.cat([torch.zeros(B, self.num_taps - 1, device=device), x], dim=-1)\n",
    "\n",
    "        for t in range(T):\n",
    "            xt = x[:, t: t + self.num_taps]\n",
    "            y_pred_t, std_pred_t, ar_preds_t, nt = self._step(xt, nt)\n",
    "            y_pred[:, t] = y_pred_t\n",
    "\n",
    "            # get residuals\n",
    "            r_t = (y[:, t] - y_pred_t)\n",
    "            residuals[:, t] = r_t #\n",
    "            std_pred[:, t] = std_pred_t\n",
    "            ar_preds[:, t, :] = ar_preds_t\n",
    "\n",
    "        # whiten the innovations\n",
    "        innovations = self._whiten(residuals, ar_preds)\n",
    "        return y_pred, std_pred, innovations\n",
    "\n",
    "\n",
    "    def forward_simulate(self, x, eps=None):\n",
    "        device = x.device\n",
    "        T = x.size(-1)\n",
    "        B = x.size(0)\n",
    "        y_pred = torch.zeros(B, T, device=device)\n",
    "        if eps is None:\n",
    "            eps = torch.randn(B, T, device=device)\n",
    "        residuals = []\n",
    "        x = torch.cat([torch.zeros(B, self.num_taps - 1, device=device), x], dim=-1)\n",
    "        n_t = self.n0.unsqueeze(0).repeat(B, 1).clone()\n",
    "        for t in range(T):\n",
    "            max_lag = min(self.ar_taps, t)\n",
    "            xt = x[:, t: t + self.num_taps]\n",
    "            y_pred_t, std_pred_t, ar_preds, n_t = self._step(xt, n_t)\n",
    "            if max_lag > 0:\n",
    "                past_resids = torch.stack(residuals[-max_lag:], dim=0) # [max_lag, B]\n",
    "                past_resids = past_resids.transpose(0, 1) # [B, max_lag]\n",
    "                past_resids = past_resids.flip(dims=[1]) # Flip so that first residual is closest in time\n",
    "                ar_component = torch.sum(ar_preds[:, :max_lag] * past_resids, dim=1) # [B, max_lag] * [B, max_lag]\n",
    "            else:\n",
    "                ar_component = torch.zeros(B, device=device)\n",
    "\n",
    "            r_t = ar_component + std_pred_t * eps[:, t]\n",
    "            residuals.append(r_t)\n",
    "            y_pred[:, t] = y_pred_t + r_t\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be83bd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel model parameters frozen: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maild\\AppData\\Local\\Temp\\ipykernel_14764\\624795791.py:268: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.alpha = nn.Parameter(torch.tensor(3 * torch.randn(state_size)))\n",
      "C:\\Users\\maild\\AppData\\Local\\Temp\\ipykernel_14764\\1104233139.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(channel_model_path)\n"
     ]
    }
   ],
   "source": [
    "# channel_model = StateSpaceModel(\n",
    "#     deterministic_num_taps=remote_config['deterministic_num_taps'],\n",
    "#     deterministic_state_size=remote_config['deterministic_state_size'],\n",
    "#     deterministic_hidden_size=remote_config['deterministic_hidden_size'],\n",
    "#     stochastic_state_size=remote_config['stochastic_state_size'],\n",
    "#     stochastic_hidden_size=remote_config['stochastic_hidden_size']\n",
    "# )\n",
    "\n",
    "channel_model = ProbabilisticStateSpaceModel(\n",
    "    num_taps = remote_config[\"num_taps\"],\n",
    "    state_size = remote_config[\"state_size\"],\n",
    "    hidden_size = remote_config[\"hidden_size\"],\n",
    "    ar_taps = remote_config[\"ar_taps\"],\n",
    "    detach_residuals = remote_config[\"detach_residuals\"],\n",
    "    linear_fast = remote_config[\"linear_fast\"]\n",
    ")\n",
    "\n",
    "channel_model_path = os.path.join(artifact_dir, model_name + \".pth\")\n",
    "checkpoint = torch.load(channel_model_path)\n",
    "channel_model.load_state_dict(checkpoint[\"channel_model\"])\n",
    "\n",
    "# Freeze before moving to device\n",
    "for param in channel_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "channel_model = channel_model.to(device).float()\n",
    "channel_model.eval()\n",
    "\n",
    "print(\"Channel model parameters frozen:\",\n",
    "      all(not param.requires_grad for param in channel_model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bca40a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "constellation_mode = \"m7_apsk_constellation\"\n",
    "\n",
    "def get_constellation(mode: str):\n",
    "        if mode == \"qpsk\":\n",
    "            constellation = QPSK_Constellation()\n",
    "        elif mode == \"m5_apsk_constellation\":\n",
    "            constellation = RingShapedConstellation(filename=r'/Users/dylanjones/Desktop/mldrivenpeled/lab_scripts/saved_constellations/m5_apsk_constellation.npy')\n",
    "        elif mode == \"m6_apsk_constellation\":\n",
    "             constellation = RingShapedConstellation(filename=r'/Users/dylanjones/Desktop/mldrivenpeled/lab_scripts/saved_constellations/m6_apsk_constellation.npy')\n",
    "        elif mode == \"m7_apsk_constellation\":\n",
    "             # /Users/dylanjones/Desktop/mldrivenpeled/lab_scripts/saved_constellations/m7_apsk_constellation.npy\n",
    "             # C:\\Users\\maild\\mldrivenpeled\\lab_scripts\\saved_constellations\\m7_apsk_constellation.npy\n",
    "             constellation = RingShapedConstellation(filename=r'C:\\Users\\maild\\mldrivenpeled\\lab_scripts\\saved_constellations\\m7_apsk_constellation.npy')\n",
    "        return constellation\n",
    "\n",
    "constellation = get_constellation(constellation_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "727b880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdylanbackprops\u001b[0m (\u001b[33mdylanbackprops-university-of-washington\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\maild\\mldrivenpeled\\notebooks\\wandb\\run-20251202_104442-grppk2fb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/grppk2fb' target=\"_blank\">sleek-bee-7752</a></strong> to <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/grppk2fb' target=\"_blank\">https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/grppk2fb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB run info:\n",
      "  Name: sleek-bee-7752\n",
      "  ID: grppk2fb\n",
      "  URL: https://wandb.ai/dylanbackprops-university-of-washington/mldrivenpeled/runs/grppk2fb\n",
      "Chosen hyperparameters for this session:\n",
      "{'CP_ratio': 0.25, 'batch_size': 16, 'dc_offset': 0, 'num_taps': 10, 'epochs': 300, 'gain': 20, 'lr': 0.001, 'nlayers': 2, 'hidden_channels': 16, 'dilation_base': 2, 'preamble_amplitude': 3, 'num_symbols_per_frame': 1, 'scheduler_type': 'reduce_lr_on_plateu', 'weight_init': 'default', 'Nf': 370, 'Nt': 1, 'flow': 300000, 'fhigh': '4e6', 'subcarrier_spacing': '1e4', 'modulator': 'm7_apsk_constellation'}\n"
     ]
    }
   ],
   "source": [
    "script_dir = os.getcwd()\n",
    "config_path = os.path.join(script_dir, \"..\", \"offline_time_ae_config.yml\")\n",
    "with open(config_path, \"r\") as f:\n",
    "    hyperparams = yaml.safe_load(f)\n",
    "\n",
    "    wandb.init(project=\"mldrivenpeled\",\n",
    "            config=hyperparams,\n",
    "            tags=['autoencoder'])\n",
    "    config = wandb.config\n",
    "    if wandb.run.notes is None:\n",
    "        wandb.run.notes = \"\"\n",
    "    config.modulator = constellation_mode\n",
    "    wandb.run.notes += wandb.run.notes + f\"\\n | trained on channel model {run_name} \\n | {constellation_mode}\"\n",
    "    print(f\"WandB run info:\")\n",
    "    print(f\"  Name: {wandb.run.name}\")\n",
    "    print(f\"  ID: {wandb.run.id}\")\n",
    "    print(f\"  URL: {wandb.run.url}\")\n",
    "    print(\"Chosen hyperparameters for this session:\")\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f73f372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TCN(\n",
    "    nlayers=config.nlayers,\n",
    "    dilation_base=config.dilation_base,\n",
    "    num_taps=config.num_taps,\n",
    "    hidden_channels=config.hidden_channels,\n",
    ").to(device)\n",
    "\n",
    "decoder = TCN(\n",
    "    nlayers=config.nlayers,\n",
    "    dilation_base=config.dilation_base,\n",
    "    num_taps=config.num_taps,\n",
    "    hidden_channels=config.hidden_channels\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f581d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=config.lr, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec7549ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2600"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_BITS = config.Nt * config.Nf * constellation.modulation_order\n",
    "FREQUENCIES = torch.arange(float(config.flow), float(config.fhigh), float(config.subcarrier_spacing))\n",
    "delta_f = FREQUENCIES[1] - FREQUENCIES[0]\n",
    "KS = (FREQUENCIES / delta_f).to(torch.int)\n",
    "K_MIN = int(KS[0].item())\n",
    "K_MAX = int(KS[-1].item())\n",
    "NUM_ZEROS = K_MIN - 1\n",
    "UPSAMPLING_ZEROS= (NUM_POINTS_FRAME  +  -2 * K_MIN + -2 * len(KS)) // 2\n",
    "PREAMBLE_MAX = config.preamble_amplitude\n",
    "UPSAMPLING_ZEROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db9546e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2590"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_BITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "435f914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_time_validate_plots(sent_frames_time, received_frames_time, decoded_frames_time,\n",
    "                             frame_BER, run_model, step=0, zoom_samples=200):\n",
    "\n",
    "    # Convert to numpy\n",
    "    enc_in = sent_frames_time.detach().cpu().numpy().flatten()\n",
    "    enc_out = received_frames_time.detach().cpu().numpy().flatten()\n",
    "    dec_in = received_frames_time.detach().cpu().numpy().flatten()\n",
    "    dec_out = decoded_frames_time.detach().cpu().numpy().flatten()\n",
    "\n",
    "    # Power and scaling\n",
    "    enc_power_in = np.mean(enc_in**2)\n",
    "    enc_power_out = np.mean(enc_out**2)\n",
    "    enc_scale = enc_power_out / (enc_power_in + 1e-12)\n",
    "\n",
    "    dec_power_in = np.mean(dec_in**2)\n",
    "    dec_power_out = np.mean(dec_out**2)\n",
    "    dec_scale = dec_power_out / (dec_power_in + 1e-12)\n",
    "\n",
    "    # MSEs\n",
    "    mse_encoder = np.mean((enc_in - enc_out) ** 2)\n",
    "    mse_decoder = np.mean((dec_in - dec_out) ** 2)\n",
    "    mse_total = np.mean((enc_in - dec_out) ** 2)\n",
    "\n",
    "    # Log scalars\n",
    "    prefix = \"time_\"\n",
    "    wandb.log({f\"{prefix}mse_loss\": mse_total}, step=step)\n",
    "    wandb.log({f\"{prefix}frame_BER\": frame_BER}, step=step)\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(12, 16))\n",
    "    time_points = np.arange(zoom_samples)\n",
    "\n",
    "    axes[0].plot(time_points, enc_in[:zoom_samples], 'r', alpha=0.5, label='Encoder Input')\n",
    "    axes[0].plot(time_points, enc_out[:zoom_samples], 'b', alpha=0.8, label='Encoder Output')\n",
    "    axes[0].set_title(\n",
    "        f\"Encoder Comparison (MSE: {mse_encoder:.2e}) | \"\n",
    "        f\"In {enc_power_in:.3f} | Out {enc_power_out:.3f} | Scale {enc_scale:.3f}\"\n",
    "    )\n",
    "    axes[0].legend(); axes[0].grid(True)\n",
    "\n",
    "    axes[1].plot(time_points, dec_in[:zoom_samples], 'r', alpha=0.5, label='Decoder Input')\n",
    "    axes[1].plot(time_points, dec_out[:zoom_samples], 'b', alpha=0.8, label='Decoder Output')\n",
    "    axes[1].set_title(\n",
    "        f\"Decoder Comparison (MSE: {mse_decoder:.2e}) | \"\n",
    "        f\"In {dec_power_in:.3f} | Out {dec_power_out:.3f} | Scale {dec_scale:.3f}\"\n",
    "    )\n",
    "    axes[1].legend(); axes[1].grid(True)\n",
    "\n",
    "    axes[2].plot(time_points, enc_in[:zoom_samples], 'r', alpha=0.5, label='Original Input')\n",
    "    axes[2].plot(time_points, dec_out[:zoom_samples], 'b', alpha=0.8, label='Final Output')\n",
    "    axes[2].set_title(\n",
    "        f\"End-to-End Comparison ({'Trained' if run_model else 'Untrained'})\\n\"\n",
    "        f\"MSE: {mse_total:.2e}, BER: {frame_BER:.2f}\"\n",
    "    )\n",
    "    axes[2].legend(); axes[2].grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    wandb.log({f\"{prefix}time_signals\": wandb.Image(fig)}, step=step)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c91e8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CP_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c0f48d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,\n",
       "         44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,\n",
       "         58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
       "         72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,\n",
       "         86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
       "        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
       "        114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
       "        128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
       "        142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
       "        184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
       "        198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,\n",
       "        212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
       "        226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
       "        240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
       "        254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,\n",
       "        268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,\n",
       "        282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,\n",
       "        296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n",
       "        310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,\n",
       "        324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "        338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
       "        352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,\n",
       "        366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,\n",
       "        380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
       "        394, 395, 396, 397, 398, 399], dtype=torch.int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c109ac27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maild\\AppData\\Local\\Temp\\ipykernel_14764\\2405448157.py:29: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\Convolution.cpp:1037.)\n",
      "  sent_filtered = F.conv1d(sent_time.unsqueeze(1), h, padding='same').squeeze(1)\n",
      "C:\\Users\\maild\\AppData\\Local\\Temp\\ipykernel_14764\\2405448157.py:160: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  true_bits_array = np.array(true_bits)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Finished | Avg Loss: 0.12044768035411835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maild\\AppData\\Local\\Temp\\ipykernel_14764\\2405448157.py:160: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  true_bits_array = np.array(true_bits)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Finished | Avg Loss: 0.11955181509256363\n",
      "Epoch 2 Finished | Avg Loss: 0.1183292493224144\n",
      "Epoch 3 Finished | Avg Loss: 0.11794055998325348\n",
      "Epoch 4 Finished | Avg Loss: 0.11445077508687973\n",
      "Epoch 5 Finished | Avg Loss: 0.11368311941623688\n",
      "Epoch 6 Finished | Avg Loss: 0.11236777901649475\n",
      "Epoch 7 Finished | Avg Loss: 0.10975070297718048\n",
      "Epoch 8 Finished | Avg Loss: 0.1090206578373909\n",
      "Epoch 9 Finished | Avg Loss: 0.10685618966817856\n",
      "Epoch 10 Finished | Avg Loss: 0.10436522960662842\n",
      "Epoch 11 Finished | Avg Loss: 0.10026341676712036\n",
      "Epoch 12 Finished | Avg Loss: 0.09785860031843185\n",
      "Epoch 13 Finished | Avg Loss: 0.09673261642456055\n",
      "Epoch 14 Finished | Avg Loss: 0.09390603005886078\n",
      "Epoch 15 Finished | Avg Loss: 0.08937866985797882\n",
      "Epoch 16 Finished | Avg Loss: 0.0863528922200203\n",
      "Epoch 17 Finished | Avg Loss: 0.08346813172101974\n",
      "Epoch 18 Finished | Avg Loss: 0.07959093898534775\n",
      "Epoch 19 Finished | Avg Loss: 0.07460330426692963\n",
      "Epoch 20 Finished | Avg Loss: 0.07132095098495483\n",
      "Epoch 21 Finished | Avg Loss: 0.06795806437730789\n",
      "Epoch 22 Finished | Avg Loss: 0.06376460939645767\n",
      "Epoch 23 Finished | Avg Loss: 0.05970225855708122\n",
      "Epoch 24 Finished | Avg Loss: 0.05668886378407478\n",
      "Epoch 25 Finished | Avg Loss: 0.05302081257104874\n",
      "Epoch 26 Finished | Avg Loss: 0.04902076721191406\n",
      "Epoch 27 Finished | Avg Loss: 0.045141834765672684\n",
      "Epoch 28 Finished | Avg Loss: 0.0416732020676136\n",
      "Epoch 29 Finished | Avg Loss: 0.03895598277449608\n",
      "Epoch 30 Finished | Avg Loss: 0.034927867352962494\n",
      "Epoch 31 Finished | Avg Loss: 0.03206309303641319\n",
      "Epoch 32 Finished | Avg Loss: 0.029217593371868134\n",
      "Epoch 33 Finished | Avg Loss: 0.02587711438536644\n",
      "Epoch 34 Finished | Avg Loss: 0.02307162992656231\n",
      "Epoch 35 Finished | Avg Loss: 0.02110935188829899\n",
      "Epoch 36 Finished | Avg Loss: 0.01925758831202984\n",
      "Epoch 37 Finished | Avg Loss: 0.017165396362543106\n",
      "Epoch 38 Finished | Avg Loss: 0.015649795532226562\n",
      "Epoch 39 Finished | Avg Loss: 0.014315147884190083\n",
      "Epoch 40 Finished | Avg Loss: 0.013191711157560349\n",
      "Epoch 41 Finished | Avg Loss: 0.012023771181702614\n",
      "Epoch 42 Finished | Avg Loss: 0.011253662407398224\n",
      "Epoch 43 Finished | Avg Loss: 0.010813923552632332\n",
      "Epoch 44 Finished | Avg Loss: 0.010363195091485977\n",
      "Epoch 45 Finished | Avg Loss: 0.009888522326946259\n",
      "Epoch 46 Finished | Avg Loss: 0.009521536529064178\n",
      "Epoch 47 Finished | Avg Loss: 0.008513406850397587\n",
      "Epoch 48 Finished | Avg Loss: 0.00802907720208168\n",
      "Epoch 49 Finished | Avg Loss: 0.007500527426600456\n",
      "Epoch 50 Finished | Avg Loss: 0.0066768755204975605\n",
      "Epoch 51 Finished | Avg Loss: 0.00593572435900569\n",
      "Epoch 52 Finished | Avg Loss: 0.005426978226751089\n",
      "Epoch 53 Finished | Avg Loss: 0.0048086270689964294\n",
      "Epoch 54 Finished | Avg Loss: 0.004519787151366472\n",
      "Epoch 55 Finished | Avg Loss: 0.004015485290437937\n",
      "Epoch 56 Finished | Avg Loss: 0.0037150888238102198\n",
      "Epoch 57 Finished | Avg Loss: 0.003599919844418764\n",
      "Epoch 58 Finished | Avg Loss: 0.0034540921915322542\n",
      "Epoch 59 Finished | Avg Loss: 0.0034488271921873093\n",
      "Epoch 60 Finished | Avg Loss: 0.0032404251396656036\n",
      "Epoch 61 Finished | Avg Loss: 0.0033091495279222727\n",
      "Epoch 62 Finished | Avg Loss: 0.0032453208696097136\n",
      "Epoch 63 Finished | Avg Loss: 0.0031601479277014732\n",
      "Epoch 64 Finished | Avg Loss: 0.003097698325291276\n",
      "Epoch 65 Finished | Avg Loss: 0.003030854742974043\n",
      "Epoch 66 Finished | Avg Loss: 0.002942844061180949\n",
      "Epoch 67 Finished | Avg Loss: 0.0027915420942008495\n",
      "Epoch 68 Finished | Avg Loss: 0.0026272472459822893\n",
      "Epoch 69 Finished | Avg Loss: 0.0025175458285957575\n",
      "Epoch 70 Finished | Avg Loss: 0.0023688790388405323\n",
      "Epoch 71 Finished | Avg Loss: 0.0022473095450550318\n",
      "Epoch 72 Finished | Avg Loss: 0.0021884196903556585\n",
      "Epoch 73 Finished | Avg Loss: 0.002016659826040268\n",
      "Epoch 74 Finished | Avg Loss: 0.001985318260267377\n",
      "Epoch 75 Finished | Avg Loss: 0.001886857207864523\n",
      "Epoch 76 Finished | Avg Loss: 0.0018695017788559198\n",
      "Epoch 77 Finished | Avg Loss: 0.0018292648019269109\n",
      "Epoch 78 Finished | Avg Loss: 0.001750068855471909\n",
      "Epoch 79 Finished | Avg Loss: 0.0017690440872684121\n",
      "Epoch 80 Finished | Avg Loss: 0.001697016297839582\n",
      "Epoch 81 Finished | Avg Loss: 0.0016969982534646988\n",
      "Epoch 82 Finished | Avg Loss: 0.001647006836719811\n",
      "Epoch 83 Finished | Avg Loss: 0.0016361484304070473\n"
     ]
    }
   ],
   "source": [
    "def evm_loss(true_symbols, predicted_symbols):\n",
    "    return torch.mean(torch.abs(true_symbols - predicted_symbols) ** 2)\n",
    "\n",
    "def in_band_filter(x, ks_indices, nfft):\n",
    "    mask = torch.zeros(nfft, device=device)\n",
    "    neg_ks_indices = nfft - ks_indices\n",
    "    mask[ks_indices] = 1.0\n",
    "    mask[neg_ks_indices] = 1.0\n",
    "\n",
    "    impulse_response = torch.fft.ifftshift(torch.fft.ifft(mask).real)\n",
    "    h = impulse_response.view(1, 1, -1)\n",
    "    filtered_x = F.conv1d(x.unsqueeze(1), h, padding='same').squeeze(1)\n",
    "    return filtered_x\n",
    "\n",
    "\n",
    "def in_band_time_loss(sent_time, decoded_time, ks_indices, n_fft, num_taps):\n",
    "    \"\"\"Compute in-band loss directly in time domain using filtering\"\"\"\n",
    "    # Create frequency mask\n",
    "    mask = torch.zeros(n_fft, device=sent_time.device)\n",
    "    neg_ks_indices = n_fft - ks_indices\n",
    "    mask[ks_indices] = 1.0\n",
    "    mask[neg_ks_indices] = 1.0\n",
    "\n",
    "    # Convert to time-domain filter (this is differentiable)\n",
    "    impulse_response = torch.fft.ifftshift(torch.fft.ifft(mask).real)\n",
    "    h = impulse_response.view(1, 1, -1)\n",
    "\n",
    "    # Filter both signals\n",
    "    sent_filtered = F.conv1d(sent_time.unsqueeze(1), h, padding='same').squeeze(1)\n",
    "    decoded_filtered = F.conv1d(decoded_time.unsqueeze(1), h, padding='same').squeeze(1)\n",
    "\n",
    "    # Compute MSE on filtered signals (equivalent to in-band frequency loss)\n",
    "    loss = torch.mean((sent_filtered[:, num_taps:] - decoded_filtered[:, num_taps:]).pow(2))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def symbols_to_time(X, num_padding_zeros: int, num_leading_zeros=0):\n",
    "    # Make hermetian symmetric\n",
    "    Nt, Nf = X.shape\n",
    "    padding_zeros = torch.zeros(Nt, num_padding_zeros, device=device)\n",
    "    leading_zeros = torch.zeros(Nt, num_leading_zeros, device=device)\n",
    "    X = torch.cat([leading_zeros, X.to(device), padding_zeros], dim=-1)\n",
    "    DC_Nyquist = torch.zeros((X.shape[0], 1), device=X.device)\n",
    "    X_hermitian = torch.flip(X, dims=[1]).conj()\n",
    "    X_full = torch.hstack([DC_Nyquist, X, DC_Nyquist, X_hermitian])\n",
    "    # Convert to time domain\n",
    "    x_time = torch.fft.ifft(X_full, dim=-1, norm=\"ortho\").real\n",
    "    return x_time.to(device)\n",
    "\n",
    "def add_noise(signal, SNR):\n",
    "    signal_power = signal.abs().pow(2).mean()\n",
    "    noise_power = signal_power / SNR\n",
    "    noise_std = (noise_power / 2) ** 0.5 # real and complex\n",
    "    noise = noise_std * torch.randn_like(signal) + noise_std * 1j * torch.randn_like(signal)\n",
    "    signal += noise\n",
    "    return signal\n",
    "\n",
    "# def add_noise_time(signal, SNR):\n",
    "#     signal_power = signal.pow(2).mean()\n",
    "#     noise_power = signal_power / SNR\n",
    "#     noise_std = noise_power.sqrt()\n",
    "#     noise = noise_std * torch.randn_like(signal)\n",
    "#     return signal + noise\n",
    "\n",
    "\n",
    "def add_noise_time_cp(signal_with_cp, cp_length, snr_in, snr_low, snr_high, inband_idx, print_snr=False):\n",
    "    \"\"\"\n",
    "    Adds spectrally-shaped noise with three regions:\n",
    "      - In-band: indices in inband_idx\n",
    "      - Low out-of-band: below min(inband_idx)\n",
    "      - High out-of-band: above max(inband_idx)\n",
    "    \"\"\"\n",
    "    B, N_with_cp = signal_with_cp.shape\n",
    "    device = signal_with_cp.device\n",
    "\n",
    "    signal_no_cp = signal_with_cp[:, cp_length:]\n",
    "    P_sig = signal_no_cp.pow(2).mean(dim=-1, keepdim=True)\n",
    "\n",
    "    Pn_in_target = P_sig / snr_in\n",
    "    Pn_low_target = P_sig / snr_low\n",
    "    Pn_high_target = P_sig / snr_high\n",
    "\n",
    "    num_pos_freqs = (N_with_cp - 1) // 2\n",
    "    pos_freq_slice = slice(1, num_pos_freqs + 1)\n",
    "    neg_freq_slice = slice(N_with_cp - num_pos_freqs, N_with_cp)\n",
    "\n",
    "    inband_mask = torch.zeros(num_pos_freqs, dtype=bool, device=device)\n",
    "    valid_inband_indices = inband_idx[(inband_idx > 0) & (inband_idx <= num_pos_freqs)]\n",
    "    if valid_inband_indices.numel() > 0:\n",
    "        inband_mask[valid_inband_indices - 1] = True\n",
    "\n",
    "    all_idx = torch.arange(num_pos_freqs, device=device)\n",
    "    low_mask = (all_idx < inband_idx.min()) & ~inband_mask\n",
    "    high_mask = (all_idx > inband_idx.max()) & ~inband_mask\n",
    "\n",
    "    num_in_bins = inband_mask.sum()\n",
    "    num_low_bins = low_mask.sum()\n",
    "    num_high_bins = high_mask.sum()\n",
    "\n",
    "    def make_noise(num_bins, target_power):\n",
    "        if num_bins == 0:\n",
    "            return torch.zeros((B, 0), dtype=torch.complex64, device=device)\n",
    "        var_per_bin = (target_power * N_with_cp) / (2 * num_bins)\n",
    "        std_per_bin = torch.sqrt(var_per_bin)\n",
    "        noise = (torch.randn(B, num_bins, device=device) +\n",
    "                 1j * torch.randn(B, num_bins, device=device)) / math.sqrt(2.0)\n",
    "        return std_per_bin * noise\n",
    "\n",
    "    noise_in_pos = make_noise(num_in_bins, Pn_in_target)\n",
    "    noise_low_pos = make_noise(num_low_bins, Pn_low_target)\n",
    "    noise_high_pos = make_noise(num_high_bins, Pn_high_target)\n",
    "\n",
    "    noise_pos = torch.zeros(B, num_pos_freqs, dtype=torch.complex64, device=device)\n",
    "    if num_in_bins > 0: noise_pos[:, inband_mask] = noise_in_pos\n",
    "    if num_low_bins > 0: noise_pos[:, low_mask] = noise_low_pos\n",
    "    if num_high_bins > 0: noise_pos[:, high_mask] = noise_high_pos\n",
    "\n",
    "    noise_fft = torch.zeros(B, N_with_cp, dtype=torch.complex64, device=device)\n",
    "    noise_fft[:, pos_freq_slice] = noise_pos\n",
    "    noise_fft[:, neg_freq_slice] = torch.conj(torch.flip(noise_pos, dims=[1]))\n",
    "    noise_fft[:, 0] = 0\n",
    "    noise_time = torch.fft.ifft(noise_fft, norm=\"ortho\").real\n",
    "\n",
    "    if print_snr:\n",
    "        P_sig_mean = P_sig.mean().item()\n",
    "        def check(mask, noise_vals, target):\n",
    "            if mask.sum() == 0: return\n",
    "            tmp_fft = torch.zeros_like(noise_fft)\n",
    "            tmp_pos = torch.zeros_like(noise_pos); tmp_pos[:, mask] = noise_vals\n",
    "            tmp_fft[:, pos_freq_slice] = tmp_pos\n",
    "            tmp_fft[:, neg_freq_slice] = torch.conj(torch.flip(tmp_pos, dims=[1]))\n",
    "            Pn_actual = torch.fft.ifft(tmp_fft, norm=\"ortho\").real.pow(2).mean().item()\n",
    "            print(f\"SNR Check: target={target:.2f}, actual={P_sig_mean/Pn_actual:.2f}\")\n",
    "        check(inband_mask, noise_in_pos, snr_in)\n",
    "        check(low_mask, noise_low_pos, snr_low)\n",
    "        check(high_mask, noise_high_pos, snr_high)\n",
    "\n",
    "    return signal_with_cp + noise_time\n",
    "\n",
    "\n",
    "\n",
    "def calculate_BER(received_symbols, true_bits, constellation):\n",
    "    # Demap symbols to bits\n",
    "    constellation_symbols = torch.tensor(\n",
    "        list(constellation._symbols_to_bits_map.keys()),\n",
    "        dtype=received_symbols.dtype,\n",
    "        device=received_symbols.device\n",
    "    )\n",
    "    distances = abs(received_symbols.reshape(-1, 1) - constellation_symbols.reshape(1, -1))\n",
    "\n",
    "    closest_idx = distances.argmin(axis=1)\n",
    "    constellation_symbols_list = list(constellation._symbols_to_bits_map.keys())\n",
    "    decided_bits = [constellation._symbols_to_bits_map[constellation_symbols_list[idx]] for idx in closest_idx.cpu().numpy()]\n",
    "\n",
    "    # Flatten decided bits into a 1D array\n",
    "    decided_bits_flat = [int(bit) for symbol_bits in decided_bits for bit in symbol_bits]\n",
    "\n",
    "\n",
    "    # Convert to NumPy arrays for comparison\n",
    "    true_bits_array = np.array(true_bits)\n",
    "    decided_bits_flat_array = np.array(decided_bits_flat)\n",
    "\n",
    "    # Take minimum length to avoid shape mismatch\n",
    "    min_len = min(len(true_bits_array), len(decided_bits_flat_array))\n",
    "    true_bits_array = true_bits_array[:min_len]\n",
    "    decided_bits_flat_array = decided_bits_flat_array[:min_len]\n",
    "\n",
    "    # Calculate BER\n",
    "    BER = float(np.sum(true_bits_array != decided_bits_flat_array) / len(true_bits_array))\n",
    "    return BER\n",
    "\n",
    "\n",
    "def train(encoder, decoder, optimizer, scheduler, config, device, mask=None):\n",
    "\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "\n",
    "        epoch_loss = 0\n",
    "        epoch_freq_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        batch_entries = []\n",
    "        true_bits_list = []\n",
    "        for batch in range(config[\"batch_size\"]):\n",
    "            # Generate frame data\n",
    "            true_bits = np.random.randint(0, 2, size=NUM_BITS)\n",
    "            true_bits_list.append(torch.tensor(true_bits))\n",
    "            # true_bits = np.zeros(NUM_BITS).astype(int)\n",
    "            true_bits_str = ''.join(map(str, true_bits))\n",
    "            true_symbols = torch.tensor(\n",
    "                constellation.bits_to_symbols(true_bits_str),\n",
    "                dtype=torch.complex64, device=device\n",
    "            )\n",
    "            true_frame = true_symbols.reshape(config[\"Nt\"], config[\"Nf\"])\n",
    "\n",
    "            # Add known experimental noise\n",
    "\n",
    "            # true_frame = torch.zeros(config[\"Nt\"], config[\"Nf\"])\n",
    "            # true_frame[:, 100] = 10\n",
    "\n",
    "            if POWER_NORMALIZATION:\n",
    "                true_frame = true_frame / true_frame.abs().pow(2).mean(dim=1, keepdim=True).sqrt()\n",
    "            batch_entries.append(true_frame)\n",
    "\n",
    "        true_bits = torch.stack(true_bits_list)\n",
    "\n",
    "        # Batch along time domain\n",
    "        true_frame = torch.cat(batch_entries)\n",
    "\n",
    "        # print(\"Inband symbol power\", true_frame.abs().square().mean())\n",
    "        # Convert to time domain\n",
    "        sent_frames_time = symbols_to_time(true_frame, UPSAMPLING_ZEROS, NUM_ZEROS)\n",
    "        sent_frames_time = torch.hstack((sent_frames_time[:, -CP_LENGTH:], sent_frames_time))\n",
    "\n",
    "        encoded_frames_time = encoder(sent_frames_time)\n",
    "        # encoded_frames_time = in_band_filter(encoded_frames_time, KS, NUM_POINTS_FRAME)\n",
    "\n",
    "        # Clip to preamble make\n",
    "        encoded_frames_time = torch.clip(encoded_frames_time, -PREAMBLE_MAX, PREAMBLE_MAX)\n",
    "        # encoded_frames_time = add_noise_time_cp(encoded_frames_time,\n",
    "        #                                              snr_in=float(100000),\n",
    "        #                                                 snr_low=float(100000),\n",
    "        #                                                snr_high=0,\n",
    "        #                                               inband_idx=torch.arange(int(1), int(25e6)),\n",
    "        #                                              cp_length=CP_LENGTH)\n",
    "\n",
    "        received_frames_time = channel_model.forward_simulate(encoded_frames_time)\n",
    "\n",
    "\n",
    "        # Filter out of band noise\n",
    "        # received_frames_time_noisy = in_band_filter(received_frames_time_noisy, KS, NUM_POINTS_FRAME)\n",
    "\n",
    "        # received_frames_time = add_noise(received_frames_time, SNR=10**(config[\"snr_db\"]/10))\n",
    "        decoded_frames_time = decoder(received_frames_time)\n",
    "\n",
    "        # Convert to frequency domain for loss\n",
    "        sent_frames_frequency = torch.tensor(rfft(sent_frames_time[:, CP_LENGTH:].detach().cpu().numpy(), norm='ortho', axis=1)[:, KS])\n",
    "        decoded_frames_frequency = torch.tensor(rfft(decoded_frames_time[:, CP_LENGTH:].detach().cpu().numpy(), norm='ortho', axis=1)[:, KS])\n",
    "\n",
    "        sent_norm = sent_frames_frequency.abs().square().mean(dim=1, keepdim=True).sqrt()\n",
    "        decoded_norm = decoded_frames_frequency.abs().square().mean(dim=1, keepdim=True).sqrt()\n",
    "\n",
    "\n",
    "        if POWER_NORMALIZATION:\n",
    "            sent_frames_frequency = sent_frames_frequency / sent_norm\n",
    "            decoded_frames_frequency = decoded_frames_frequency / decoded_norm\n",
    "\n",
    "\n",
    "        # print(\"Time power through channel\", sent_frames_time.abs().square().mean().item(), received_frames_time.abs().square().mean().item(), sent_frames_time.shape)\n",
    "        loss = in_band_time_loss(sent_frames_time, decoded_frames_time, ks_indices=KS, n_fft=NUM_POINTS_FRAME, num_taps=config['num_taps'])\n",
    "        # loss = evm_loss(sent_frames_time, decoded_frames_time)\n",
    "        diff_complex = sent_frames_frequency.detach() - decoded_frames_frequency.detach()\n",
    "        # print(\"evm shapes\", sent_frames_frequency.shape, decoded_frames_frequency.shape)\n",
    "        freq_loss = torch.mean(diff_complex.abs().pow(2))\n",
    "\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_freq_loss += freq_loss.item()\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step(epoch_loss)\n",
    "\n",
    "        wandb.log({\"loss\": epoch_loss}, step=epoch)\n",
    "        wandb.log({\"freq_loss\": epoch_freq_loss}, step=epoch)\n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        wandb.log({\"learning_rate\": lr}, step=epoch)\n",
    "\n",
    "        # Get BER\n",
    "        ber = calculate_BER(decoded_frames_frequency.detach().flatten(), true_bits.flatten(), constellation=constellation)\n",
    "        wandb.log({\"BER\": ber}, step=epoch)\n",
    "        print(f\"Epoch {epoch} Finished | Avg Loss: {epoch_loss}\")\n",
    "        if epoch % 5 == 0:\n",
    "            make_time_validate_plots(\n",
    "            sent_frames_time[0],\n",
    "            received_frames_time[0],\n",
    "            decoded_frames_time[0],\n",
    "            frame_BER=ber,\n",
    "            run_model=True,\n",
    "            step=epoch\n",
    "            )\n",
    "\n",
    "            # Plot first example of sent and reconstructed time\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(sent_frames_time[0][:100].detach().cpu().numpy(), label=\"Sent (time)\")\n",
    "            ax.plot(decoded_frames_time[0][:100].detach().cpu().numpy(), label=\"Decoded (time)\")\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"Sent vs Decoded (Time Domain) EVM: {loss: 0.3e}\")\n",
    "            wandb.log({\"time_domain_plot\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "            sent_symbols = sent_frames_frequency[0].detach().cpu().numpy()\n",
    "            decoded_symbols = decoded_frames_frequency[0].detach().cpu().numpy()\n",
    "\n",
    "            # Compute EVM for logging (per frame)\n",
    "            evm_val = evm_loss(torch.tensor(sent_symbols), torch.tensor(decoded_symbols)).item()\n",
    "\n",
    "            # Create constellation plot\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.scatter(sent_symbols.real, sent_symbols.imag, color='blue', alpha=0.6, label='Sent')\n",
    "            ax.scatter(decoded_symbols.real, decoded_symbols.imag, color='red', alpha=0.6, label='Decoded')\n",
    "            ax.set_xlabel('In-phase')\n",
    "            ax.set_ylabel('Quadrature')\n",
    "            ax.set_title(f'Constellation Diagram EVM: {evm_val:0.3e}')\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "\n",
    "            # Log to wandb\n",
    "            wandb.log({\"constellation\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "            evm_per_freq = ((sent_frames_frequency[0] - decoded_frames_frequency[0]).abs()**2).detach().cpu().numpy()\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(evm_per_freq)\n",
    "            ax.set_title(\"EVM vs Frequency\")\n",
    "            wandb.log({\"evm_vs_freq\": wandb.Image(fig)}, step=epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "\n",
    "            # # Plot Model SNRs\n",
    "            # sent_k = torch.fft.fft(encoded_frames_time[:, CP_LENGTH:], norm=\"ortho\", dim=-1)\n",
    "            # received_k = torch.fft.fft(received_frames_time[:, CP_LENGTH:], norm=\"ortho\", dim=-1)\n",
    "\n",
    "            # residual = received_frames_time - mean\n",
    "            # received_noise_k = torch.fft.fft(residual[:, CP_LENGTH:] ** 2, norm=\"ortho\", dim=-1)\n",
    "\n",
    "\n",
    "            # signal_power = torch.mean(torch.abs(sent_k) ** 2, dim=0).detach().cpu().numpy()\n",
    "            # received_power = torch.mean(torch.abs(received_k) ** 2, dim=0).detach().cpu().numpy()\n",
    "            # received_noise_power = torch.mean(torch.abs(received_noise_k), dim=0).detach().cpu().numpy()\n",
    "            # snr_vs_freq = (received_power / received_noise_power + 1e-12)\n",
    "\n",
    "            # fig, ax = plt.subplots()\n",
    "            # ax.plot(10 * np.log10(signal_power[:len(signal_power)//2]))\n",
    "            # ax.axvline(30, c='r', linestyle='--')\n",
    "            # ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            # ax.set_title(f\"Encoded Signal Frequency Power Spectrum for {run.name}\")\n",
    "            # ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            # ax.set_ylabel(\"Power (dB)\")\n",
    "            # wandb.log({\"encoded_signal_power_spectrum\": wandb.Image(fig)}, step=epoch)\n",
    "            # plt.close(fig)\n",
    "\n",
    "            # fig, ax = plt.subplots()\n",
    "            # ax.plot(10 * np.log10(received_power[:len(received_power)//2]))\n",
    "            # ax.axvline(30, c='r', linestyle='--')\n",
    "            # ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            # ax.set_title(f\"Received Signal Frequency Power Spectrum for {run.name}\")\n",
    "            # ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            # ax.set_ylabel(\"Power (dB)\")\n",
    "            # wandb.log({\"received_signal_power_spectrum\": wandb.Image(fig)}, step=epoch)\n",
    "            # plt.close(fig)\n",
    "\n",
    "            # fig, ax = plt.subplots()\n",
    "            # ax.plot(10 * np.log10(snr_vs_freq[:len(snr_vs_freq)//2]))\n",
    "            # ax.set_title(f\"SNR vs Freq Estimate for {run.name}\")\n",
    "            # ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            # ax.set_ylabel(\"SNR (dB)\")\n",
    "            # ax.axvline(30, c='r', linestyle='--')\n",
    "            # ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            # wandb.log({\"snr_vs_freq\": wandb.Image(fig)}, step=epoch)\n",
    "            # plt.close(fig)\n",
    "\n",
    "            # fig, ax = plt.subplots()\n",
    "            # ax.plot(10 * np.log10(received_noise_power[:len(snr_vs_freq)//2]))\n",
    "            # ax.set_title(f\"Noise power vs Freq Estimate for {run.name}\")\n",
    "            # ax.set_xlabel(\"Freq Index k (10 kHz)\")\n",
    "            # ax.set_ylabel(\"Power (dB)\")\n",
    "            # ax.axvline(30, c='r', linestyle='--')\n",
    "            # ax.axvline(int(4e2), c='r', linestyle='--')\n",
    "            # wandb.log({\"noise_power_vs_freq\": wandb.Image(fig)}, step=epoch)\n",
    "            # plt.close(fig)\n",
    "\n",
    "    # Save model\n",
    "    torch.save({\n",
    "        \"time_encoder\": encoder.state_dict(),\n",
    "        \"time_decoder\": decoder.state_dict()\n",
    "    }, \"time_autoencoder.pth\")\n",
    "\n",
    "    artifact = wandb.Artifact(\"time_autoencoder\", type=\"model\")\n",
    "    artifact.add_file(\"time_autoencoder.pth\")\n",
    "    wandb.log_artifact(artifact)\n",
    "\n",
    "    return epoch_loss\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "train(encoder, decoder, optimizer, scheduler, config, device)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get SNR vs freq estimate\n",
    "test_freqs = torch.arange(0, 1e4 * 2999, 1e4, device=device)\n",
    "test_ks = (test_freqs / (1e4)).to(torch.int)\n",
    "true_bits = np.random.randint(0, 2, size=7 * len(test_freqs) * 100)\n",
    "\n",
    "\n",
    "true_bits_str = ''.join(map(str, true_bits))\n",
    "true_symbols = torch.tensor(\n",
    "    constellation.bits_to_symbols(true_bits_str),\n",
    "    dtype=torch.complex64, device=device\n",
    ")\n",
    "\n",
    "test = (NUM_POINTS_FRAME  +  -2 * test_ks[0] + -2 * len(test_ks)) // 2\n",
    "\n",
    "true_frame = true_symbols.reshape(100, 2999)\n",
    "true_bits = torch.tensor(true_bits)\n",
    "sent_frames_time = symbols_to_time(true_frame, test, 0)\n",
    "sent_frames_time = torch.hstack((sent_frames_time[:, -CP_LENGTH:], sent_frames_time))\n",
    "encoded_frames_time = encoder(sent_frames_time)\n",
    "received_frames_time_noisy, mean, std, nu = channel_model(encoded_frames_time)\n",
    "decoded_frames_time = decoder(received_frames_time_noisy)\n",
    "\n",
    "sent_k = torch.fft.fft(encoded_frames_time[:, CP_LENGTH:], norm=\"ortho\", dim=-1)\n",
    "received_k = torch.fft.fft(mean[:, CP_LENGTH:], norm=\"ortho\", dim=-1)\n",
    "\n",
    "residual = received_frames_time_noisy - mean\n",
    "received_noise_k = torch.fft.fft(residual[:, CP_LENGTH:] ** 2, norm=\"ortho\", dim=-1)\n",
    "\n",
    "\n",
    "signal_power = torch.mean(torch.abs(sent_k) ** 2, dim=0).detach().cpu().numpy()\n",
    "received_power = torch.mean(torch.abs(received_k) ** 2, dim=0).detach().cpu().numpy()\n",
    "received_noise_power = torch.mean(torch.abs(received_noise_k), dim=0).detach().cpu().numpy()\n",
    "snr_vs_freq = (received_power / received_noise_power + 1e-12)\n",
    "\n",
    "\n",
    "plt.plot(10 * np.log10(signal_power[:len(signal_power)//2]))\n",
    "plt.axvline(30, c='r', linestyle='--')\n",
    "plt.axvline(int(4e2), c='r', linestyle='--')\n",
    "plt.title(f\"Encoded Signal Frequency Power Spectrum for {run.name}\")\n",
    "plt.xlabel(\"Freq Index k (10 kHz)\")\n",
    "plt.ylabel(\"Power (dB)\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(10 * np.log10(received_power[:len(received_power)//2]))\n",
    "plt.axvline(30, c='r', linestyle='--')\n",
    "plt.axvline(int(4e2), c='r', linestyle='--')\n",
    "plt.title(f\"Received Signal Frequency Power Spectrum for {run.name}\")\n",
    "plt.xlabel(\"Freq Index k (10 kHz)\")\n",
    "plt.ylabel(\"Power (dB)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(10 * np.log10(snr_vs_freq[:len(snr_vs_freq)//2]))\n",
    "plt.title(f\"SNR vs Freq Estimate for {run.name}\")\n",
    "plt.xlabel(\"Freq Index k (10 kHz)\")\n",
    "plt.ylabel(\"SNR (dB)\")\n",
    "plt.axvline(30, c='r', linestyle='--')\n",
    "plt.axvline(int(4e2), c='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(10 * np.log10(received_noise_power[30:len(snr_vs_freq)//2]))\n",
    "plt.title(f\"Noise power vs Freq Estimate for {run.name}\")\n",
    "plt.xlabel(\"Freq Index k (10 kHz)\")\n",
    "plt.ylabel(\"Power (dB)\")\n",
    "plt.axvline(30, c='r', linestyle='--')\n",
    "plt.axvline(int(4e2), c='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, tag):\n",
    "    # Sample hyperparameters\n",
    "    dilation_base = trial.suggest_categorical(\"dilation_base\", [2])\n",
    "    num_taps = trial.suggest_int(\"num_taps\", 10, 30, step=2)\n",
    "    hidden_channels = trial.suggest_int(\"hidden_channels\", 4, 64, step=8)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2)\n",
    "    nlayers = trial.suggest_categorical(\"nlayers\", [2, 3, 4])\n",
    "\n",
    "    local_config = {\n",
    "        \"dilation_base\": dilation_base,\n",
    "        \"num_taps\": num_taps,\n",
    "        \"hidden_channels\": hidden_channels,\n",
    "        \"lr\": lr,\n",
    "        \"epochs\": 800,\n",
    "        \"batch_size\": 16,\n",
    "        \"Nt\": 1,\n",
    "        \"Nf\": 370,\n",
    "        \"save_path\": \"./saved_models\",\n",
    "        \"nlayers\": nlayers,\n",
    "        \"weight_init\": \"default\",\n",
    "        \"scheduler_type\": \"reduce_lr_on_plateu\",\n",
    "        \"modulator\": f\"{constellation_mode}\"\n",
    "    }\n",
    "\n",
    "    wandb.init(project=\"mldrivenpeled\", config=local_config, reinit=True,\n",
    "               tags=['autoencoder', f'{tag}', f'trial {trial.number}'], mode='online')\n",
    "\n",
    "    wandb.run.notes = f\"\\n | trained on channel model {run_name} \\n | {constellation_mode}\"\n",
    "\n",
    "    encoder = None\n",
    "    decoder = None\n",
    "    optimizer = None\n",
    "    scheduler = None\n",
    "\n",
    "    try:\n",
    "        encoder = TCN(\n",
    "            nlayers=nlayers,\n",
    "            dilation_base=dilation_base,\n",
    "            num_taps=num_taps,\n",
    "            hidden_channels=hidden_channels\n",
    "        ).to(device)\n",
    "\n",
    "        decoder = TCN(\n",
    "            nlayers=nlayers,\n",
    "            dilation_base=dilation_base,\n",
    "            num_taps=num_taps,\n",
    "            hidden_channels=hidden_channels\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(\n",
    "            list(encoder.parameters()) + list(decoder.parameters()), lr=lr\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "\n",
    "        final_loss = train(encoder, decoder, optimizer, scheduler, local_config, device)\n",
    "\n",
    "        return final_loss\n",
    "\n",
    "    finally:\n",
    "        wandb.finish()\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        del encoder, decoder, optimizer, scheduler\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7232b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "study_name = f\"optuna_offline_ae_model_{timestamp}\"\n",
    "# study_name= \"optuna_offline_ae_model_20250919_174002\"\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=study_name, storage=\"sqlite:///optuna_results.db\", load_if_exists=True)\n",
    "study.optimize(lambda trial: objective(trial, study_name), n_trials=100)\n",
    "print(\"Best trial:\")\n",
    "print(study.best_trial.params)\n",
    "\n",
    "'''\n",
    "{'dilation_base': 2, 'num_taps': 12, 'hidden_channels': 20, 'lr': 0.0005269745303114973, 'nlayers': 4, 'taps': 20} Current best with loss 2e-3\n",
    "Trial 44 finished with value: 0.001965869450941682 and parameters: {'dilation_base': 2, 'num_taps': 10, 'hidden_channels': 44, 'lr': 0.009314226151764216, 'nlayers': 4}. Best is trial 44 with value: 0.001965869450941682\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3987779",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = \"sqlite:///optuna_results.db\"\n",
    "summaries = optuna.get_all_study_summaries(storage=storage)\n",
    "for summary in summaries:\n",
    "    print(f\"Study name: {summary.study_name}\")\n",
    "    print(f\"  Trial count: {summary.n_trials}\")\n",
    "    if summary.best_trial is not None:\n",
    "        print(f\"  Best value: {summary.best_trial.value}\")\n",
    "        print(f\"  Best params: {summary.best_trial.params}\")\n",
    "    else:\n",
    "        print(\"  No trials completed yet.\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90307804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    "    plot_slice,\n",
    "    plot_parallel_coordinate\n",
    ")\n",
    "\n",
    "# Step 1: Choose your study name (copy it from the summaries you printed earlier)\n",
    "study_name = \"optuna_offline_ae_model_20250928_115643\"\n",
    "storage = \"sqlite:///optuna_results.db\"\n",
    "\n",
    "# Step 2: Load the study\n",
    "study = optuna.load_study(study_name=study_name, storage=storage)\n",
    "\n",
    "# Step 3: Plot using interactive Plotly charts\n",
    "plot_optimization_history(study).show()\n",
    "plot_param_importances(study).show()\n",
    "plot_slice(study).show()\n",
    "plot_parallel_coordinate(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcb5c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f19e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc26e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldrivenpeled",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
